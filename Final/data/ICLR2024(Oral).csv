"Papers_Title","Papers_Keywords","Papers_OfficialReview_list2_StrengthandWeak","Papers_OfficialReview_list2_Rating","Papers_OfficialReview_list2_Confidence"
"Proving Test Set Contamination in Black-Box Language Models","Keywords: language modeling, memorization, dataset contamination","I have some questions about the definition of test set contamination below.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Proving Test Set Contamination in Black-Box Language Models","Keywords: language modeling, memorization, dataset contamination","The experiments do not compare the performance of the proposed tests to prior work. I understand that this work differs from say, the work from Carlini et al. in that this work focuses on set-level contamination, but how does aggregating instance-level statistics over a set compare?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Proving Test Set Contamination in Black-Box Language Models","Keywords: language modeling, memorization, dataset contamination","Although a more efficient sharded rank comparison test is proposed, the computational complexity is still considerable. For example, testing 49 files using 1000 permutations per shard can take 12 hours for LLaMA2.
There is no comparison with other baseline methods.
The method relies on a strong assumption of data exchangeability, which may not hold in real-world datasets.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Proving Test Set Contamination in Black-Box Language Models","Keywords: language modeling, memorization, dataset contamination","I'm most concerned about the definition of contamination used in this paper. Currently, the most popular definition of contamination follows the n-gram analysis. In real-world scenarios when training large language models, it's hardly seen to directly feed original data samples in their original ordering as shown in Figure 1. The application of this work could be greatly limited.
From Figure 3, it seems that the parameters for shards and permutations are sensitive and have to be carefully selected when being applied to other test sets.
The paper only targets direct sentence appearance in the pre-training stage. What about instruction-tuning data in the SFT stage?","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"BooookScore: A systematic exploration of book-length summarization in the era of LLMs","Keywords: summarization, evaluation, long context, prompting, LLM","A potential weakness lies in the design of the BOOOOKSCORE metric. The approach of weighing all sentences equally may overlook the varying importance of different parts of the text for overall coherence. Additionally, there is an absence of a consistency check for the evaluation metric.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"BooookScore: A systematic exploration of book-length summarization in the era of LLMs","Keywords: summarization, evaluation, long context, prompting, LLM","One point I miss in the experiments is a baseline without hierarchical merging or incremental updating. The reason is that a significant fraction of books have length around 100k tokens or less (if we observe the statistics of BookSum, for instance), and it would be interesting to see if the hierarchical merging or incremental updating introduce (or not) a high quantity of coherence issues compared to a vanilla LLM approach. Even with some level of truncation, it should still be possible to assess coherence issues.
Minor issue: you mention in section 3 that ""we did not find summaries online for any books in our dataset, which means LLM memorization of these summaries is impossible."" Not finding results online by no means imply that memorization is impossible. In fact, we have no guarantee that closed-source models such as GPT-4 are trained just on publicly available data.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"BooookScore: A systematic exploration of book-length summarization in the era of LLMs","Keywords: summarization, evaluation, long context, prompting, LLM","I have very little concerns about this paper. It is however unfortunate that the evaluation framework did not consider faithfulness. This could have been done by asking annotators to assess each fact and search for it inside the book to verify its factuality.","10: strong accept, should be highlighted at the conference","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"BooookScore: A systematic exploration of book-length summarization in the era of LLMs","Keywords: summarization, evaluation, long context, prompting, LLM","The evaluation of human annotations focuses only on precision and does not investigate recall. However, the authors are open about this limitation.
Some of the examples of types of errors shown in Table 1 seem to be of questionable quality; for example, the first example about the ""mysterious man"" might as well be unanswered in the book (although I do not know the contents of the book in question). This may be a side effect of offering a monetary reward based in part on the number of annotations (cf. Appendix G).
The sentence-level score may disproportionately favor summaries that contain a large number of (short) sentences. Furthermore, the evaluation of different models does not further investigate whether some of the score differences can be explained by the different length of the summaries (e.g., a shorter summary may be more prone to omissions).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Generalization in diffusion models arises from geometry-adaptive harmonic representations","Keywords: diffusion models, memorization, generalization, inductive bias, curse of dimensionality, denoising, geometry-adaptive harmonic basis","It seems that the theoretical framework posited in section 3 is specific to the particular denoiser architectures being studied in the paper (BF-CNN). For example, PixelNet++-type denoisers used in modern diffusion models do not seem to be amenable to a decomposition like equation (6), because they involve attention layers and positional embeddings (presumably with affine components) to implement different conditioning operations. It would be good if the authors could comment on this issue, and how they see the theory extending to this modern setting.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Generalization in diffusion models arises from geometry-adaptive harmonic representations","Keywords: diffusion models, memorization, generalization, inductive bias, curse of dimensionality, denoising, geometry-adaptive harmonic basis","Nothing stands out, just needs to finalize the text.","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Generalization in diffusion models arises from geometry-adaptive harmonic representations","Keywords: diffusion models, memorization, generalization, inductive bias, curse of dimensionality, denoising, geometry-adaptive harmonic basis","The paper's results were obtained using a straightforward CNN architecture. However, prior studies have indicated that CNN architectures can effectively learn and utilize harmonic bases (https://arxiv.org/abs/1810.12136). In my opinion, the paper's only weakness lies in not acknowledging this perspective that has been previously established in the literature.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Generalization in diffusion models arises from geometry-adaptive harmonic representations","Keywords: diffusion models, memorization, generalization, inductive bias, curse of dimensionality, denoising, geometry-adaptive harmonic basis","further validation on a more realistic data might be beneficial to strengthen the main points of the paper
lack of any sort of description of more ""general DNN GAHBs""","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions","Keywords: In-context learning, Transformers, Large language models, Boolean functions","I don't see any major weakness.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions","Keywords: In-context learning, Transformers, Large language models, Boolean functions","I am not sure which is the message of this paper compared to previous work. It has already been observed that transformers can ""choose"" between algorithms in [1], while we already knew that there are some tasks that transformers perform well and some others that they don't. I think that all the observations in this paper have been observed in different settings in other papers, thus I consider the contribution marginal.
[1]: Bai, Yu, et al. ""Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection."" arXiv preprint arXiv:2306.04637 (2023).","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions","Keywords: In-context learning, Transformers, Large language models, Boolean functions","The takeaway messages are a bit unclear to me. [Update: The authors have clarified in the rebuttal. I hope the changes could be reflected in the revised paper.]
Some results could be better presented and explained.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions","Keywords: In-context learning, Transformers, Large language models, Boolean functions","The author claimed that TFs can learn two distinct algorithms on tasks such as conjunctions, which is not that convincing to me.
Let's take figure 3 as an example and let's call the four sub-figure a to d from the left to the right. The way that authors compared these four figures and draw conclusions is that: they compare a and b, and the compare c with d, then they drew conclusion that the trained TFs can learn two distinct algorithms. This is not a good way for comparison. This is because one can easily give a counter-example to show that a single algorithm can simultaneously achieve a and b. For example, suppose the algorithm that TFs learn is: randomly pick one decision rule (or Boolean function) which is in the conjunction function class and agrees with all examples in the test context (the x_i, y_i pairs at test time). Then, when tested on teach conjunction (fig a), since there is only one conjunction function matching all test context, it will achieve a perfect accuracy. When tested with random sequence of examples from a conjunction task, there can be many functions in the conjunction function class that satisfying all test examples, so it can achieve a imperfect performance. Similar logic applies on the comparison between c and d.
At a high level, if you want to show the trained TFs can learn two distinct algorithms, it is not a good idea to show that they achieve different performance on different test examples but trained on same data distribution, It is better to show that they achieve different performance when trained on different data distribution, but tested on the same examples. In this case, you should compare figure b and c to draw your conclusion, instead of comparing a and b. The reason behind this is that the in-context learning is specific to the pre-training distribution, and it s very natural that they learn different algorithms on different pre-training distributions.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"The mechanistic basis of data dependence and abrupt learning in an in-context classification task","Keywords: in-context learning, mechanistic interpretability, language models, induction heads","Although I consider the analysis presented a tour de force, possessing all the strengths describe above, it is not perfectly clear that the analysis of the 2-3 parameter reduction would carry over to the full 2-attention-head network of Figure 1c. A hunch I have is that the L=N case might not be quite as susceptible to failure in the full network because the full network might have a more complex loss landscape with a lower likelihood of being initialized in a place in that landscape that doesn't allow a complete solution. An important and simple step toward addressing this would be to repeat the L = N simulation in the full network. If the full network fails to learn in that case, it would confirm the applicability of the analysis to the full network. Success would not fully invalidate the analysis, but would leave something left to explain.
More generally, I believe more consideration of what will happen in a larger model will be useful for the field. Clearly things will not work just in the way they do in these reductions when the task is learned in a larger transformer. While fuller characterization of that will be a task for future work, noting this issue as a limitation of the present effort and pointing considering how these results inform us about what is happening in LLMs will be valuable.
There are two less important weaknesses I'd like to see addressed.
First, I don't feel I have an intuitive understanding of why the loss landscape of the 3 parameter model does not have a saddle point at the point were all three parameters are equal to 0. Perhaps an understanding of this is latent in the equations and I could work it out with a bit of effort, but to help me (and possibly others) understand, it would be useful if the authors could work out such an intuitive understanding. Such an understanding could help address reasons why the behaviors of the 2- and 3-parameter reduced models might or might not be applicable to the full model.
Second, paper is harder to read than it should be. The main deficiency of the paper was its failure to take cognizance of the difficulty of extended chains of arbitrary associative bindings requiring long-distance leaps across context. It is just such binding that lie at the heart of the mechanisms the authors are investigating, but they are hard for human readers when arbitrary as they often were in this paper.
As examples, we are treated to terms like the former vs the latter as referring expressions, arbitrary labels (a-d) for key phenomena, random ordering of the assignments of these labels to lines in graphs, arbitrary labels for hypotheses (I-V), and the unhelpful placement of figures (esp fig 4) on pages remote from the place in the paper where they are discussed. Although ultimately the conclusions are stated in (what I find myself to be) conceptual terms, there should be engagement with this conceptual structure in the referential expressions used. I know space is limited, but I'm sure it is possible to do a better job. As examples, H3 could be abbreviated sCLA -> ILA+TILA (slow-learned context-label attention -> Item-label attention and Target-item-label association). Just let a,b,c,d and I-V go. H4 and H5 should each be expressed directly, or at the very least the order of defining the symbols x and 0/ should correspond to their order of appearance in these hypotheses.
I am also not sure that the difficulty of the L=N case in the","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"The mechanistic basis of data dependence and abrupt learning in an in-context classification task","Keywords: in-context learning, mechanistic interpretability, language models, induction heads","The paper can be improved in terms of writing/presentation. For example, you can explain early on in the paper what ""induction head"" means for readers that are less familiar with this area.
There are also several other parts of the paper in which the writing can be improved -- mostly by writing simpler/shorter/more clear sentences.","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"The mechanistic basis of data dependence and abrupt learning in an in-context classification task","Keywords: in-context learning, mechanistic interpretability, language models, induction heads","In a sense, the paper is tantalizing, as it invites further work, for instance on the interplay of overlap difference \xi and data Zipfianity parameter \alpha.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"The mechanistic basis of data dependence and abrupt learning in an in-context classification task","Keywords: in-context learning, mechanistic interpretability, language models, induction heads","I have the following concerns about this paper. Many of them involve claims that I feel are made too strongly in the paper relative to the level of evidence provided.
-- The paper illustrates a set of phenomena in figure 2, and promises a mechanistic understanding of these phenomena. But the mechanistic analysis provided later in the paper does not speak to most of the phenomenology -- for instance, the dependence of the ICL/IWL tradeoff on B, epsilon, K, and alpha. In fact, the mechanistic analysis focuses on the p_C > 0 case, which is different from the p_c = 0 regime that gives rise to all the tradeoffs observed in Figure 2. Thus, the connection between pages 1-4 of the paper and the rest is not entirely clear.
-- -- The following sentence, while intuitively reasonable, is written as a key strong claim and as far as I can tell is not really justified with evidence: ""Therefore, the relative rates at which the network acquires ICL and IWL control the fraction of loss explained by each mechanism after convergence.""
-- The paper makes strong causal claims based only on correlational evidence. For instance, ""Induction head formation drives the abrupt transition during ICL."" As far as I can tell no evidence is given for this claim, other than the (very suggestive, I agree!) fact that they coincide in time.
-- The paper makes strong claims about the three-parameter model proving or ruling out certain hypotheses. An example is the sentence ""This rules out hypothesis V as only the factors corresponding to the progress measures (a) through (d) have been included in the minimal model."" In my opinion, such claims are much too strong. The three-parameter model is ultimately a different model from the original transformer architecture being used! While the analysis of its behavior is suggestive of the learning strategies used by the original architecture, it is not conclusive. The strength of the claims should be adjusted accordingly.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Improved Techniques for Training Consistency Models","Keywords: Consistency Models, Consistency Training, Diffusion Models, Score-Based Generative Models, Score-Based Diffusion Models, Distillation","If I remember correctly, in the original consistency model, the teacher set to have EMA is more of an empirical decision. Using the same network as the student (with STOPGRAD operation) is definitely reasonable and even more intuitive (we want the model to be consistent with itself). Thus, I am not against dropping the EMA component, if it means better empirical performances.
However, I do not feel the theoretical analysis presented in Sec.3.2 is justified. Note since I believe the main contribution of the paper is an empirical one, my complaint here does not change my assessment of the paper significantly. Still, I would appreciate it if the authors could clarify my concerns here.
I think Eq.6 applies no matter the relation between
θ
and
θ−
, no?
In Eq.7, why are we looking at the gradient scaled by
1/Δσ
? If we look at just the pure gradient, it should be 0 if
θ=θ−
, and some finite value associated with their difference if not, and furthermore, the difference between
θ
and
ξ
disappears. It may look like the loss function has nothing to do with learning the correct parameter
ξ
like the authors suggest in the second last paragraph in Sec.3.2. However, to me, this is not a surprise and totally expected. The self-consistency loss itself does not really force the network to learn anything correctly, i.e. the model could just predict a constant no matter the input and still be considered consistent with itself. In my understanding, it is really the boundary condition enforced through parameterizations that makes the model work, which is not a fact used in this toy example.
In the current version, I am curious as to what the authors have in mind about ""if the consistency loss either does not exist or is unsuitable"". This notion does not seem to be explained well.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Improved Techniques for Training Consistency Models","Keywords: Consistency Models, Consistency Training, Diffusion Models, Score-Based Generative Models, Score-Based Diffusion Models, Distillation","W1: The choice to use the pseudo-Huber loss is not entirely convincing, as its effectiveness appears sensitive to the chosen constant value, and it offers negligible improvements over the tuning-free LPIPS loss, which is known for its alignment with human perception and computational efficiency, especially in pixel-space models.
W2: Apart from the significant change of removing EMA, the other enhancements resemble engineering optimizations rather than foundational advances. Their relevance to broader applications is questionable, especially since the empirical evaluation is limited to smaller datasets like CIFAR-10 and ImageNet-64x64. Expanding experiments to include higher-resolution images on ImageNet or more varied datasets such as COCO or LAION could substantiate the model's versatility.
W3: The training speed for the consistency model is comparatively slow, especially when compared with models like GANs. It would be insightful if the authors could address this aspect and discuss its implications for scaling to larger datasets.
W4: The applicability of consistency training appears confined to training unguided models, which significantly underperform in applications such as text-to-image generation.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Improved Techniques for Training Consistency Models","Keywords: Consistency Models, Consistency Training, Diffusion Models, Score-Based Generative Models, Score-Based Diffusion Models, Distillation","This paper functions primarily as a technical exploration, compiling successful practices in training diffusion models. While it includes numerous ablation studies, it lacks sufficient theoretical backing to fully support these practices.
The paper’s improved training schemes do allow the consistency model to avoid relying on a pre-trained diffusion model. However, its theoretical basis still seems anchored in diffusion model principles. It would be beneficial if the authors explored the broader potential of the consistency training scheme. Specifically, whether this training would be effective when the generation process is not the reverse of a diffusion process but a more general corruption process, such as those described in [1] and [2].
[1] Bansal, A., Borgnia, E., Chu, H.M., Li, J.S., Kazemi, H., Huang, F., Goldblum, M., Geiping, J. and Goldstein, T., 2022. Cold diffusion: Inverting arbitrary image transforms without noise. arXiv preprint arXiv:2208.09392. [2] Xu, Y., Liu, Z., Tegmark, M. and Jaakkola, T., 2022. Poisson flow generative models. Advances in Neural Information Processing Systems, 35, pp.16782-16795.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Improved Techniques for Training Consistency Models","Keywords: Consistency Models, Consistency Training, Diffusion Models, Score-Based Generative Models, Score-Based Diffusion Models, Distillation","I think the paper has no major weaknesses. However, there would be opportunities to further improve the work:
I am wondering how scalable consistency models are with the proposed modifications. Can one train, for instance, text-to-image consistency models? Or how about training on higher-resolution images?
The new consistency models do not require LPIPS losses anymore and are thereby more general in that they are not limited to image synthesis anymore. It would be interesting to validate that consistency models can also be successfully trained on non-image data (e.g. audio, graphs, 3D, video, etc).
Conclusion: Overall, I think this is a good and solid paper. It significantly improves consistency models, a very promising new class of generative models, and the paper is overall well-written and of high quality. Hence, I recommend acceptance.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Provable Compositional Generalization for Object-Centric Learning","Keywords: compositional generalization, identifiability, object-centric learning, generalization, OOD generalization, unsupervised learning, slot attention, disentanglement, autoencoders, representation learning","The assumptions of compositionality and irreducibility are quite restrictive. Most real-world datasets likely violate these.
The additive decoder limits modeling of complex object interactions and relations.
The consistency regularization implementation requires sampling implausible object combinations. More principled schemes could improve results in complex environments.
Experiments only validate the theory on simple synthetic datasets. Testing on more diverse and realistic data would better demonstrate applicability, though the evaluation would also be more challenging.
The proposed methods, especially when ensuring encoder-decoder consistency and handling latent slots, might pose scalability issues for very large datasets or more complex models. A discussion on the scalability, computational costs, and potential solutions would make the paper more robust.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Provable Compositional Generalization for Object-Centric Learning","Keywords: compositional generalization, identifiability, object-centric learning, generalization, OOD generalization, unsupervised learning, slot attention, disentanglement, autoencoders, representation learning","It would be great if the assumptions could be relaxed, e.g., to handle occluded objects or to handle general latent variable learning domains other than the image objects.
The ""contemporary"" work [1] discussed most parts of this paper except for the generalizable encoder.
The experimental environment is simple with two-object synthetic images. It would be more convincing to see results on multi-object real images.
[1] S ́ ebastien Lachapelle, Divyat Mahajan, Ioannis Mitliagkas, and Simon Lacoste-Julien. Additive decoders for latent variables identification and cartesian-product extrapolation. arXiv preprint arXiv:2307.02598, 2023.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Provable Compositional Generalization for Object-Centric Learning","Keywords: compositional generalization, identifiability, object-centric learning, generalization, OOD generalization, unsupervised learning, slot attention, disentanglement, autoencoders, representation learning","Although they support the theory, the experiments are quite limited. For instance, these are all with only two slots with 16 dimensions each. See the questions section for additional information that would be interesting to see from experimentation.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Predictive auxiliary objectives in deep RL mimic learning in the brain","Keywords: hippocampus, neuroscience, cognitive science, deep reinforcement learning, representation learning, prediction","One important feature that isn't clear from what is presented in the paper is how the environment itself may or may not affect these results. I don't find any examples of what gridworld environments are being solved by these models, let alone how complex they are. Surely the predictability of the environment itself has some bearing on the rate of learning and retrainability for novel tasks, not to mention the quality of representations? Please provide examples of these environments. If possible, please consider varying the complexity of the environments.
minor:
Bottom of page 3 ""the standard double deep Q-learning temporal difference loss function"": Even though standard, please either provide the form of this loss or provide a reference.
page 4, just below figure caption, definition of positive sample loss: should o_{t+1} be z_{t+1}?
last sentence, first paragraph page 5: ""the predictive model is trained with..."" (No ""be"")
first sentence, section 4.2: remove ""is used"" at the end of the sentence.
first sentence, last paragraph on page 7: remove ""to"",I.e. ""undergo experience-dependent changes"".
last paragraph, page 8: ""remembering the previous trial type"". (Remove ""whether""), also empty reference at the end of that sentence.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Predictive auxiliary objectives in deep RL mimic learning in the brain","Keywords: hippocampus, neuroscience, cognitive science, deep reinforcement learning, representation learning, prediction","It's interesting to see in section 4.4 where the authors describe the effects of value learning in the encoder network, but this part feels somewhat disconnected from the rest of the paper, as the primary focus is to demonstrate how predictive objectives can lead to representation changes similar to those seen in the brain","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Predictive auxiliary objectives in deep RL mimic learning in the brain","Keywords: hippocampus, neuroscience, cognitive science, deep reinforcement learning, representation learning, prediction","The related works section is a little small/sparse. The authors do a good job in highlighting works on auxiliary predictive losses in RL within the machine learning realm, but I think there is also a growing body of work that is using this framework to produce various behavioral phenomenon in cognitive science/neuroscience. These are complimentary works to the current submission and would be good to include. Here are some examples that I feel should definitely be included:
Kumar et al. 2022 NeurIPS use auxiliary predictive losses in RL agents to predict abstractions of the observation, operationalized through language and symbolic programs, in order to reproduce abstract human biases.
Jensen et al. 2023 bioRxiv introduce a predictive auxiliary loss which helps the agent learn when to plan and reproduces replay patterns seen in rodent hippocampal work.
This is not exactly auxiliary predictive loss, but I think it is having the same effect, Binz & Schulz 2022 NeurIPS show adding a regularization term to the loss on the number of bits required to compress the agent's weights reproduces quirks in human exploration.
I think the clarity in some portions in this submission can be improved.
On page 4, the description of the auxiliary losses can be improved. Its an important part of the work so it'd be good to have this be as clear as possible. A sentence describing what exactly
τ
is representing and why
L+
is a loss term that enforces transition structure in the state representations would be very helpful. Also, for the third term in
L+
, shouldn't it be
τ(zt+1,at+1)
and not
τ(ot+1,at+1)
? For the negative sampling loss term, making it explicit
zi
and
zj
are latent representations of states that are not consecutive in the same area where the loss term is introduced would be helpful. It'd also be good to have a sentence explaining the motivation for choosing these two specific auxiliary losses. I suspect its loosely inspired by pattern completion vs pattern seperation in hippocampus (respectively) but it would be good to confirm that in this section.
It would be helpful to state what the colors in Figure 2D mean. It wasn't clear to me upon first read.
The memory component in page 8 is not explained at all. It seems important to describe what this is to put Fig. 4's results in context.
There are a couple of design decisions that left me a little confused (details in the questions section). It would be nice for the authors to clarify the motivations behind them.
Last, I don't think there was any section in the paper explicitly discussing the limitations of the work. I think this is an important part of any iclr paper so it'd be good to include one.
References:
Kumar, S., Correa, C. G., Dasgupta, I., Marjieh, R., Hu, M. Y., Hawkins, R., ... & Griffiths, T. (2022). Using natural language and program abstractions to instill human inductive biases in machines. Advances in Neural Information Processing Systems, 35, 167-180.
Jensen, K. T., Hennequin, G., & Mattar, M. G. (2023). A recurrent network model of planning explains hippocampal replay and human behavior. bioRxiv, 2023-01.
Binz, M., & Schulz, E. (2022). Modeling human exploration through resource-rational reinforcement learning. Advances in Neural Information Processing Systems, 35, 31755-31768.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning","Keywords: reinforcement learning, pre-training, goal-conditioned RL, open-world environments","Ablations are fairly limited and leave me with several unanswered questions that seem important to address given the technical contributions of the paper. Firstly, it is evident that too few clusters (10) fails to capture the diversity of the goal space, and that no clustering fails to learn at all. However, it is not clear to me what the breaking point would be in terms of number of clusters: would e.g. 5,000 clusters lead to similar or more diverse behaviors than 500 clusters, or would it collapse to similar performance as the no-clustering ablation? Similarly, it is not clear based on the ablation on the number of low-level steps that more than 100 steps (thus offloading more of the learning to behavior cloning rather than RL) would lead to worse behaviors. Given that the low-level policy is trained on a very large dataset, I imagine that behavior cloning over longer horizons, e.g., 1,000 steps, could still lead to very meaningful behaviors. Additionally, # of clusters and # of steps are highly dependent hyper-parameters given that they jointly balance how much of the behavior should be offloaded to the high-level RL policy vs. the low-level BC policy, but I didn't find any discussion or results that highlight this. Lastly, could the authors please clarify why the third ablation is conducted on Spider rather than the Log task like the two other ablations?
The paper is lacking in terms of implementation details on the proposed method + the baselines. It would be helpful if the paper was more self-contained and described the overall architecture etc. in the appendix rather than simply referencing prior work. Additionally, in cases where baselines are adapted to new domains yet fail completely (e.g., VPT for the Kitchen environment), I would appreciate if the authors could share some thoughts on why this might be, even if not backed by data.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning","Keywords: reinforcement learning, pre-training, goal-conditioned RL, open-world environments","The novelty of discretizing goal spaces is limited.
The baselines are not sufficient. There are many goal-conditioned RL methods that can be applied to offline pre-training, including continuous goals [1] and discretized goals [2]. The included baselines are not well selected. SPiRL was proposed in 2021, and VPT is not goal conditioned. Steve-1 is language-labeled which is used in quite different settings.
I don’t think the visualization in Figure 4 can support that the clustered goals are meaningful. You can always find images from different clusters representing different behaviors. What I would expect is that images clustered into the same group should present similar patterns.
[1] Rosete-Beas, Erick, et al. ""Latent plans for task-agnostic offline reinforcement learning."" Conference on Robot Learning. PMLR, 2023.
[2] Islam, Riashat, et al. ""Discrete factorial representations as an abstraction for goal conditioned reinforcement learning."" arXiv preprint arXiv:2211.00247 (2022).","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning","Keywords: reinforcement learning, pre-training, goal-conditioned RL, open-world environments","Relatively complex method with many steps: The presented method requires the learning of three separate networks: a low-level goal-conditioned policy, a high-level goal-generating policy and a goal prior model. This results in a lot of hyperparameters such as the appropriate horizon (k) as well as the weight on the intrinsic reward for the high-level policy (
α
). Additionally, the compression of the goal into a low-dimensional space is also driven by heuristics and requires the appropriate choice for the number of goals to cluster into. Applying this algorithm into a new domain will not be straightforward and would require significant engineering work. However, I acknowledge that if an end-user puts in the engineering effort, then this method can have very strong performance in a new domain.
Novelty: PTGM draws on several ideas from existing work by Pertsch et al.[1]. It would be helpful to get a better understanding of the similarities and differences between the two methods to judge the novelty of the work.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!","Keywords: AI Safety, Large Language Models, Fine-tuning, Jailbreaking, AI Alignment","It is not surprising that fine-tuning an LLM could degrade its safety as LLMs are very strong in following instructions.
The technique (fine-tuning) used in the paper is very simple. From the technique perspective, the contribution is limited.
The evaluation is conducted on the dataset created by this paper. It is not clear whether the used dataset is representative or not. In Appendix F, the authors show some results on the advbench dataset. I am wondering why the authors don’t show most of the results on this dataset as it is publicly available. Also, in Table 10, many other metrics are not used. It is unclear whether the results in Table 10 are reliable or not.
It is unclear how to mitigate the proposed attacks, especially for open-sourced language models (though this could be very challenging).
Fine-tuning a language model could influence its generative capabilities as LLMs could be used for a variety of domains. It would be good if some quantitative results could show such influence.","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!","Keywords: AI Safety, Large Language Models, Fine-tuning, Jailbreaking, AI Alignment","There is already a lot of useful material in this paper, but it could be made stronger by including a brief discussion of hypothesized causes (if the authors intuit any) of the observed fragility of current safety-enforcing methodologies, maybe in the conclusion section (but I understand the page length limitation and the speculative nature of such hypotheses).","10: strong accept, should be highlighted at the conference","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!","Keywords: AI Safety, Large Language Models, Fine-tuning, Jailbreaking, AI Alignment","Missing comparisons with jailbreak attacks. Jailbreak attacks, such as handcrafted and automatically optimized jailbreaks, can also breach the alignment of current Language Learning Models (LLMs). This risk is already well-known and existing. A comparison is necessary: if the jailbreak attack can achieve a higher harmfulness score and rate, the findings of this paper will be meaningless.
Critical evaluations are missing. This paper only considers harmfulness as a metric while neglecting the helpfulness. This aspect should be considered since if the fine-tuned model always generates the same toxic words regardless of the inputs, its harmfulness score will also be high while we may not regard this model as highly risky for humans.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!","Keywords: AI Safety, Large Language Models, Fine-tuning, Jailbreaking, AI Alignment","The findings are interesting but not surprising. Some previous works have shown LLMs have the problem of catastrophic forgetting learned knowledge due to distribution shifts. Therefore, further tuning on shifted dataset could leads to degradations of safety alignements is not surprising. Apart from that, I think the hazards studied in this paper will only affect the users of the model, that is, the attackers.
The evaluations are not clear, especially experiments in Section 4.2 and 4.3. The authors only evaluate the performance of safety alignment. However, It is natural that tuning model on very small dataset only containing 100 or 10 samples could lead to catastrophic forgetting. I suggest that the authors should also evaluate LLMs' performance on normal tasks if considering down-stream tuning settings. I noticed that the author take evaluations on MT-bench. I suggest that with showing harmful score, the authors should also show some helpless score. Another concern is model scale. Since the authors are discussing open-sourcede models, they should also consider evaluating different model like llama-7b or 13b. Please show the generated samples from Llama-2 model.
The novelty of the paper is limited, SFT on harmful dataset. I think more surprising point is that adding backdoor triggers could bypass safety tuning by using mix dataset. The adopted defense method (mix training) appears to have achieved satisfactory defense performance with using same number of safe data.
This paper lacks exploration of the underlying principles. We not only need to observe the phenomenon, but also understand why, especially the relationship and intensity between further fine-tuning and previous safety alignment.","6: marginally above the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors","Keywords: Pre Training, Transformers, State Space Models, Long Range Models, Fair Evaluation","The paper largely compares the different models on the effectiveness in terms of benchmark accuracy. It would be good to include commentary on SPT computational costs relative to initializations of state space models.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors","Keywords: Pre Training, Transformers, State Space Models, Long Range Models, Fair Evaluation","W1. There are no results on computing requirements for SPT and, e.g., how to best combine SPT with supervised fine-tuning.
W2. The results on PathX-256 suggest SPT failed to close the gap in this case. This seems to warrant further investigation.","None","8: accept, good paper"
"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors","Keywords: Pre Training, Transformers, State Space Models, Long Range Models, Fair Evaluation","Most experiments are performed on Long Range Arena which is relatively small or synthetic.
The main self-pretraining results (Tables 1 and 2) are not with the latest Transformers and SSMs.
Some experimental analysis is lacking. See my questions below.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors","Keywords: Pre Training, Transformers, State Space Models, Long Range Models, Fair Evaluation","The paper does not seem to take the cost of SPT vs training directly on the downstream task into account, or at least does not make this axis of comparison clear.
The details are unclear in how much time is spent pretraining vs fine-tuning with the SPT procedure and how this compares to the typical training method for these tasks. These points should be discussed clearly in the main paper.
It is stated in Section 3.2 that sub-par LRA performance is often cited as a prime motivating factor for new methods, but it seems efficiency is often just as important a reason new methods are proposed
If one method can be directly trained on the task, while another has to first be pretrained and then fine-tuned, one would need to compare the cost/time/compute/etc to achieve a certain performance to determine if one method is superior, at least in many settings (note this point is less relevant in large scale language and vision settings where pretraining is the norm).
Further exploration and clarification on these points would improve the paper.
Even when trained with SPT, it seems from the results that methods such as S4 with structured biases consistently outperform methods with less structured biases across almost every task (I believe Text and Retrieval in Table 2 are the only exceptions to this). The reviewer agrees these differences are not as drastic as it seems when using the traditional procedure, but it still seems the structured biases are helping and the traditional procedure is somewhat predictive of the ordering. Or is this just an artifact of the experiments? A potential discussion on this point could be useful.
Table 1 lists many efficient attention methods that were originally evaluated on LRA. It would have been interesting to see a couple of these methods also trained with SPT to confirm empirically that they also do not perform as poorly when using SPT. (I suspect this is the case, but currently have to guess since no result is provided).
The tasks considered in this paper are standard, but nonetheless the addition of less synthetic or larger scale tasks and experiments would also make the paper more compelling to a broader audience
No code appears to be included (it seems it will be made available based on the anonymized link, but would have been nice to explore during the review).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models","Keywords: quantization, compression, large language models, NLP, machine learning, low rank","None, but a few clarifying questions stated below.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models","Keywords: quantization, compression, large language models, NLP, machine learning, low rank","It might be better to put higher priority and conduct more experiments on decoder-based (or encoder decoder) models for generative tasks. It seems that quantized lora (whether with or without intialization) lacks too much in classification tasks with encoders, to the extent that pratictionars probably won't want to train quantized lora models on these tasks.
Otherwise, I find this paper well rounded without significant weaknesses.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models","Keywords: quantization, compression, large language models, NLP, machine learning, low rank","I couldn't identify serious weaknesses of this work but I have some suggestions and questions for the authors. See below.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Graph Neural Networks for Learning Equivariant Representations of Neural Networks","Keywords: Deep weight space, Graph neural networks, Transformers, Permutation equivariance, Implicit neural representations, Networks for networks, Neural graphs","While probe features improve performance, they are giving privileged information that is not quite in the same learning regime as other related works, which only take in parameters. With enough probe features, you are essentially inputting the original MNIST image into your neural network.
Many claims of invariance or equivariance to permutation symmetries, without any proofs.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Graph Neural Networks for Learning Equivariant Representations of Neural Networks","Keywords: Deep weight space, Graph neural networks, Transformers, Permutation equivariance, Implicit neural representations, Networks for networks, Neural graphs","The CNN graph construction is effective but feels quite hacky. To use the method, the user must first specify a maximum kernel size. While this is unlikely to be a problem in practice, because the kernel size of modern CNNs does not vary much, it is not obvious how to extend this to other network layers that exhibit parameter sharing. For example, attention layers share parameters over sequence length which may vary significantly more than kernel size. Moreover, other standard building blocks like normalization layers are not covered in this work and there is no clear recipe provided for designing the corresponding neural graph representations.
There is little theoretical justification for the proposed approach. Prior work proves the expressivity of their methods alongside their group equivariance properties. Neither of these are explored formally in this work.
I consider the empirical results to be quite complete, but an ablation of the various design decisions introduced would be valuable. For example, I'd like to better understand how much value the probe features, non-linearity identification, positional encoding, and other components contribute to the overall performance.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Graph Neural Networks for Learning Equivariant Representations of Neural Networks","Keywords: Deep weight space, Graph neural networks, Transformers, Permutation equivariance, Implicit neural representations, Networks for networks, Neural graphs","Despite considering new types of layers (e.g. residual connections) compared to the literature, other types of layers such as multi-head attention layers are still missing. Moreover, only the MLP and convolutional layers have been tested in the experiments. The paper could be improved a lot if it experimentally showed that the other types of proposed layers can also help improve the performance of their model. The paper also does not discuss the expressive power of their approach compared to the baselines, nor how difficult it is to scale their approach to very large neural networks/graphs.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations","Keywords: Adversarial attacks to graph classification; provable robustness","As an expert in the security domain with a strong background in signal processing, the paper looks more like building a classifier robust to noise rather than a defense method against adversarial attacks. When it comes to internet security applications, in order to add value, someone has to work on real case scenarios where the deception in building the graph can be realistic. Here, the benchmarks are very weak in terms of real-case scenarios. In cases like malware or DNS graphs, etc, the deception models have to be very sophisticated and realistic. I understand that this is more like an ML theory paper, but it really has no value in real life. Another problem that I have with this paper is the use of the term ""adversarial attack."" A malicious agent tries to minimize the perturbation so that the perturbed graph is as close as possible to the initial one. Either through a black or white box attack, the agent tries to reverse engineer the classifier so that a small perturbation can lead to a big change in the output; they might choose to change, let's say, one feature or connection that will have a big impact. I don't see that study here. Instead, the authors claim that we will make it robust to a certain type of noise.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations","Keywords: Adversarial attacks to graph classification; provable robustness","On Page 4, at the end of line 4: Shouldn't the notation be
H(.)
%
Ts+1
?
Based on my understnading
(Svt⨁Svj)≠(Svj⨁Svt)
. If that is correct, then it seems in structure division explained in 3.3.1 the same edge can have two different hash values depending on which end node is visited first. Can the authors clarify this?
The hashing process, while detailed, lacks clarity on one aspect: How are node features transformed into string representations for the hash function? Given the diverse nature of node features in graphs, understanding this process, especially for features requiring unique treatments, is essential.
Could the authors provide an intuitive explanation for the preference of hash-based subsampling over methods like
τ
fraction-based sampling (referenced in the benchmarks) or other similar techniques? What advantages does this approach offer and what are its potential limitations?
How do the authors determine the values for
Ts
and
Tf
? It would be beneficial if this determination were associated with specific graph properties (e.g., the number of edges, nodes, diameter, path length, clustering coefficient, etc.), as this would guide potential users of this defense strategy in tailoring it to their datasets.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations","Keywords: Adversarial attacks to graph classification; provable robustness","The paper fails to cite prior work on derandomized smoothing which is strikingly similar to GraphGuard. For example, Levine & Feizi (2020) designed a certifiably robust classifier that also splits the input into sub-parts, classifies the sub-parts using a base model, and makes the final classification using majority vote. While their method is applied to image classification to certify against patch attacks, the fundamental design pattern (and analysis) is similar to GraphGuard. More recently, Hammoudeh & Lowd (2023) showed that the same design pattern can be used to achieve certified robustness against L0 perturbations (including patch attacks) at training-time and test-time. Given this context, GraphGuard could be viewed as an extension of derandomized smoothing to a new domain (graphs), which could impact the assessment of technical novelty. Update 21/11: The authors have promised to address this issue. I have therefore raised my Presentation score from 1 to 3.
Although the experiments are comprehensive, I believe there is a crucial baseline missing: the base graph classifier (GIN) without GraphGuard. Specifically, I would like to see a comparison of standard accuracy for GIN trained normally on full graphs, and GraphGuard with GIN trained on sub-graphs. This would allow for an assessment of GraphGuard’s impact on accuracy. This is important, as the standard accuracy of GraphGuard is fairly low for most datasets (around 70% based on Fig. 2)—it’s not clear whether this is due to GraphGuard or the inherent difficulty of the datasets. Incidentally, it may be interesting to report the accuracy of the base classifiers for all certified methods. Levine & Feizi (2020) found much higher base classifier accuracies for derandomized smoothing (which is similar to GraphGuard) than randomized ablation (which is similar to Zhang et al., 2021b). The same explanation may apply here.
While GraphGuard outperforms prior methods in terms of certified accuracy, the standard accuracy is rather low (at around 70% for 6 of the 8 datasets). This has a bearing on the significance of the paper in my view, as the sacrifice in terms of accuracy seems to high to be practical. It’s also worth noting that the variant of GraphGuard that protects against structure and feature perturbations simultaneously suffers a severe accuracy drop for some of the datasets (DBLP and ENZYMES). For these datasets, the classifiers are no better than random based on the standard accuracy in Figs. 9 and 10.
Minor:
The idea of training the base classifier on sub-graphs is claimed to be a contribution. However this is standard practice in randomized smoothing. It would be unusual not to train in this way.
Section 4.2: should alpha be 0.001?
References:
Levine & Feizi, “(De)Randomized Smoothing for Certifiable Defense against Patch Attacks,” NeurIPS 2020. https://proceedings.neurips.cc/paper_files/paper/2020/file/47ce0875420b2dbacfc5535f94e68433-Paper.pdf
Hammoudeh & Lowd, “Feature Partition Aggregation: A Fast Certified Defense Against a Union of
ℓ0
Attacks,” AdvML-Frontiers 2023. https://openreview.net/forum?id=NX5Nxrz6PV","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning","Keywords: Multi-agent reinforcement learning, episodic control, episodic incentive, state embedding","Scalability: Based on the encoder-decoder architecture of the paper, I am assuming that the global state for the environments used is feature-based. It is unclear whether this method will scale to vision-based environments due to a) the memory requirements of storing many images, b) the optimization difficulty in reconstructing image-based states and c) the effectiveness of the introduced reward structure in high-dimensional state spaces. However, I acknowledge that many existing works in this area utilize feature-based observations. Regardless, it would greatly improve the strength of the results of this paper if some gains could be shown in vision-based environments.
Evaluation: It appears that random projection performs almost equivalently to EmbNet/dCAE when compared using test win rates. The introduction of a new metric (overall win-rate) highlights that EmbNet/dCAE enable faster/more sample-efficient learning. However, improvement on this new metric is not as significant as the original win rate (which is the standard benchmark in the community). I would be curious to see the curve for EMU with random projection added to Sections 4.1 and 4.2 to better understand the significance of EmbNet/dCAE.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning","Keywords: Multi-agent reinforcement learning, episodic control, episodic incentive, state embedding","The biggest weakness of this work at its current state is the limited scope of the literature review and the lack of comparison with existing methods for episodic memory. There are multiple works ([1-3] to name a few) that have created similar frameworks in single-agent settings, specially in exploration settings. So one wonders what prevents port these frameworks here? Without that for instance the embedding procedure of EMU could be a reinventing the wheel from existing procedures in [1,2]. I strongly encourage authors to visit that line of works and contrast those approaches with the features incorporated in EMU.
Moreover, I believe that the comparison with related work is imperative to understand the position of the paper and its contributions and should not be relegated to the appendix.
As a minor issue, writing also should be reviewed, but clarity in general is good
[1] Henaff, M., Raileanu, R., Jiang, M., & Rocktäschel, T. (2022). Exploration via elliptical episodic bonuses. Advances in Neural Information Processing Systems, 35, 37631-37646. [2] Le, H., Do, K., Nguyen, D., & Venkatesh, S. (2023). Intrinsic Motivation via Surprise Memory. arXiv preprint arXiv:2308.04836. [3] Fernandes, D. M., Kaushik, P., Shukla, H., & Surampudi, B. R. (2022). Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments.
---- Post Second Rebuttal ---
I want to thank the authors for the additional work to address the concerns, specially what you wrote in your last response from ""It seems that adding a surprise-based incentive can be"".... until ""For these reasons, incorporating the feature embedding structure from the single-RL domain and its learning framework into the multi-agent domain may necessitate extensive modification, resulting in a distinct line of research."" was the kind of motivation and comparison that I was looking for.
This, together with the results in Appendix D.13 makes clear that the existing methods from single agent literature is not as good as EMU in this context and that indeed it is a relevant contribution that authors are giving to the community.
My only remaining comment is that none of this new work and the discussion is present in the main document, (at least I don-t see anything in magenta there) I would encourage the authors to incorporate a reference in the introduction highlighting that existing methods in single agent reinforcement learning are not valid here (incorporating a reference to this part of the appendix),
I believe now that the paper is sound and there is enough evidence to support the main claims from the authors. I am updating my score accordingly.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning","Keywords: Multi-agent reinforcement learning, episodic control, episodic incentive, state embedding","EMU needs to set a return threshold to determine the desirability of a trajectory. This may require some domain knowledge to properly determine it, even when using R_{max}. This knowledge may partially explain its outperformance.
When the key encoder is updated, the proposed method needs to update all keys in the memory, which seems quite computationally intensive.
It may be interesting to compare the proposed method with MAPPO.","6: marginally above the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning","Keywords: Multi-agent reinforcement learning, episodic control, episodic incentive, state embedding","I have concerns about the desirable trajectory. In paper, the author set
Rthr=Rmax
. Since the desirable trajectories are the states that can achieve maximum returns, they must be the optimal states. What if the agents are impossible to achieve
Rmax
. How to determine
Rthr
in other environments?
The dimension of
x
is very small (i.e. 4 according to table 4 in the appendix). It's doubtful that it can reconstruct the global state.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs","Keywords: neural ODE, time-series forecasting, climate prediction, physics-informed ML","A couple of Figures (e.g Figure 5) would benefit from a longer caption/description
Not comparing against state-of-the-art methods, such as GraphCast
It should be compared against pre-trained ClimaX or other methods that don't require pre-training","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs","Keywords: neural ODE, time-series forecasting, climate prediction, physics-informed ML","For the model of FLOW VELOCITY (section 3.2), as we already know
v˙k(x,t)=u¨k(x,t)
, why we still need to parameterize it? Is it because the computation of
u¨k(x,t)
is too costly? There are also many methods that could approximate
u¨k(x,t)
based on
u˙k(x,t)
. More discussion or claims are encouraged.
The model treats the advection PDE as independent for each task or quantity. However, in the intricate tapestry of climate dynamics, various quantities are interdependent. For instance, wind patterns can influence temperature fluctuations. The paper doesn't clearly illustrate how the proposed method addresses these inherent inter-correlations.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs","Keywords: neural ODE, time-series forecasting, climate prediction, physics-informed ML","""Closed system assumption implies value-preserving manifold"" is unclear and needs more justification. While the conclusion that:
Ex[uk(x,t)]=const.
sounds intuitive, it's not justified rigourously. The expectation is taken with respect to which density? I would expect the quantity to be preserved would be
∫Ωuk(x,t)dV
, since that's the total quantity over the whole ""volume"" you're considering which should be preserved (e.g. when
uk=ρ
, the integral over the volume becomes the mass). In any case, since this is a Machine Learning submission, it would be better if this part is thoroughly justified.
Benchmark only up to 36 hours while state-of-the-art methods reported results for up to 10 days ahead. The paper would be better if it reported results for at least five or seven days ahead.
Authors mention that other deep learning methods lacked open-source code, while that's true for PanguWeather (who only provide a pseudo-code ""implementation""), it's not for the others:
FourCastNet: https://github.com/NVlabs/FourCastNet
GraphCast: https://github.com/google-deepmind/graphcast
Given that GraphCast seem to outperform ClimaX, it would have been good to compare against it as well and also FourCastNet since it's one of the first papers to perform weather forecasting on such a scale.
Authors claim that the vaue-preserving manifold (that emanates from the closed system assumption), presents a strong inductive bias for long-term forecasts, yet, using Euler scheme to solve the ODE is known to be unstable and it'll especially not conserve the quantity we want preserved, so that inductive bias is no longer enforced. It would be better to include that limitation in the paper and acknowledge that while it is a strong inductive bias, it's hard to enforce in practice. This is further seen from Table 2 which shows that the error does increase dramatically with lead time and that suggests that ClimODE is better at inferring the true physics but not in mitigating the error propagation in long-term forecasts.
While Figure 6 shows qualitatively the soundness of the predicted bias and variance, there's no quantitative approach that evaluates the quality of the bias and variance output by the model. A metric like CRPS (Continuous Ranked Probability Score) can showcase that.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs","Keywords: neural ODE, time-series forecasting, climate prediction, physics-informed ML","Limited Performance and Comparison: The proposed model, although surpasses vanilla Neural ODE and ClimaX, still cannot compete with IFS (ECMWF NWP), let alone bigger models such as FourCastNet and Pangu-Weather that have already reported better results than NWP. There lacks enough comparison to other models in general, such as Adaptive Fourier Neural Operator (practiced by FourcastNet), previous weather forecasting methods like [1, 2], even models for similar tasks such as spatio-temporal traffic forecasting or video forecasting, etc. Comparison to Neural ODE is more of an ablation study and ClimaX is a weak baseline marginally better than ResNet. Comparing only with ClimaX is definitely not convincing enough.
Limited Physical Complexity: The partial differential continuity equation is indeed a fundamental concept in fluid dynamics as it describes how quantities such as mass, moisture, or energy are transported and conserved in the atmosphere over time and space. What makes it less predictive in the real world is that this equation comes with assumptions such as the homogeneity and isotropy of the fluid. In cases where these assumptions are violated, the equation might not hold perfectly. I am not certain whether relying too much on this physical equation would be optimal for modeling the complex dynamics of weather, especially in finer-granular resolution with more weather factors and potentially larger noises.
Limited Physical Understanding: In all, the partial differential continuity equation is a general-form conservation equation rather than any specific equations explaining each weather factor. Other than that, because neural ODE is essentially still a black-box model due to using neural network, it remains hard to know, for example, the relationships and the interactions between different weather variables.
[1] Yan Han, Lihua Mi, Lian Shen, CS Cai, Yuchen Liu, Kai Li, and Guoji Xu. A short-term wind speed prediction method utilizing novel hybrid deep learning algorithms to correct numerical weather forecasting. Applied Energy, 312:118777, 2022. [2] Xiaoying Yang, Shuai Yang, Mou Leong Tan, Hengyang Pan, Hongliang Zhang, Guoqing Wang, Ruimin He, and Zimeng Wang. Correcting the bias of daily satellite precipitation estimates in tropical regions using deep neural network. Journal of Hydrology, 608:127656, 2022.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space","Keywords: Tabular data, tabular generation, diffusion models","The motivation behind using latent diffusion for tabular data generation is not thoroughly discussed in the paper, and the model design does not effectively exploit the characteristics of tabular data.
The VAE decoder design is tailored specifically for either numerical or categorical features, which limits its applicability in a wider range of tabular data scenarios, such as datasets containing a mixture of both numerical and categorical features.","5: marginally below the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space","Keywords: Tabular data, tabular generation, diffusion models","The method's efficacy is contingent upon a well-trained VAE. It would be beneficial to compare the outcomes between optimally and sub-optimally trained VAEs, providing insights into worst-case vs. best-case scenarios.
Given the generative capability of VAEs, it would be insightful to see results from data generated solely by the VAE used in this study. The distinction between the paper's transformer-based VAE and TVAE warrants further exploration to determine the independent efficacy of the former.
While adjusting default hyperparameters for a fair comparison is commendable, understanding performance under default settings across consistent training epochs would give a fuller picture. This would ascertain whether hyperparameter enlargement (as done for CTGAN and CoDi) equally benefits the models or favors the presented method disproportionately.
The discrepancy observed where TabDDPM struggles with the News dataset (poor performance in Table 1), yet exhibits a low error rate in Table 2 seems unintuitive. Additionally, given TabDDPM's consistent second-place ranking, except for the News dataset, its fourth-place average rank seems unfair. An alternative could be per-dataset ranking or reporting modal / averaged ranks.
Given that the News dataset is primarily of numeric nature, it seems counterintuitive that TabDDPM, a diffusion based model would underperform on this dataset. It would be beneficial to understand the authors' rationale behind the model's inability to generate meaningful content for this dataset.
The deployment of MLE as a metric for privacy is unconventional. Traditionally, MLE assesses the synthetic data's task-performance equivalence to real data, not privacy leakage. It would be enriching if the authors could shed light on this choice.
Overall, this paper stands out for its meticulous code, articulate presentation, and thorough analysis. I commend the authors for their contribution.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space","Keywords: Tabular data, tabular generation, diffusion models","Model itself seems to be pretty much the same as Vahdat 2021, except that in that paper authors used only images, whereas now tokenization is needed to use the same model. I would like authors to comment on this, and it would really help the paper to be very clear in the Introduction that where the technical novelty lies.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space","Keywords: Tabular data, tabular generation, diffusion models","The scientific contribution is mostly incremental and expected
The authors claim that no ""unified and comprehensive evaluation"" exists for tabular data synthesis. To my opinion, one weakness of this paper is indeed that it feeds this lack of a unified benchmark by proposing another new benchmark with new metrics that are not used in other papers. Sticking a bit more to previous paper's metrics and datasets could improve that point.
given the size of the appendix, one is surprised to see that no simple baselines like Bayesian Networks or SMOTE are provided in the experiments. SMOTE is known to be a competitive baseline for ""target-conditional"" data generation.
No privacy preservation metrics (like DCR) are provided. No detection test metric (like C2ST) is provided
The absence of hyper-parameters tuning in the benchmark is both laudable and questionable as it may hinder some of the other models (a fair option could be to report the total training time with a fixed budget).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement","Keywords: language model, natural language processing, inductive reasoning","My concern mainly lies in Section 4:
For the example perturbation experiment in section 4.2, there are no studies on how well humans can actually perform on perturbed tasks. It is hard to judge how big the performance drop of LMs is compared with humans.
Experiments in 4.1 and 4.2 are conducted with simple prompting which may not be the most effective method to elicit this type of reasoning from the model.
The generalizability of the findings in 4.3 is doubtful because only one type of prompt is used to generate rules from LM. According to the appendix, example rules on List Fn and MiniARC are generated from LM with a prompt that contains no format instruction. It is unknown whether LMs can generate human-like inductions with more guidance or provided with human-induced rules as few shot examples.
Overall, I believe the main contribution of the paper is an effective inductive reasoning pipeline using LMs. So these are not significant flaws of the paper. So I still recommend acceptance. However, I strongly encourage authors to provide more rigorous evidence when making claims in Section 4.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement","Keywords: language model, natural language processing, inductive reasoning","A few of the experiment setups feel a bit contrived - for example, randomly perturbing a set of items in a small set of experiments, of course, makes the task harder for a language model since it also requires it to infer that the noise is noise and not itself a deterministic part of the rule. The section on familiarity of exemplars should also likely mention Dasgupta et al.'s ""Language models show human-like content effects"" there.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement","Keywords: language model, natural language processing, inductive reasoning","An analysis of the complexity of the rules used to generate the data would be interesting. Comparing the complexity of the hypothesis across tasks and domains might give some insight into the model performance.
Similarly, the complexity of the human induced and LLM induced rules might be interesting to analyze.
How were the number of examples seen by the model chosen across domains? What is the minimum number of examples needed to learn a rule?
An open source model would make the evaluations more comprehensive.
A separate evaluation for LLMs as symbolic interpreters of rules would help tease apart the rule-proposing / application componenets more. More on complexity: LMs might be bad appliers of complex rules.
Can LLMs apply rules induced by humans?
Is there a change in the types of rules induced if the prompt is changed to encourage communication (since this was what humans seemed to do)? Change prompt to emphasize communication?
MiniAC→MiniARC: 4.3 para1 line 3","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement","Keywords: language model, natural language processing, inductive reasoning","The results would be more informative if compared directly with human performance. Do any of these benchmarks contain human performance measures (e.g. I believe that there is already human behavioral data for miniSCAN in the original paper)?
The results on noisy rule induction are especially difficult to interpret without a human baseline. The authors cite a paper indicating that humans are somewhat robust to noise when inducing rules, but the amount of noise and the specific tasks will matter a lot.
Throughout the paper, the authors appeal to intuition concerning putative human performance on the benchmarks they consider (e.g. in considering the potential for human reasoners to show a discrepancy between hypothesis generation and rule application), but intuition is not always a reliable guide regarding human performance. It would be good to qualify these statements a bit more (or, to the extent possible, to include a direct comparison with human performance).
The 'task accuracy' measure seems designed to emphasize the consistency of the symbolic rule application. When looking at raw accuracy, the differences between symbolic and LLM rule application don't look nearly as large. I think this somewhat undermines the claim that their rule application abilities are so much worse than their hypothesis generation abilities.
It should be emphasized more that miniARC, unlike the other tasks, is a distinctly visual task, in that it requires understanding visual concepts like 'objectness'. It is somewhat unsurprising that a text-only model would show special difficulty on such a task.
Do the authors have any explanation for why the hypothesis refinement approach achieves worse performance on miniARC relative to the baselines? Given the visual nature of the task, it's not surprising that it doesn't help much, but I was surprised that it actually seems to impair performance.
The familiarity analysis seems to confound two very different issues: 1) The presence of the same exact problems in the LLM pretraining data (a significant possibility, given the use of pre-existing datasets), and 2) the use of familiar vs. unfamiliar words (e.g. pseudowords). I think it's important to dissociate these concerns. This can be done by creating a new dataset with similar properties, e.g. by replacing the specific pseudowords and colors in miniSCAN (but maintaining the same general pseudoword -> color structure).
Is the interaction between iid vs. ood and IO vs. hypothesis refinement (figure 2) statistically significant? Also, the text describes the hypothesis refinement results as demonstrating superior robustness to this ood setting, but for miniARC the ood accuracy is actually higher for the IO baseline (even though the difference between iid and ood performance is larger for IO). This should be clarified in the text.
Were the language model and human hypotheses systematically compared in any way, or only qualitatively inspected? Did the strength of the language model hypotheses correspond to performance on the task? Were there cases where the model performed well on the task despite providing unhuman-like hypotheses?
Minor comments:
What setting was used for the 'top p' parameter in GPT-4?
It would be helpful to either include the variable names in figure 1, or to have a separate figure illustrating the overall flow of the model with the corresponding variable names.
It would be good to say a bit more about how this work differs from Wang et al (2023). This is concurrent work, so there is no concern about novelty, but it would still be useful to have more discussion of the relationship.
I found the description of the approach somewhat confusing. Based on the abstract and intro, I was expecting that the hypotheses would be articulated in natural language, and this would somehow be translated into code which is then symbolically executed. It is explained later on (in section 2.2) that the LM also carries out this translation step for list functions and miniARC, but it would be good to provide some hint that this is the case earlier in the section describing the approach. My understanding is that for the other tasks, the LM is prompted so as to ensure hypotheses in a particular format, which can then be automatically parsed, is that correct? It would be helpful to clarify this (in section 2 it says that the hypotheses are 'constrained', but it's not immediately clear what that means).
I found this sentence, 'However, they also behave as puzzling inductive reasoners, showing notable performance gaps in rule induction (i.e., identifying plausible rules)…' to be confusing, because it seems to say that LLMs are bad at proposing rules, even though it was just stated that they are good at this. This also seems misaligned with the results. It seems like this sentence should instead emphasize the rule application specifically (though, as mentioned above, it's not clear how significant this discrepancy really is).
The authors might consider citing this related work on analogical reasoning (a special case of inductive reasoning) in LLMs: Webb, T., Holyoak, K. J., & Lu, H. (2023). Emergent analogical reasoning in large language models. Nature Human Behaviour.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness","Keywords: Graph Neural Networks, Expressive Power, Homomorphism, Subgraph Counting, Weisfeiler-Lehman","it's better to have more examples of different kinds of substructures in Theorem 3.3 (and how they are different from each other).
Missing discussion on some previous works: there are many papers proposed to count substructures, and it is not clear how your result is related to them.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness","Keywords: Graph Neural Networks, Expressive Power, Homomorphism, Subgraph Counting, Weisfeiler-Lehman","The presentation is quite dense. It might be beneficial to push Subsection 3.3. to the appendix and expand on the other parts.
The experimental study on real-world datasets is quite limited. It would be nice to see a more refined analysis, e.g., analyzing subgraph occurrences and see if an architecture's performance is correlated to its ability to count different subgraphs.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness","Keywords: Graph Neural Networks, Expressive Power, Homomorphism, Subgraph Counting, Weisfeiler-Lehman","I cannot see any major weakness but have one potential minor weakness for the authors:
Although the authors claim that the proposed framework can quantitatively analyze the expressive power of different GNN variants based on the NED, the authors didn’t characterize the exact number of NED that exists for each NED class (share-point/strong/near strong/general NED). Thus, it is still hard to see the quantitative expressive gap between each GNN variant. I understand the exact number could be hard to count but It would be excellent if the authors could at least give a rough scale for each NED class.
I also have a few questions/thoughts in mind when reading the paper. Please see the question section for the details.","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness","Keywords: Graph Neural Networks, Expressive Power, Homomorphism, Subgraph Counting, Weisfeiler-Lehman","There seems to be a technical issue with the definition of homomorphism expressivity (Definition 3.1). I believe it can be solved, but requires addressing or further clarification. Specifically,
FM
is not necessarily defined for all models
M
since it does not take into account graphs
F
for which there exist graphs
G
and
H
with equal homomorphism counts with respect to
F
but different representations according to
M
. Homomorphism expressivity of
M
is defined only if no such
F
exists since it cannot be within
FM
and also cannot be outside
FM
. For example, homomorphism expressivity is not defined for a universal architecture as it can assign different representations to any two non-isomorphic graphs.
Is it the case that for the GNNs considered
FM
is always well-defined? This seems to be indicated by Theorem 3.3 and the subsequent discussion, however, it is not clear enough. I strongly recommend elaborating upon this point near the definition to avoid confusion.
Homomorphism expressivity is referred throughout as a “complete” measure. Given that it is not defined for all architectures
M
, I believe this terminology can be misleading.
Homomorphism expressivity suffers from a limitation that also exists in the WL framework: it disregards features of vertices/edges. The proposed expressivity measure takes into account only the ability to capture graph structures, assuming each vertex is associated with a unique discrete label. While identifying graph structure is indeed important, in many cases the features of vertices play an equal, if not more important role (see, e.g., [1]). I do not believe this significantly harms the quality of the current paper, and is perhaps a consideration for future work, but to me referring to homomorphism expressivity as a “complete” measure may require some hedging.
[1] Liu, Renming, et al. ""Towards a Taxonomy of Graph Learning Datasets."" arXiv preprint arXiv:2110.14809 (2021).","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts","Keywords: large language models, large multimodal models, mathematical reasoning, vision-language reasoning, foundation models and their evaluations","The results have been completely superseded by GPT-4 Vision, which together with GPT-4 are SotA in vision-language models.
The methods have been superseded by recent prompting methods.
The related work and references are lacking:
a. Prompting:
Phenomenal yet puzzling: Testing inductive reasoning capabilities of language models with hypothesis refinement L. Qiu, L. Jiang, X. Lu, M. Sclar, V. Pyatkin, C. Bhagavatula, B. Wang, Y. Kim, Y. Choi, N. Dziri, X. Ren, 2023.
Hypothesis search: Inductive reasoning with language models, R. Wang, E. Zelikman, G. Poesia, Y. Pu, N. Haber, N. D. Goodman, 2023.
Large language model (LLM) as a system of multiple expert agents: An approach to solve the abstraction and reasoning corpus (ARC) Challenge, J. T. Min, M. Motani, 2023.
b. GPT-4V:
Lost in translation: When GPT-4V(ision) can’t see eye to eye with text, a vision-language-consistency analysis of VLLMs and beyond, X. Zhang, S. Li, Z. Wu, N. Shi, 2023.
c. PoT: Solving Linear Algebra by program synthesis, I. Drori, N. Verma, November 2021. Solving Probability and Statistics problems by probabilistic program synthesis at human level and predicting solvability L. Tang, E. Ke, N. Singh, B. Feng, D. Austin, N. Verma, I. Drori, AIED, 2022. A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level I. Drori, S. Zhang, R. Shuttleworth, L. Tang, A. Lu, E. Ke, K. Liu, L. Chen, S. Tran, N. Cheng, R. Wang, N. Singh, T. L. Patti, J. Lynch, A. Shporer, N. Verma, E. Wu, G. Strang, PNAS, 2022.
The paper lacks a comprehensive discussion of the limitations of the benchmark.
The work is missing an analysis of why specific models perform better than others.
I expect the author response to include GPT-4 Vision results, missing related work and references, and updated methods.","5: marginally below the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts","Keywords: large language models, large multimodal models, mathematical reasoning, vision-language reasoning, foundation models and their evaluations","For data collection of the 3 new datasets, it is not clear if inter-annotation consistency checks were conducted and how the mentioned ""rigorous review process"" was conducted (details are missing).
Few-shot performance is computed only for LLMs and not LMMs. Given LMMs such as Multimodal-Bard, Flamingo/Open-Flamingo and mPLUG-Owl also support few-shot learning, these can also be evaluated few-shot to better evaluate the benchmark challenges.
Further, LLMs can also be evaluated on a broader range of K-shot settings (currently only 2-shot is evaluated). Evaluation over {2,4,8,16,32} could provide better evidence of whether mathematical reasoning capabilities can be learned in a few-shot manner.
Relatively minor:
Benchmark is relatively small (6141 examples) and meant as an evaluation benchmark primarily drawn from existing datasets (5405 examples) with no finetuning subset which could be useful for improving mathematical reasoning capabilities of current models.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts","Keywords: large language models, large multimodal models, mathematical reasoning, vision-language reasoning, foundation models and their evaluations","How to disentangle the visual understanding ability or text understanding ability with the math reasoning ability? For example, if a model incorrectly answers “how many cars are to the left of the tree”, it could be the error in spatial understanding (failing to find the cars on the left), or error in counting, or the model cannot understand this question. In the current form of the dataset, there is no disentangled evaluation of the visual/text understanding versus math reasoning. A possible way to address this questions could be having the annotations for rationales (results of intermediate reasoning steps or sub-questions), and evaluate the model’s performance against the intermediate steps.
Why is the human accuracy only 60.3% on the dataset? Does this suggest that the dataset is noisy, containing ambiguous/uncertain cases, or simply the task is very difficult thus humans are not good at it as well? An analysis on the 40% of the data where humans cannot answer correctly will be preferred.
While it is good that the paper defines 7 types of fine-grained reasoning ability, what are the take-away messages (of Tab-2) that can be derived with the differences in the 7 types? It would be nice if the expertise of different models can be reflected using the fine-grained types, besides that Bard is the best model
Results of GPT-4V? I understand that the model is not released by the submission deadline, but it would be good to have the results in later versions.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts","Keywords: large language models, large multimodal models, mathematical reasoning, vision-language reasoning, foundation models and their evaluations","W1. A potential downside of the chosen tasks is that they ""amalgamate"" mathematical and visual reasoning (as stated in the abstract). This does not seem desirable since one would usually also wants to understand the capabilities of a model for these two steps (visual understanding and reasoning) independently. The argument that there exists other benchmarks that do look at these individual capabilities means that this is however not a critical issue.
W2. The low human performance on the benchmark (~60% accuracy) is concerning. Could this indicate an issue with data quality of annotation noise? (rather than intrinsic task difficulty)","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Protein Discovery with Discrete Walk-Jump Sampling","Keywords: generative modeling, langevin mcmc, energy-based models, score-based models, protein design, protein discovery","(-) Only a single task (antibody design) is evaluated. Testing on other protein classes or discrete domains would be useful.
(-) The distributional conformity score for evaluation is introduced late with little detail. More motivation and analysis would improve clarity. Certain details are unclear, like how sequences are aligned and handled.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Protein Discovery with Discrete Walk-Jump Sampling","Keywords: generative modeling, langevin mcmc, energy-based models, score-based models, protein design, protein discovery","While the paper touts the simplification to a single hyperparameter choice (noise level, σ) as a strength, it might also be seen as a limitation since the entire model's performance could be sensitive to this single parameter.
Set of properties includes both continuous, binary, and discrete values and estimating the distribution by a kernel density approach may not be very effective. Also DCS may be overly influenced by outliers and extreme data points in the dataset.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Protein Discovery with Discrete Walk-Jump Sampling","Keywords: generative modeling, langevin mcmc, energy-based models, score-based models, protein design, protein discovery","Some of the comparisons to autoregressive language models (LMs) were a bit under-developed. For example, the paper mentions fast mixing sampling, but this is trivial for LMs. Second, LMs provide a natural way to condition on metadata; how would the current model do that? Finally, claims that LM sampling is expensive in terms of compute aren't that compelling, since for these antibody design applications the wet-lab experiments are orders of magnitude more expensive than the compute to generate the library.
The 'distributional conformity scores' (DCS) section was interesting and cool, but not central to the paper and felt like a way to add extra math into the paper. Please clarify: was this used to filter any of the samples for the wet-lab experiments or was it only used to provide the rightmost column in Table 2? Given that your proposed does not have strong DCS scores compared to some other baselines, how should I be interpreting these results? Overall, I would recommend removing the DCS content and allocating more space in the main paper to details/derivations of the model fitting/sampling.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis","Keywords: Program Synthesis, Programming By Example, Generalization, Compositional Generalization","The two datasets are small domain-specific tasks, thus the evaluation does not really show the promise of scalability, which is the original motivation.
I/O-based specifications are not easy to construct -- both intermediate states and output states may vary significantly from the initial given I/O examples. For instance, intermediate states may involve auxiliary temporary variables, and the output states may have to be adjusted according to the actual application domains.
Both DSLs seem simple straight-line code, and there are no recursion, loops, or if-else conditions, all of which are important components to construct a realistic large program.
Creating a good training dataset for decomposition tasks can be very challenging. Particularly, there are many valid solutions, which may have quite different intermediate sub-goals. Supervising only one specific solution would be problematic.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis","Keywords: Program Synthesis, Programming By Example, Generalization, Compositional Generalization","In the intro there's a mention of how compositional generalization ""has not previously been studied in the context of programming by example"" and later in the related work a mention of how there's ""less work on systematic generalization for machine learning for code, although Bieber et al. (2020) studies length generalization""
While both systematic generalization and specifically compositional generalization are understudied in program synthesis, there are a few other citations that apply to each of these places.
First, the DeepCoder paper (Balog 2017) actually evaluates on length generalization (section 5.2 of that paper).
Nye et al 2021 (""Representing Partial Programs with Blended Abstract Semantics"") has some compositional generalization evaluation as well, such as the excerpt from section 5.1 ""Tower objects seen during training were composed in previously unseen ways...""
Ellis et al 2019 Program Synthesis in a REPL (already cited here) also applies for length generalization, eg the line from 4.2 ""Although it was trained on programs whose maximum length was 30 actions and average length approximately 8 actions, during test time we regularly achieved programs with 40 actions or more""
Just adding those citations in the appropriate places would strengthen this. To be clear, ExeDec's formalization of generalization and range of types of generalization go far beyond any of this prior work, but it's important to acknowledge that there have been some explorations of some of these kinds of generalization in the past.
Aside from this point, I think the related work citations are quite thorough and well done
How often are proposed subgoals actually achieved? Are they achieved more along a successful synthesis path than an unsuccessful one, on average? Some quantitative insights into these sorts of questions would strengthen the paper.
The results are decent but not extremely strong – in my opinion they're good enough but of course stronger results would help.
The idea mentioning in the Limitations section of how subgoals that are not just line-by-line but which could instead correspond to more than one line is one that immediately came to mind. Of course, fully generally doing that kind of generic hierarchical decomposition of a problem into subproblems is something of a holy grail in synthesis, and I think that this fairly limited form of subproblem is a reasonable step, so this is not a huge weakness.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis","Keywords: Program Synthesis, Programming By Example, Generalization, Compositional Generalization","The main limitations are that the method requires supervision for the sub-goals and that the experiments are limited to synthetic programs, as acknowledged by the authors in the limitations section. I can see that an unsupervised approach to predicting subgoals constitutes its own paper, but I think it'd still be interesting to see how the method fares with different decompositions. For example, picking
n
lines per subprogram, or randomly grouping multiple lines into a subprogram.
The experiments cover both the training from scratch scenario and a pre-trained LLM. The middle ground of finetuning a pre-trained LLM would be interesting to see. Here the same LLM could be used for the different models via different prompts (similar to the few-shot setting) and trained like the from-scratch setting. Since the benchmark intends to measure generalization and considering the importance of pre-training on the generalization performance, I believe this is an important additional experiment.
ExeDec requires subgoals which are essentially execution traces as supervision. It'd be interesting to see how the Transformer baseline performs when it also has access to them (for example by inserting the variable values after/before each program line). This baseline would further clarify the importance of training with intermediate program states versus decomposing the program into parts that are individually generated.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis","Keywords: Program Synthesis, Programming By Example, Generalization, Compositional Generalization","The benchmark introduced in Sections 2 and 3 is claimed as a novel contribution (""we introduce a new meta-benchmark for measuring the compositional generalization abilities of program synthesizers.""). However, it is very hard to tell from these descriptions the actual contents and novelty of the benchmark. I was ultimately able to get a better understanding from reading the evaluation and Appendix B, but in isolation the clarity of these sections are very low.
The implications of the loop in Algorithm 1 are not sufficiently discussed:
What happens if the loop never terminates?
What is the comparison in FLOPs between the ExeDec models and the baseline models (including the beam search, etc)? Even if the parameter count is the same, the loop in ExeDec could give these models significantly more power than the Transformer / Latent Programmer baselines.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Batched Low-Rank Adaptation of Foundation Models","Keywords: LLM Adaptation, Low-rank, Code Generation","The approach requires re-adapting the models that have already been adapted with LORA to leverage the improvements. There is a breaking point where FLORA doesn't improve over LORA effectively. Intuitively, there is at least 4 factors for this: the model, the gpu architecture, the rank of the adaptation and the batch size . The rank is taken into account but it is not very clear how the other elements will come into play in practice. Eq 7 claims only important factors are the dimension of the multiplication the constants for MM and BMM and the rank. However, it is difficult to understand why this should be the case for batch size 1 in contrast to a larger batch size. Computing some plots in this area would have been very helpful to grasp how the theoretical analysis transfer to the practical scenarios.. Another example of this would be computing per token and example adapters , which is the extreme case. It would have been interesting for latency and throughput curves to see such an extreme case, even though there is no such a real task. The section 3.1 is confusing in its current form and a rewrite paying attention to the Matrix and elementwise operations would improve readability. Given the constrains of the approach regarding the low-rank dimension, the applicability of the approach is limited to some specific scenarios which could have already been taken care on the base LLM pretraining. For instance, for the multilingual case the models could have already specific sparsely activated components given the language category or the programing language from the beginning.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Batched Low-Rank Adaptation of Foundation Models","Keywords: LLM Adaptation, Low-rank, Code Generation","I don’t find major weaknesses. Minor comments are indicated in the following section.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Batched Low-Rank Adaptation of Foundation Models","Keywords: LLM Adaptation, Low-rank, Code Generation","If each example in a minibatch has its own adapters, the overall performance is expected to overcome LoRA, however, it's almost the same as LoRA. So the ""performance bottleneck in scenarios requiring personalized, task-specific adaptations for each incoming request"" isn't largely solved.
The whole mechanism and the algorithm isn't mentioned clearly. e.g., how to choose the batch size for real situations, how to make each example corresponding to its appropriate adapters during inference. The paper over-concentrates on Fomulation and Computational Efficiency, while the high-level algorithm--the whole process is not quite clear.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Batched Low-Rank Adaptation of Foundation Models","Keywords: LLM Adaptation, Low-rank, Code Generation","Some parts of the paper are not clear (see comments below).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Improved Active Learning via Dependent Leverage Score Sampling","Keywords: leverage score sampling, active learning, polynomial regression, differential equations, pivotal sampling","My main concerns are stated below and are related with the technical novelty of the results of the analysis of Theorems~1.1 and 1.2. The experimental section is sufficient for the demonstration of the approach, yet it could be elaborated to the higher-dimensional problems.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Improved Active Learning via Dependent Leverage Score Sampling","Keywords: leverage score sampling, active learning, polynomial regression, differential equations, pivotal sampling","— The empirical evaluation lacks clarity regarding the improvements. The authors should explicitly state the claimed 50% reduction in samples in the technical sections.
— The theoretical improvements are solely for polynomial regression, which is essentially linear regression with an infinite number of rows. It would be interesting to explore whether the pivotal sampling method has other implications for different norms. For instance, can this ""tournament"" style technique be applied to all norms and their respective optimal sampling strategies?
— The selection of the tree in Algorithm 1 significantly impacts the performance of the sampling method. If the running time is a major concern in large-scale systems or datasets, it isn’t clear if a PCA-based approach is always feasible.","n/A","6: marginally above the acceptance threshold"
"Improved Active Learning via Dependent Leverage Score Sampling","Keywords: leverage score sampling, active learning, polynomial regression, differential equations, pivotal sampling","a. My primary concern pertains to the computational complexity of the proposed method. The paper lacks both theoretical analysis and empirical results in this regard, leaving an important aspect unaddressed.
b. The experimental setup in the paper includes only a single baseline, and it would be beneficial to include additional baseline methods, such as maximum leverage score sampling.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Improved Active Learning via Dependent Leverage Score Sampling","Keywords: leverage score sampling, active learning, polynomial regression, differential equations, pivotal sampling","The presented analysis does not provide justification for the improved empirical effectiveness of the method (besides for
ℓ2
polynomial regression). So, it is not clear theoretically why the method performs much better than independent leverage score sampling. Nevertheless, this is a limitation that the authors clearly concede and mention a few times throughout.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Improved Active Learning via Dependent Leverage Score Sampling","Keywords: leverage score sampling, active learning, polynomial regression, differential equations, pivotal sampling","As noted in the strengths part, the techniques in this paper are not very novel. To get their first
dlog⁡d+d/ϵ
sample complexity for active regression, they mainly utilize [KKS22]. The approximate matrix product result requires a bit more work, but it's also standard and not surprising. For the second result regarding polynomial regression, it also mainly follows procedures from [KKP17]. Nevertheless, I still think these results are nice, and are interesting enough to be published in conferences like ICLR.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs","Keywords: Large Language Model, Efficient Inference, Generative Inference, Key-Value Cache","The paper could benefit from presenting actual GPU inference performance results using FastGen and comparing them with other compression methods. Additionally, providing a runtime breakdown would offer more insights into the overhead caused by the profiling, compression, and decompression processes.
It would be nice to look into the structure of KV in the multi-query attention design.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs","Keywords: Large Language Model, Efficient Inference, Generative Inference, Key-Value Cache","Based on my understanding, the proposed algorithm specializes in the most classic softmax-based attention. Is it possible to include a small section discussing the limitations of the proposed algorithm for more complicated attention mechanisms and some preliminary ideas about supporting those mechanisms in the future?
Given the scale of the benchmarked model (llama-70B fp16 on A100-80G), I guess there is a missing detail about the parallel strategies applied in the experiments.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs","Keywords: Large Language Model, Efficient Inference, Generative Inference, Key-Value Cache","Although, the idea of adaptive KV cache compression sounds interesting, what is the overhead of book-keeping to support this adaptive and diverse ability based on the type of the attention? This is not discussed anywhere in the paper?
That is, each layer id will be mapped to a eviction policy and is deployed with the model at hand.
Next, what is the added computational complexity both asymptotically as well experimentally.
Table 3 shows an ablation on the policy order, why is this needed? Is the policy fixed per layer and the order will be dictated by the layer that needs a certain policy determined by the diagnosis step. Is it not true, clarify on this please.
Another interesting exploration/ablation to see is to experiment with long context tasks. What if the downstream task requires a long context window then what can be the best set of eviction strategies and the corresponding expected win rates?
Minor comments:
""The resulting distribution is visualized in Figure As in Figure 3."" can be rewritten as "" Figure 3 shows the resulting distribution""
A minor nit, the paper has too much forward referencing, which disturbs the flow of reading and attention, general recommendation in research papers is to avoid such referencing..!
Better to define the new terms such as win-rate, KV cache budget, etc. when they were introduced for the first time. Similar applies to abbreviations when they are introduced first time, expand them, for the sack of saving readers time to search internet.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs","Keywords: Large Language Model, Efficient Inference, Generative Inference, Key-Value Cache","Weaknesses:
The compression policies are combined in a naive way. More advanced adaptive selection could be explored (see detailed in C1).
No experiment on encoder-decoder models. The efficacy on them is unclear (see detailed in C2).
More analysis on the overhead of profiling could be provided (see detailed in C3).","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs","Keywords: Large Language Model, Efficient Inference, Generative Inference, Key-Value Cache","The model profiling part is not clear. Did the authors do a profiling for each model on all datasets, or each model on a single dataset.
The model profiling results have a huge impact on the final KV cache compression results. Although the authors show empirical data supporting the structure of the attention map is stable at different positions for all attention heads, the authors still need to discuss what if the structure of the attention map is not stable.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs","Keywords: Large Language Model, Efficient Inference, Generative Inference, Key-Value Cache","Since the inference time matters in practical serving, it would be helpful to understand more if the authors can provide corresponding results
For example, how long does inference take compared to the full-cache strategy? I think it might become slower because the existing attention kernels may not efficiently deal with the sparsity
How long does profiling take? Is it feasible for practical inference scenarios?
It seems that the StreamingLLM paper [1] is similar to this work. It sets sink tokens and performs local attention, where the sink tokens may correspond to
Cspecial
(and maybe
Cpunct
. Since the StreamingLLM paper has also recently been uploaded, it is unlikely to compare this paper with it. But it would be better if the differences in this paper were clarified.
[1] Xiao, Guangxuan, et al. ""Efficient Streaming Language Models with Attention Sinks."" arXiv preprint arXiv:2309.17453 (2023).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"One-shot Empirical Privacy Estimation for Federated Learning","Keywords: differential privacy, federated learning, empirical privacy","The example analyzed in Table 1 assumes a high dimension as well as a large number of canaries, which is not particularly realistic. The authors should provide similar analysis for lower values of d and k. Similarly, in the experiments conducted the number of canaries used is quite large, which is likely to have an impact on the model utility. Thus, the authors should also reports the accuracy obtained for the model. In contrast, the values of epsilon used are very high and additional experiments should be performed with values of epsilon such as 0.1, 1, 5 and 10. Finally, experiments with a varying number of clients should also be conducted.
The difference between user-level and example-level differential privacy should be discussed and defined more clearly within the context of federated learning. For instance, how would the attack framework be impact by the change of definition, in particular with respect to the guarantees measured.
A small typo : -« the choice gives » -> « this choice gives »","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"One-shot Empirical Privacy Estimation for Federated Learning","Keywords: differential privacy, federated learning, empirical privacy","Using canary clients seems more inefficient compared to using canary examples. More resource allocation might be needed.
In the paper it is suggested that ""In production settings, a simple and effective strategy would be to designate a small fraction of real clients to have their model updates replaced with the canary update whenever they participate."" but this would destroy the representation of such clients and problematic, especially, in data heterogenous settings. It would also result in fairness problems.
It is hard to interpret the provided empirical comparison with CANIFE. Other than the assumptions for CANIFE, it is not clear to me how this method is better.
The authors claim that their method is agnostic to architecture knowledge, but aren't the
cj
are of same dimension as the architecture? Hence would not designing such canaries would require architecture knowledge?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"One-shot Empirical Privacy Estimation for Federated Learning","Keywords: differential privacy, federated learning, empirical privacy","The analytical privacy bound doesn't seem like a good ""ground truth"" for the comparison with CANIFE, as the analytical bound is expected to be much larger than necessary. The best
ϵ
to return would be the upper bound that any membership inference attack could achieve, which is of course not known. It is possible that your method is simply overestimating the best
ϵ
, and is closer to the analytical because of that, and not because it is better at estimating the best
ϵ
than CANIFE. This does not seem a too remote of a possibility, as if your result was accurate, it would imply that CANIFE grossly underestimated the
ϵ
, and simply doesn't work in the setting.
A better ""ground truth"" would be an
ϵ
lower bound obtained from the TPR and FPR of some strong membership inference attack. It might be possible to use your method as this attack by thresholding the cosine test statistics
gi
, and estimating the TPRs and FPRs that different thresholds give empirically.
The proofs are missing some details, which makes them harder to understand and check than necessary. In the proof of Theorem 3.1, what is the value of the measure
Ad(θ)
, and how is it derived from the
(d−2)
measure of its boundary? In the proof of Theorem 3.2,
t
is not defined. You should also name the theorem that allows you to conclude convergence in distribution from pointwise convergence of the density function, and you should explicitly account for the fact that the density of
t
is 0 outside
[−d,d]
.
These two issues are the main reason for my score, and I will increase the score if they are addressed.
Regarding the challenge to come up with an attack that breaks your method, I can come up with two scenarios where this is likely to happen. The first is not using a cryptographically secure random number generator to generate the Gaussian noise, which would allow an attacker to remove the noise if they can break the insecure RNG. The second is an attack based on finite-precision issues with floating point numbers (see Mironov 2012 and Holohan and Braghin 2021), if the noise is not sampled with defenses against these in place. I don't think your method would detect these, as it is only looking at the noise as a real number, and detecting either scenario seems to require looking at the noise as a finite-precision float. Of course, your method is not designed to detect anything like these in the first place, and I don't think any of alternatives are either, so this is not a large limitation, but it should still be mentioned.
References:
N. Holohan, S. Braghin ""Secure random sampling in differential privacy"" Computer Security – ESORICS 2021
I. Mironov ""On significance of the least significant bits for differential privacy"" ACM Conference on Computer and Communications Security 2012
Minor comments:
The Anderson-Darling test should be cited.
The assumption that
n=o(d)
should be stated in Theorem 3.3, not just as a footnote.
Font size in Figures 1 and 2 are too small.
Table 6 would be much easier to read as a plot of the quantiles, which would also allow showing much more than 5 quantiles.
Specifying the exact CNN and LSTM architectures in the experiments would be good for reproducibility, as the code is not included in the submission.
Using \left and \right on the curly braces in Equation (1) would make the equation easier to read.
Comments on references:
Feldman et al. (2021) URL points to arXiv, not the conference submission
Capitalisation in some paper titles, for examples ""rényi"" in Feldman et al. (2023)
arXiv papers have inconsistent format, for example compare Maddock et al. (2022) and Pillutla et al. (2023)
Steinke (2022) is missing the publication forum
Zanella-Beguelin et al. (2022) and (2023) are the same paper","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"SWE-bench: Can Language Models Resolve Real-world Github Issues?","Keywords: Language models, Natural language processing, Software engineering","It seems that none of the models is doing well when the benchmark is used. It would be nice if the benchmark can be used to more clearly indicate where the problem in the language model lies. The results of the model evaluation e.g. difficulty correlates with context length or difficulty correlates with output length are expected and thus do not seem very interesting","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"SWE-bench: Can Language Models Resolve Real-world Github Issues?","Keywords: Language models, Natural language processing, Software engineering","Generating a patch file, and generating code, are two very different tasks. Existing models are pretrained on code, not patch files, so at least some of the poor performance could simply be due to the fact that the models are operating out of distribution on this data set. (The authors mention this issue in the paper.)","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"SWE-bench: Can Language Models Resolve Real-world Github Issues?","Keywords: Language models, Natural language processing, Software engineering","Although benchmark and LLM evaluation on it are valuable, the paper does not present any novel solutions to the task in the benchmark. This limits the contribution.
Please reorganize the paper so tables and figures are collocated with the text. Currently, it is hard to read when tables referenced out of order and explained very far from their location in the paper.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"SWE-bench: Can Language Models Resolve Real-world Github Issues?","Keywords: Language models, Natural language processing, Software engineering","Some of the comparison is not very fair. As Claude 2 is trained on data up to early 2023, GPT's knowledge cutoff is September 2021 and there is no specific time for Code Llama’s training data, evaluating these models on the dataset that contains instances before 2023 is not fair enough.
The contribution of SWE-Llama is not significant, especially for an AI conference. The paper could better target a software engineering/programming conference.
This method is mainly based on Code Llama while there is no comparison between Code Llama and SWE-Llama.
Some of the experimental analysis is not solid enough. For example, in the “Difficulty correlates with output length” (Section 5), Table 8 only presents all successfully applied patches, and does not show the correlation between difficulty and output length. The length of other patches needs to be taken into account.
There are a lot of work on automated bug fixing, including LLM-based ones and traditional ones. The authors could discuss and compare. For example: Jiang et al., Shaping Program Repair Space with Existing Patches and Similar Code, Proc. ISSTA 2018. D. Sobania, et al., An analysis of the automatic bug fixing performance of Chatgpt,arXiv:2301.08653, 2023.","5: marginally below the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models","Keywords: Large Language Models, Sparsity, Activation Function, ReLU Activation Function","The authors argue that pretraining with other activation only gives at best marginal performance, and longer training could compensate for the gap. However, I believe this argument can be better supported. The bottom row of Figure 2 only considers three downstream datasets ( maybe perplexity would be more indicative here), and it seems like the accuracy is still growing. It is hard to judge whether longer training could compensate, and if yes, how much more training we need.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models","Keywords: Large Language Models, Sparsity, Activation Function, ReLU Activation Function","Authors should provide more empirical comparisons to other size-reduction methods to validate thesucess of their strategy. The approach they develop is not compared to any pruning methods such as [https://openreview.net/forum?id=0GRBKLBjJE, https://arxiv.org/abs/2003.03033] which could be seen as competition.
The sparsification mechanism relies on the underlying architecture supporting the sparse BLAS operations which is not the case for some applications. It would be good to discuss this shortcoming in more detail and perhaps include latency measurements in the main text.
Takig advantage of the sparsity-promoting property of RELU is not trivial with regular implementations. Authors do not provide the link to their implementation of the method/experiments making applying this approach quite difficult.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models","Keywords: Large Language Models, Sparsity, Activation Function, ReLU Activation Function","The observation that replacing activation functions like GeLU, SiLU with ReLU only marginally influences performance is not new. It is also mentioned and discussed in [1][2].
The evaluation (Table 1 & 2) majorly focuses on zero-shot learning and ICL scenarios. Although I understand that zero-shot learning and ICL are common settings to compare LLM performance, it can be helpful to compare the model performance on generation tasks to better understand how different activations influence model performance.
I am confused by the applications studied in Section 5.1, what does “loading new weights” mean here? Shouldn’t all weights be pre-loaded to the GPU HBM in common inference frameworks like vLLM [3]?
Although the paper claims that replacing other activations with ReLU only has negligible impacts on the performance, the accuracy drop seems not to be so marginal. However, I agree that this replacement can also be a potential good trade-off between model performance and model efficiency.
[1] Li, Zonglin, et al. ""The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers."" The Eleventh International Conference on Learning Representations. 2022.
[2] Zhang, Zhengyan, et al. ""MoEfication: Transformer Feed-forward Layers are Mixtures of Experts."" Findings of the Association for Computational Linguistics: ACL 2022. 2022.
[3] Kwon, Woosuk, et al. ""Efficient Memory Management for Large Language Model Serving with PagedAttention."" Proceedings of the 29th Symposium on Operating Systems Principles. 2023.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"On the Joint Interaction of Models, Data, and Features","Keywords: Generalization, feature learning, empirical phenomena","Honestly, I don't see obvious weaknesses of the proposed framework and study.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"On the Joint Interaction of Models, Data, and Features","Keywords: Generalization, feature learning, empirical phenomena","Figure 1 is a bit vague. It is recommended to replace it with a clearer version.","nan","8: accept, good paper"
"On the Joint Interaction of Models, Data, and Features","Keywords: Generalization, feature learning, empirical phenomena","I definitely agree with ""the empirical phenomena of deep learning can be understood at many different layers of abstraction"". However, I think the model proposed in this paper is too simplistic. The implicit biases of deep learning are core to some of the merging phenomenon that we see these days and the models that the authors propose fails to capture that. I also think that a good toy model should leave the door open to generalizations and getting closer to real world practice (for example, for the random features model of deep learning, there is a very obvious way to move towards making it more realistic). But the models that the authors propose is too abstract and it is not clear what simplifications are made to the real problem to arrive at the proposed model.
Although the model is based on some observations using the interaction tensor, I still find the model to be not very well motivated. Any insights on how this can relate to the training of deep nets?
It is not very clear how the authors set the hyperparameters in their model (e.g., the thresholds).
The notations are a bit confusing (i, j, k, etc.). I suggest authors avoid using these generic letters. Also, the paper will benefit greatly from a figure that summarizes all the notations (p_d, p_r, etc.). It will also help explain the method.
The authors ""prove"" GDE in their model without the explicit assumption of calibration. But the model is very abstract/high-level and I'm not sure if the assumptions that they make are stronger or weaker than calibration.
The theoretical understanding of feature learning is not as rudimentary as the authors claim. For example,
[1] Alex Damian, Jason Lee, and Mahdi Soltanolkotabi. Neural networks can learn representations with gradient descent, 2022.
[2] Zhichao Wang, Andrew Engel, Anand Sarwate, Ioana Dumitriu, and Tony Chiang. Spectral evolution and invariance in linear-width neural networks, 2022.
[3] Eshaan Nichani, Alex Damian, and Jason D Lee. Provable guarantees for nonlinear feature learning in three-layer neural networks, 2023.
[4] Yatin Dandi, Florent Krzakala, Bruno Loureiro, Luca Pesce, and Ludovic Stephan. Learning two-layer neural networks, one (giant) step at a time, 2023.
[5] Behrad Moniri, Donghwan Lee, Hamed Hassani, and Edgar Dobriban, A theory of non-linear feature learning with one gradient step in two-layer neural networks, 2023.
and many more.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"On the Joint Interaction of Models, Data, and Features","Keywords: Generalization, feature learning, empirical phenomena","Like any theoretical framework, many assumptions went into the combinatorial analysis. In particular, this framework assumes features and datapoints are each either dominant or rare, a dominant/rare datapoint always has the same number of dominant/rare features, etc
The framework is less useful for understanding the learning process of networks, such as why some runs might collapse while others successfully learn the desired features
Some minor typos: section 5, data generating process paragraph's second-to-last sentence samples
nr
rare, not dominant, features. Appendix C, equation line 34 the two
≠∅
could maybe instead be
=∅","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Topological data analysis on noisy quantum computers","Keywords: Topological data analysis, quantum computing, unsupervised learning, feature extraction","A minor weakness of this work is that the proposed algorithm is not strictly applicable to NISQ devices. NISQ devices can only implement an O(log n)-depth quantum circuit before the measurement outcomes become random noise. While the work provided a significant improvement in the circuit depth, the circuit depth is still O(n).
A theorem analyzing the amount of local depolarizing noise on each gate that can be tolerated by the proposed NISQ-TDA algorithm is missing in the current writeup (the physical experiments do show that the proposed algorithm is promising).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Topological data analysis on noisy quantum computers","Keywords: Topological data analysis, quantum computing, unsupervised learning, feature extraction","I feel the technical discussion in Section 3 (especially the projection to a simplicial order) is a bit hard to follow. Is it possible to give some concrete examples (e.g., in terms of explicit circuit & Pauli operators)? Also, it would be better to discuss more on the actual resources (gate counts, # of measurements, etc.) spent on the Quantinuum hardware. See the following ""Questions"" section.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Topological data analysis on noisy quantum computers","Keywords: Topological data analysis, quantum computing, unsupervised learning, feature extraction","For real quantum advantage, the input data must satisfy several conditions listed at the end of Section 3. The advantage for solving the problem of deciding whether a simplicial complex has exponentially many holes seems less clear and perhaps less practical. It would be great to know if the algorithm still provides speedup for real-world instances.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Topological data analysis on noisy quantum computers","Keywords: Topological data analysis, quantum computing, unsupervised learning, feature extraction","The reviewer has a basic understanding of quantum computing, but not familiar with TDA. The paper does not provide sufficient background and related work on quantum computing, TDA and QTDA. It assumes that the reader is familiar with these topics and does not cite relevant literature or explain the key concepts and notations.
The paper does not provide any empirical evidence of the quantum advantage or noise-resiliency of the NISQ-TDA algorithm. It only shows some preliminary results on small datasets and noisy simulations, without any statistical analysis or comparison with baselines.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","Keywords: Retrieval-augmented Generation, Language Models, Retrieval-augmented LMs, Factuality","Even though there are a lot of benchmarks and ablations, I still find that many of my questions are not answered by these evaluations
Specifically, I'd like to separate out the contribution from the main two parts of the approach, the self-reflection, and RAG. I don't see much ablation or comparison on the self-reflection side. Only the IsSup token is ablated and that it.
The RAG also has many details that I'm not certain have been compared against, other than simply changing the underlying model, which is not that interesting IMO. I believe simple changes to prompt, number of topk to retrieve, and order of retrieval (top first or top last) can produce highly nuanced results.
I would have also liked to see at least an attempt at trying to combine self reflection with RAG without any pre-training
I find some of the numbers reported not convincing and in need of more investigation
Ret-ChatGPT in Table 2: in all but the Long-form generation tasks, ChatGPT performs better than the retrieval-augmented version. This is curious and tells me either the model has seen the data (which makes the dataset slightly not a good representative of the RAG task) or that RAG is not being done correctly
I have a similar (but less important) observation for the Alpaca models (specifically 13B). I can understand the reduced MAUVE score, but accuracy on PubMed has also been reduced which tells a similar story
Same is true in Figure 3.a (ablations) where Self-RAG without retrieval is already better than all the other baselines in Table 2. Is this because there has been a data leak? If yes, that completely invalidates these results","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","Keywords: Retrieval-augmented Generation, Language Models, Retrieval-augmented LMs, Factuality","The critic model plays a pivotal role within the framework, and the authors have reported its accuracy in the Appendix. However, the paper does not include an evaluation of the LLM's accuracy in predicting reflection tokens.
The retrieval threshold is predetermined, but the authors have not provided an analysis of how variations in the retrieval threshold might affect downstream task performance.
In the ablation study, the paper only investigates 'Retrieve top1,' while SELF-RAG utilizes top 5 or top 10. Furthermore, the study exclusively focuses on 'Remove[IsSup],' neglecting an examination of the other criticize tokens.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","Keywords: Retrieval-augmented Generation, Language Models, Retrieval-augmented LMs, Factuality","There are some related search that prompts the model to decide when retrieval is needed and how to use retrieval during decoding. E.g., ""Active retrieval augmented generation."" by Jiang et al [1]. It would be nice to study what benefits the offline data augmentation & training approach can bring comparing to these prompting-based frameworks.
Since most experiments uses automated evaluation focusing on accuracy and factuality, it is still unclear to me if such a training approach could hurt some aspects of the model, e.g., instruction following, creativity, or reasoning.
One limitation of the proposed Self-RAG is that the model sees each passage independent from the others. The generator cannot synthesize multiple passages.
[1] Jiang, Zhengbao, et al. ""Active retrieval augmented generation."" arXiv preprint arXiv:2305.06983 (2023).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection","Keywords: Retrieval-augmented Generation, Language Models, Retrieval-augmented LMs, Factuality","The reflection tokens might be useful to select more promising generations during the decoding time. But it seems that they do not affect (or guide) the generation process from the beginning and might not help if none of the candidates is good.
If GPT-4 somehow can decently provide the labeled data required for each reflection step, it seems intuitive to just instruct GPT-4 to obtain the ideal response that is grounded by the input. Also, GPT-4 might make the decisions on whether to retrieve or not differently from the small LMs as GPT-4 memorizes a lot more world knowledge. Therefore, the annotation given by GPT-4 might not be suitable for small LMs. It would be great to have some discussion or clarification on this.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection","Keywords: Data Selection, Interpretability, Fairness, Robustness","I have a number of confusion about this work that I state here and in the questions section. I would be happy to revise my score in light of feedback from the authors.
Details of the approach: The exact procedure of the trimming portion is not quite clear to me. I think the authors miss discussing retraining. I assume that the authors are referring to a model retrained after a subset of examples are deleted? So in Fig. 2, x axis==zero is a model trained on all data points? Then you trim a percent of the training samples and then retrain a model on the new dataset? If yes, is it the original model that is used for deciding which samples to trim or is the model changing?
What is the motivation behind the cart regression procedure?: As it stands it seems the cart procedure takes as input
(xi,yi)
, and the predicts some influence score per example? More details could be useful here. Are the samples used in the training of the cart model a subset of the original training set for which the influence was estimated? Since we know that the influence score measures the effect of up(down)weighting the training sample, alone, we also know that the label should not have any effect on predictive quality of the tree. What is the point of then concatenating the label? It seems like the goal here is to estimate the effect of a feature on the performance metric of interest. I take this judging from Figure 1 where the authors plot performance metric vs features that is colored by influence. If the goal is really to determine the effect of a feature on the performance metric of interest, then how to do that is already in section 2.2 of the original Koh and Liang paper. If the goal is not to measure the effect of the feature on the influence score, then I am not sure I understand the point of this section. Another point here is that in the rest of the paper, the trimming-based approach is really what the authors use and not the cart procedure. If this is the case, I don't think we can that as a contribution of this work. I am asking all these questions as a way to better understand the motivation and goal of fitting the tree to predict the estimated influence score.
Related Work: There is some related work that this paper should be aware of. I list them here: Kong et. al., Resolving Training Biases via Influence-based Data Relabeling, Adebayo et. al. Quantifying and mitigating the impact of label errors on model disparity metrics, Richardson et. al. Add-Remove-or-Relabel: Practitioner-Friendly Bias Mitigation via Influential Fairness, (concurrent) Understanding Unfairness via Training Concept Influence, Sattigerri et. al. Fair infinitesimal jackknife: Mitigating the influence of biased training data points without refitting. All of these papers have a trimming and/or relabelling scheme in them. I am not claiming that this work is not novel/important. I think the insights here are quite useful actually, but it would be helpful for the authors to acknowledge these works, and contextualize their contributions in light of these papers.
Tabular Data: I don't see this as an important weakness; however, most of this work is demonstrated on tabular data. It will be tricky to extend the feature analysis portion, as done in Figure 1 for example, to say images or text.","N/A","6: marginally above the acceptance threshold"
"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection","Keywords: Data Selection, Interpretability, Fairness, Robustness","Scalability Concerns: The use of tree-based influence estimation models might indeed pose scalability issues. Tree-based models can become computationally expensive as the size of the dataset increases, especially if the influence estimation requires building trees for many subsets of data or for complex feature interactions. This could limit the method's applicability to big data scenarios or require significant computational resources, which may not always be feasible.
Hard to Adopt Data with High-Dimensional Features: For example, image data presents unique challenges due to its high dimensionality and the spatial relationships between pixels. Influence functions and feature space interpretations that work well for tabular data may not translate directly to image data.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection","Keywords: Data Selection, Interpretability, Fairness, Robustness","Limitation on model class: The authors provide a discussion on why the influence function evaluations are limited to convex classifiers, possible remedies, and recently applications to deep neural networks. However,
Theoretical analysis: the estimation of the influence function is based on the trees with hierarchical shrinkage regularization. However, there is no analysis on the credibility, time complexity of the proposed Algorithm 1 and Algorithm 2. It seems that these algorithms are not scalable to large-scale datasets.
The utility, fairness and adversarial robustness are important performance metrics for a classifier; however, there is a lack of a unifying story to connect all three and therefore the discussion and experiments may seem distracted
Feature explanation is a key aspect in this paper; however, the connection of feature explanation using the influence function with existing explainable AI literature is lacking.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection","Keywords: Data Selection, Interpretability, Fairness, Robustness","When I read feature space, I think of d-dimensions where the variables (features) live. The authors' writing was a bit confusing to me because from the abstract to the introduction, I thought their influence estimation-based method was identifying features from the feature space with positive/negative influence on the model utility (accuracy, fairness, robustness, and so on). However, at the beginning of the background section and throughout the experiment results, the authors focus on only the contribution of the training samples to the utility function. I think the authors should be a bit more clear in the writing or presentation. Although section 3 is fairly written, I would recommend that authors revisit abstract+sections 1-3.
Since the authors focus on features and samples, it would have been informative to see the difference in selected/excluded features and samples and the consequential contribution to the utility with and without the authors' method.
Although influences functions are not affected by retraining-related complexity, they have a high incremental complexity due to the computation of the Hessian matrix for each x_{i} valuation, which might worsen (beyond retraining) when n is large. Additionally, using CART as a sub-module further increases model complexity. I would have appreciated looking at the code specific to section E.1 in the appendix (I couldn't find it in the shared code base)
Not entirely sure, probably it's the figure, I find the almost constant utility values with random deletion somewhat unrealistic. Could the authors also explain Figure 2C? The scale for accuracy on some figures in 2 is not intuitive. Is it possible for authors to adopt similar scales for similar utilities across datasets?
Experimental results.
Figure 2 Specific questions: I find the almost constant utility values with random deletion somewhat unrealistic. Could the authors also explain Figure 2C?
Figure 10 in the appendix. If you're removing low-value samples, I wouldn't expect TMC-Shapley to behave like that, accuracy would increase with the removal of low-value samples. If you're trimming high-value examples, then this graph would make sense but would mean influence-based trimming is performing poorly.
Instead of TMC-Shapely and random, it would have been more informative to see how the proposed approach compares with other influence estimation-based approaches, including vanilla (without CART) influence estimation.
The scale for accuracy on some figures in 2 is not intuitive. Is it possible for authors to adopt similar scales for similar utilities across datasets?
Minor:
While the focus on convex loss is understandable, it might lead to sub-optimal influence value estimation due to the model parameters not being at a stationary point or the model not converging. This might then be a net negative and misleading data value estimation.
It looks like the authors do one utility at a time. Due to often competing utilities, for example, key features and samples for fairness might not necessarily be the same for accuracy, and in most cases might have a negative influence. It would be interesting to see an interplay of various utilities.
Although authors use several datasets, all of them are binary settings. Value computation increases with classes, so I am curious to know if this is the reason authors only focused on binary settings or if there is another reason behind this design choice.
The authors' paper was 32 pages instead of 9","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"""What Data Benefits My Classifier?"" Enhancing Model Performance and Interpretability through Influence-Based Data Selection","Keywords: Data Selection, Interpretability, Fairness, Robustness","The motivation of this paper is not clear and not strong.
Technical contributions of the proposed method are limited.
Writing is not unsatisfactory. Many times, readers are unable to understand the author’s true intentions.
More details about the weaknesses can be checked below.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Generative Modeling with Phase Stochastic Bridge","Keywords: Generative Modeling, Stochastic Optimal Control, Diffusion Model","The clarity of the paper will be better if the conditions of the Lemmas and Propositions written in this paper is stated more concretely and with full notations, especially in the appendix.
In the sampling-hop part, the writing does not fully cover how the sampling-hop is more accurately evaluated compared to the CLD case. Both this method and CLD make predictions of the data from both the current state and the velocity, while the compared EDM (Figure 2) does it from state alone.
In the Probabilistic ODE part of (7), an additional notation rather than
g(t)
is recommended to be used, like
gt→ht
in the matrix notation and
g(t)=ht
for BM-SDE part. Because the notation
g(t)
or
gt
is abused, it can be misleading that the score term of the probabilistic ODE is neglected.
The SOC theorem is only used limitedly; the regularization in terms of
∫||at||2
is ignored and this can threaten the stability of the acceleration space, even though this is not directly revealed in the paper.
Whereas the theoretical background is sound and the improved performance is guaranteed, the hyperparameters such as the diffusion coefficients and the SDEs are not optimized, which causes its lacking performance compared to EDM (look at Figure 5). However, this is expected to be enlightened with further works.","None.","8: accept, good paper"
"Generative Modeling with Phase Stochastic Bridge","Keywords: Generative Modeling, Stochastic Optimal Control, Diffusion Model","The work does not have significant weakness. Minor weakness points include
The work only shows experiment results on CIFAR-10, ImageNet 64, and AFHQv2 without scaling to higher resolution images.
As the author points out in limitations, AGM is not performing as good as some existing methods especially when the number of evaluations is large. I don't think this is a major weakness as the major benefit of AGM and straight sampling trajectories is the reduced number of evaluations during sampling.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Generative Modeling with Phase Stochastic Bridge","Keywords: Generative Modeling, Stochastic Optimal Control, Diffusion Model","The exposition is rather dense and, as a consequence, the paper is somewhat difficult to read. This is a pity since the underlying concept are rather intuitive and can be understood by a wide audience.
As also stated by the authors, the performance of the method is inferior to several baselines for a large number of functional evaluations. However, I do not think that this is a major issue since this class of models are generally designed to work well in the low NFE range, and the results are good in this relevant range. It is quite intuitive to me that there should be a trade off between straight paths and high NFE performance, since the smoothness constraints can limit the expressivity and probabilistic coverage of the method.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Generative Modeling with Phase Stochastic Bridge","Keywords: Generative Modeling, Stochastic Optimal Control, Diffusion Model","The paper could provide more insights into the potential applications of the AGM framework beyond image generation.
The paper could discuss potential improvements to the AGM framework, such as enhancing the training quality through data augmentation, fine-tuned noise scheduling, and network preconditioning.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Zipformer: A faster and better encoder for automatic speech recognition","Keywords: Zipformer, ScaledAdam, automatic speech recognition","While the motivation for biasnorm and scaledadam are well explained, the motivation for zipformer blcok, especially those downsampling and upsampling modules are not well presented.
The results on aishell1 is not quite convincing compared to other conformer variants. The author could elaborate more on the performance. Could be that this is a small dataset?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Zipformer: A faster and better encoder for automatic speech recognition","Keywords: Zipformer, ScaledAdam, automatic speech recognition","There are maybe too many new things being introduced here, which are all interesting by themselves, but each of them would maybe require more investigation and analysis on their own. E.g. introducing a new optimizer (ScaledAdam) is interesting, but it should be tested on a couple of different models and benchmarks, and this would basically a work on its own. Now we have way too little analysis for each of the introduced methods to really tell how good they are. The ablation study is basically only a single experiment, showing ScaledAdam vs Adam, or LayerNorm vs BiasNorm. A single experiment is not really enough to really see how ScaledAdam vs Adam performs, or BiasNorm vs LayerNorm, etc. E.g. replaying LayerNorm by BiasNorm in a standard Transformer, maybe for language modeling, how would this perform? Many of these introduced methods seem to be quite orthogonal to each other.
For comparisons, it would have been better to use a more standard transducer, not a pruned transducer. Or maybe even CTC, or CTC/AED. This would have made it easier to compare the results to other results from the literature (Table 2).
Measuring just FLOPs can sometimes be misleading as indicator for speed, because certain operations might be faster than others, and certain operations can be executed in parallelized, while others can not. It would be interesting to also see the actual measured speed on some given hardware.
No systematic comparison to other Conformer variants, e.g. E-Branchformer, etc. (I don't just mean to have the number from literature as a comparison, as done in Table 2. I mean that the differences are compared, i.e. discussed and maybe also experimentally compared.)","None","8: accept, good paper"
"Zipformer: A faster and better encoder for automatic speech recognition","Keywords: Zipformer, ScaledAdam, automatic speech recognition","From my biased view, the major weakness in this paper lies in the fact that this work actually presents two inter-connected but (arguably) separate works: one is to the novel new encoder structure, including the U-net with middle stacks operate at a lower frame rates, sharing the attention weight with two self attentions, a novel non-linear attention, a BiasNorm and a slightly modified swooshL/swooshR activation function; the other is about the modified Adam optimizer, scaledAdam, which the authors claim that it can explicitly learn the parameter scale, which the widely used adam failed to. Though the author gives some motivations behind these changes and give some ablation studies, it still points to the following unanswered questions:
the authors claim that the zipformer is better than the (reproduced) conformer, squeezeformer or other variants of transformer. However, it is unclear to me whether this is because of the model structure or because of the modified optimizer ? For example, in Table 5, the author presents that with all the proposed change (model and optimizer), zipformer-M can achieve 4.79% WER on test-other, however, with the standard adam optimizer, the WER becomes 5.51%. Will the other variants of transformer get better WER with the author proposed optimizer ?
On the other hand, I am wondering whether the proposed optimizer, which has many adhoc modifications compared with the much widely used adam optimizer, can be more widely used for other deep learning optimization tasks or does it only work for speech tasks or does it only work for zipformer ? Given the zipformer-L is a pretty small model (only 60M parameters) trained on limited data (<1000hrs) according to today's standard, will the proposed change still work better than the standard adam when the model and the training data scales up?
Other weakness of this paper include:
The authors propose changes to many widely used components, which have been well tested over time and over different tasks beyond just speech recognition. For example, the authors claim that the mean extraction in layer norm is not necessary and also remove the variance normalization. While this may seem to work for authors use case, I am intrigued to learn how generalizable this claim can be.
Some of the proposed modification seem arbitrary. It would be great if the authors can explain a bit. For example, in Eq (4), for the swooshR and swooshL functions, how the -0.08 is selected ? The authors mentioned that the coefficient 0.035 in Eq (4) is slightly tuned. How general is this parameter ?
In the ablation study, quite a few modifications results in less than 0.2% absolute WER change. How sensitive of the WERs on librispeech relative to other factors like checkpoint choosing, different training run with different seed ? In my own experiments, these factors can result in up to 0.1% WER changes.
The authors also miss a series of work in the literature that directly apply standard transformer (without much modification) for ASR. For example,
Y. Wang, A. Mohamed, D. Le, C. Liu et al., “Transformer-based Acoustic Modeling for Hybrid Speech Recognition,” in Proc ICASSP, 2020, it reports a WER of 2.26% / 4.85% on test-clean/test-other of librispeech, achieved by CTC + external NNLM; This is followed by a work in:
Zhang, Frank, et al. ""Faster, simpler and more accurate hybrid asr systems using wordpieces."" arXiv preprint arXiv:2005.09150 (2020). which achieves a WER of 2.10% and 4.20% using a similar architecture.
It is also noted that in
Wang, Y., Chen, Z., Zheng, C., Zhang, Y., Han, W. and Haghani, P., 2023, June. Accelerating rnn-t training and inference using ctc guidance. In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 1-5). IEEE.
It achieved almost the same WER as the initial conformer paper, but part of the conformer layers (10 out of total 17 layers) is running at much lower frame rate (about 120ms-160ms per frame). This is related to the temporal downsampling used in zipformer.","6: marginally above the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Zipformer: A faster and better encoder for automatic speech recognition","Keywords: Zipformer, ScaledAdam, automatic speech recognition","In my option, this paper has the same problem that it identifies in the original Conformer write-up: It's closed-source, complicated, and it will likely not be possible for the results to be reproduced. This is not by itself disqualifying; it is the nature of the field that SOTA systems are often published without source code. However, I expect that future work iterating on this design will struggle with direct comparison, much in the same way that this paper compares to a weaker reproduction of the original Conformer.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework","Keywords: Autonomous Agent, Meta Programming, Multi-Agent Society, Group Intelligence","Methodological innovation: A key issue with MetaGPT is the lack of innovation in its methodology. While it effectively utilizes Large Language Models (LLMs) in multi-agent systems, this approach may not be significantly different from existing approaches. Or MetaGPT is different from other methods in a trivial way, I don't really see their differences as being significant and requiring exploration with greater depth.
Fairness of experimental comparisons: The comparison methods used to assess the effectiveness of MetaGPT do not appear to be fully equivalent to what MetaGPT offers. Such differences may lead to biased or misleading conclusions about their superiority or efficiency.
Experimental validation of statements: Current experiments may not adequately validate the authors' claims about the efficiency and robustness of MetaGPT.","This submission does not discuss any potential ethical issues, which I think is uncritical, especially for generative AI technologies. There are potential privacy, security, and bias issues that accompany the collection, processing, and use of data, exchange between agents, communication, and so on, in open-ended tasks with multi-person collaboration. For example, I perceive at least the following concerns and considerations.
Unemployment and skill obsolescence: Automation of complex tasks in software engineering and other fields may lead to job losses. Professionals in these fields may need to adapt and acquire new skills to remain relevant. How to manage and communicate these changes is an ethical issue.
Transparency and accountability: As AI takes on more complex collaborative tasks, it becomes critical to maintain transparency in decision-making. It should be clear how MetaGPT arrives at solutions and who is accountable for those decisions, especially in critical applications.
Privacy and data security: The use of large-scale language models and AI in processing potentially sensitive information raises concerns about data privacy and security. Ensuring that user data is protected and used ethically is a key consideration.","3: reject, not good enough"
"MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework","Keywords: Autonomous Agent, Meta Programming, Multi-Agent Society, Group Intelligence","See above.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework","Keywords: Autonomous Agent, Meta Programming, Multi-Agent Society, Group Intelligence","Most of the experiment are on GPT4, which is expensive to access, how is the performance on the benchmarks or real development demands when used with open-source LLMs? Can you share some insight on which abilities of the LLMs matters most for the success of using this multi-agent framework and how to choose proper LLMs for use?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation","Keywords: uncertainty, segmentation, validation","The authors mention that “Overall, surpassing the ‘random’ AL baseline appears challenging, with marginal improvements on LIDC MAL and GTA5/CS”. However, great strides have been made in AL, and works have obtained significant improvements like in [1]. Could the authors discuss this?
The authors mention that “The choice of aggregation method exhibits dataset-dependent variability” and “The choice of aggregation method yields mixed results on LIDC TEX, similar to other downstream tasks”. Is there any recommended guidelines on which approach works best in which setting, or, should users try all combinations?
References
[1] Wang, Wenzhe, et al. ""Nodule-plus R-CNN and deep self-paced active learning for 3D instance segmentation of pulmonary nodules."" Ieee Access 7 (2019): 128796-128805.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation","Keywords: uncertainty, segmentation, validation","** The novelty is limited. The primary contribution seems to conduct additional experiments using existing methods.
** The experiments presented in the main text is not persuasiveness, and the binary (yes or no) outcomes remain inconclusive.
** Please provide detailed analytically experimental or theoretical proofs
** It would be better to conduct more ablation studies using different backbones (e.g., VIT based model).","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation","Keywords: uncertainty, segmentation, validation","I have two concerns regarding this article:
I am not sharing the enthusiasm of the authors regarding the need to separate AU and EU. They note that downstream tasks are important - which I fully agree. To solve those downstream tasks, I would not require a separation of uncertainty terms. What is the main value of this separation beyond a ""theoretical"" understanding? Perhaps authors should provide a strong justification as to why one must care about this separation...
I find the presentation style not optimal. Authors mostly provide summary results in the main text and the quantitative results in the appendix. Appendix should be there to support an otherwise self-contained main text. Here, I do not think the main text is self-contained.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation","Keywords: uncertainty, segmentation, validation","It is regrettable that component C0 was fixed (for each dataset) and not explored for at least another architecture. However, I might say that such a weakness is well within the realm of usual limitations expected in a paper.
The decisions pertaining to component C1 involve numerous hyperparameters, with some known to have a significant impact on performance. Consequently, this represents another weakness in the study, as it appears that these hyperparameters were not thoroughly investigated.
Figure 2 uses different colours to distinguish distinct parts of the figure. This is not friendly for people with colour deficiency, and the authors could try to include patterns on top of the colour scheme.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Finetuning Text-to-Image Diffusion Models for Fairness","Keywords: Fairness, Alignment, Diffusion Models, Text-to-Image Generation","The paper only tested the method on single-face generation, limiting the applicability of the proposed method.
It is unclear whether fine-tuning with the fairness loss affects the quality and diversity of the generated images on general prompts.
Although experiments in the paper show better performance than baseline methods, it is unclear how expensive the fine-tuning is compared with the baseline methods.","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Finetuning Text-to-Image Diffusion Models for Fairness","Keywords: Fairness, Alignment, Diffusion Models, Text-to-Image Generation","I could not find any major weaknesses in this manuscript. I only have a few minor questions and suggestions that I will list below.","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Finetuning Text-to-Image Diffusion Models for Fairness","Keywords: Fairness, Alignment, Diffusion Models, Text-to-Image Generation","This paper kind of mixing fairness and bias and uses both terms interchangeably, especially for the experiment evaluation part, they define the metric for bias by themself which reduces the credential of the evaluation. I wonder if any other metrics from other research papers have been used for evaluation. Is it possible to use well-defined fairness metrics like demographic parity/ equal opportunity, etc?","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models","Keywords: large language models, black-box language models, modular and collaborative knowledge","1.) The paper is missing many details and is hard to follow at times, especially in Section 2.1 and 2.3. (specific issues in questions section)
2.) Existing models that employ similar ideas of modular knowledge organization https://arxiv.org/pdf/2108.05036.pdf, https://arxiv.org/pdf/2203.06311.pdf and datasets that test temporal aspects https://arxiv.org/pdf/2110.03215.pdf are not compared.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models","Keywords: large language models, black-box language models, modular and collaborative knowledge","Language model based modules appear to entail potential risks. For example, knowledge cards based on a language model necessitate a retrieval-based factuality selector, and inaccuracies can arise in LLM-based yes/no decisions during the top-down knowledge integration process.
One of the major differences between this work and existing work based on retrieval or generation is the utilization of knowledge cards from multiple domains. Therefore, it would be beneficial to demonstrate performance trends based on the gradual accumulation of knowledge cards or the level of granularity of knowledge cards.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models","Keywords: large language models, black-box language models, modular and collaborative knowledge","The benchmarks and datasets tested in the paper primarily focus on natural language understanding tasks, lacking more results on generative tasks.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"METRA: Scalable Unsupervised RL with Metric-Aware Abstraction","Keywords: reinforcement learning","The paper can be more impactful and solid if the method is deployed on the real world tasks, like locomotion control on a real robot. Besides, as the authors have already listed in Appendix A, the method can be combined to more recent RL works.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"METRA: Scalable Unsupervised RL with Metric-Aware Abstraction","Keywords: reinforcement learning","While the paper presents results on a variety of environments, it would be beneficial to see how METRA performs on more complex environments such as Atari[1] or Google Research Football[2]. This would provide a more comprehensive evaluation of the method's scalability and effectiveness.
The paper could benefit from a comparison with more diversity RL baselines, such as RSPO[3] and DGPO[4]. This would provide a more complete picture of how METRA compares to other state-of-the-art methods in the field.
[1] MG Bellemare, Y Naddaf, J Veness, and M Bowling. “The arcade learning environment: An evaluation platform for general agents.” Journal of Artificial Intelligence Research (2012).
[2] Kurach, Karol, et al. ""Google research football: A novel reinforcement learning environment."" Proceedings of the AAAI conference on artificial intelligence. Vol. 34. No. 04. 2020.
[3] Zhou, Zihan, et al. ""Continuously discovering novel strategies via reward-switching policy optimization."" arXiv preprint arXiv:2204.02246 (2022).
[4] Chen, Wenze, et al. ""DGPO: Discovering Multiple Strategies with Diversity-Guided Policy Optimization."" arXiv preprint arXiv:2207.05631 (2022).","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"METRA: Scalable Unsupervised RL with Metric-Aware Abstraction","Keywords: reinforcement learning","There are no significant weaknesses in this paper. The theoretical explanations of why choosing WDM as the objective might be a little complicated for readers lacking corresponding background. Some explicit examples or pictures may help.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"METRA: Scalable Unsupervised RL with Metric-Aware Abstraction","Keywords: reinforcement learning","One weakness of the paper is the absence of a comparative analysis of the proposed algorithm's performance in alternative benchmarks, especially those where purely exploratory algorithms like RND have demonstrated exceptional results (e.g., in Atari). Specifically, METRA's performance remains unclear in settings such as discrete control or, more significantly, in stochastic environments. An important aspect that is missing is a demonstration of how the temporally compact space learned by METRA enables reward-free pre-training in these challenging scenarios. Addressing these points would significantly enhance the paper's impact, making it a more substantial and comprehensive contribution to the field.
The paper iteratively simplifies the proposed objective to enable tractable optimization. However, it remains unclear if these modifications impact the performance of the algorithm. An ablation study of these could also provide insightful details of the proposed objective. (e.g. if training with the formulation that requires N rollouts for each latent, would the obtained skills be more diverse?)","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction","Keywords: Continual Learning","Limited Comparison:
While the authors have made comparisons with recent baselines, the paper could benefit from a more extensive comparison by including well-established methods such as FTML[1] and LFW[2]. A broader comparison would provide a more comprehensive evaluation of the proposed method's strengths and weaknesses.
Limited Experimental Width:
Although the authors have conducted evaluations on popular datasets like CIFAR10, CIFAR100, and TinyImageNet, it would be good to test the effectiveness of the proposed method on larger datasets, such as ImageNet-1K. This would offer insights into the algorithm's performance in handling catastrophic forgetting in longer sequences.
Additionally, the experiments could be enhanced by varying the number of tasks on each dataset, thereby showcasing the adaptability of VR-MCL under different task configurations.
Lack of Memory Update Strategy Explanation:
The paper could benefit from a more thorough explanation of the memory update strategy employed in the VR-MCL algorithm. Given the algorithm's reliance on the Memory Buffer, a clearer and more detailed description of the update mechanism is essential to provide a comprehensive understanding of the methodology.
[1] Finn, C., Rajeswaran, A., Kakade, S., & Levine, S. (2019, May). Online meta-learning. In International Conference on Machine Learning (pp. 1920-1930). PMLR.
[2] Li, Z., & Hoiem, D. (2017). Learning without forgetting. IEEE transactions on pattern analysis and machine intelligence, 40(12), 2935-2947.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction","Keywords: Continual Learning","Most parts of the mathematical derivations are easy to follow. However, some detailed notations are not clear in the context, which reduces the readability.
The motivation of some experimental designs was not too clear, such as the imbalance CL setting.
It seems the math derivation process needs some strict assumptions. I doubt the gap between the theoretical findings and the empirical applications.
See the Questions part for more details.","No","8: accept, good paper"
"Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction","Keywords: Continual Learning","In Proposition 3, the author assumes that the batch size for inner step adaptation is sufficiently large. How do we quantify the term ""sufficiently large"" in reality? Is there any principle we can obtain from the proposed theorem to guide us in choosing the batch size?","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Improving Convergence and Generalization Using Parameter Symmetries","Keywords: Symmetry, optimization, generalization","Clarity: Although the paper is generally well-written, I did find it difficult to follow at times, especially with respect to the overall structure. One suggestion would be to switch the order of sections 4 and 5, as section 5 investigates how teleportation improves optimization, while section 4 is more or less self-contained with respect to generalization. I would also suggest having a (sub)section which is dedicated to introducing the necessary preliminaries and assumptions, with additional pointers to literature (e.g., some of the notation in section 3.3 could be introduced in the preliminaries already). In the appendix, it would be helpful to restate all the needed notation and equation, so the reader does not have to switch between the main paper and the appendix to follow the proofs.
Reproducibility: If I am not mistaken, there is no reference to or mention of any source code; it would be great to make your code publicly available.
Please find some minor remarks below:
p. 3: we provide theoretical analysis of teleportation -> we provide a theoretical analysis of teleportation
p. 3: that maximizes the magnitude of gradient -> that maximizes the magnitude of the gradient
p. 3: the iterates equation 4 -> the iterates in equation 4
p. 3, Theorem 3.1: I assume
θ
should be
w
Proposition 3.2: I assume
f
should be
L
p. 5: To simplify notations -> To simplify notation
p. 7: at the 20 epoch -> at the 20th epoch/at epoch 20
p. 7: teleporting to sharper point -> teleporting to sharper points
Lemma A.1: eq. (19) LHS:
ξ
seems to be missing in
L
, also 2 lines below","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Improving Convergence and Generalization Using Parameter Symmetries","Keywords: Symmetry, optimization, generalization","Overall, I really like the paper. One weakness, however, is that some of their theoretical results are not especially novel. For example their results on teleported SGD (Theorem 3.1) and the Newton steps (Prop. 3.2) seems to be minor modifications of standard proof techniques. And the (very interesting) fact that teleported SGD is equivalent to a Newton iteration was already observed by previous work [1]. However, this is no way inclines me to reject the paper -- I think its clarity and other contributions are more than enough to merit acceptance.
[1] Symmetry Teleportation for Accelerated Optimization, by Zhao, Dehmamy, Walters, and Yu 2022","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Improving Convergence and Generalization Using Parameter Symmetries","Keywords: Symmetry, optimization, generalization","I'm a bit confused about the claim that teleportation accelerates the convergence rate of SGD. The intuition part makes sense to me since it has the quadratic error term that typically arises from second-order optimization but the convergence rate in Theorem 3.1 is still
O(ϵ−4
), which is the same as SGD. The convergence guarantee is slightly stronger but I don't understand how we can claim teleportation accelerates the convergence rate of SGD.
Even though the claim is teleportation improves the convergence rate for Adagrad, SGD with momentum, RMSProp, and Adam, the only clear improvements that I could see from Figure 5 is Adagrad. The other graphs seem to have similar performance for algorithm with or without teleportation.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Improving Convergence and Generalization Using Parameter Symmetries","Keywords: Symmetry, optimization, generalization","My foremost concern is that, compared to existing work on parameter symmetry [1], this work seems more or less incremental in theory, basically extending the analysis from [1] to SGD and Newton's method. Moreover, the extension to SGD is done not based on standard noise assumption. The new results on generalization are justified mostly by experiments, rather than in theory.
The main assumptions are not clearly stated. I would suggest separating the assumptions rather than stating them at the beginning of each result. Moreover, the main result switches between stochastic (SGD) and deterministic settings (Newton's method), which makes it less accessible to the readers.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Flow Matching on General Geometries","Keywords: general manifolds, diffusion models, continuous normalizing flow","It would have been interesting to have an experiment exploring the effect of
k
on the learned model (i.e. the number of terms taken in the spectral distance, Equation 16).
In the same vein, additional experiments on the choice of scheduler
κ(t)
could provide valuable practical insights regarding the design of these models.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Flow Matching on General Geometries","Keywords: general manifolds, diffusion models, continuous normalizing flow","The advantage of simulation-free training on simple geometries is not clear. How fast is the training of the proposed approach compared to the training of previous diffusion models? As RSGM (Riemannian Score-based Generative Model) observes that they achieve similar test NLL with only 5 in-training simulation steps (Section O.1), I think that the simulation-free training does not provide significant time efficiency.
The reason for the outperformance of the proposed framework is not clear. Why does the proposed method outperform the Riemannian Diffusion model? Further, why does CNF Matching show superior performance on Earthquake and Flood datasets over the proposed method?
I would like to raise my score if the above concerns are sufficiently addressed.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Flow Matching on General Geometries","Keywords: general manifolds, diffusion models, continuous normalizing flow","I have not identified substantial weaknesses.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Ghost on the Shell: An Expressive Representation of General 3D Shapes","Keywords: Non-watertight mesh; generative model; 3D geometry; differentiable rendering","While the proposed method is faster than other methods as shown in Table 3, 3 hours is still too long.
The thin shape examples in Figure 4 and Figure 7 don't have complicated geometry. If there is a more complicated geometry, how well would the proposed method perform in reconstructing / modeling? For instance, when dropping a cloth onto an object, the cloth will have a lot of folds, wrinkles and even a lot of self-contacts. Can the proposed method deal with this case?","5: marginally below the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Ghost on the Shell: An Expressive Representation of General 3D Shapes","Keywords: Non-watertight mesh; generative model; 3D geometry; differentiable rendering","The authors claim this is the first work to propose a differentiable representation suitable for both open and closed surfaces. Though they mention representations for open surfaces based on unsigned distance fields, they should also include citations to the following two works, which offer alternative approaches:
D. Palmer, D. Smirnov, S. Wang, A. Chern, and J. Solomon, “DeepCurrents: learning implicit representations of shapes with boundaries,” in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 18665–18675.
T. V. Christiansen, J. A. Bærentzen, R. R. Paulsen, and M. R. Hannemose, “Neural Representation of Open Surfaces,” 2023, doi: 10.1111/cgf.14916.
The exposition could use some polishing. In addition to general copy-editing, some details of the method require further elaboration. Most prominently, the mesh extraction algorithm, which is a main contribution of the paper, is described only very briefly in section 4.2, and the lookup table for G-shells is only explained pictorially in figure 3. It would be helpful to readers to include at least a little more explanation of what is going on in that figure and why (even if it has to go in an appendix or supplemental material).
The description of the generative modeling approach in the paragraphs following eq. (2) is unclear. What does ""unevenly weighted prediction"" mean? What is the naïve diffusion loss, and what are you replacing it with? Why does predicting the linear interpolation coefficient instead of the value of
ν
help? Is there any tradeoff in doing this? If the normalization of SDF values is an issue, would there be an advantage to using more general implicit functions instead? If you are going to extend MeshDiffusion, it would be helpful to include at least a brief summary of how that method works.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Ghost on the Shell: An Expressive Representation of General 3D Shapes","Keywords: Non-watertight mesh; generative model; 3D geometry; differentiable rendering","While the experimental results are impressive, it is not clear whether the proposed modified marching cube or tetrahedra with mSDF value can guarantee the correct topology of the 3D mesh. For example, an isolated edge with no incident triangles.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Ghost on the Shell: An Expressive Representation of General 3D Shapes","Keywords: Non-watertight mesh; generative model; 3D geometry; differentiable rendering","G-SHELL inherits common disadvantages of implicit surface representation methods. Mainly, since it employs a regular grid, surfaces with high and unbalanced entropy will require many grid elements, which can be inefficient and limiting for real applications.
G-SHELL uses a marching cubes-like algorithm to extract the surface. Even though this method is highly parallelizable, it also represents a burden in computation compared to explicit methods.
G-SHELL does not model self-intersecting and non-orientable surfaces.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models","Keywords: Latent Diffusion Model, Text-to-Image, Neural Architectures, Foundation Models","(1) Ablation study is missing. An understanding of the impact of different model components on the final results is desired. (2) For automatic evaluation metrics in Section 4.1, only FID and Inception score are evaluated, and there are no metrics evaluating how well the generated images are aligned with the input text instructions, such as CLIPScore. (3) The paper does not elaborate on the possible limitations or potential failure cases of the proposed method. Could the authors clarify this aspect?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models","Keywords: Latent Diffusion Model, Text-to-Image, Neural Architectures, Foundation Models","I am satisfied with the current draft. As it targets robust latent visual representations, there should be a detailed analysis (e.g., the quality of the latent features / the distribution of the compression space). This can make its claim more convincing.","Wurstchen is trained on LAION-5B, which may contain potentially harmful data and influence the trained T2I model.","8: accept, good paper"
"Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models","Keywords: Latent Diffusion Model, Text-to-Image, Neural Architectures, Foundation Models","The approach is only tested on latent diffusion models. While there is no reason to believe it wouldn't work on pixel diffusion models it would be nice to verify this.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Würstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models","Keywords: Latent Diffusion Model, Text-to-Image, Neural Architectures, Foundation Models","I'm uncertain about the inference efficiency of this approach, as it appears to add an ""extra"" computation (Stage C) on top of the conventional LDM and SD (Stage B and Stage A). In particular, how could the proposed method achieve better inference time than SD-v2.1 in Figure 4? A detailed computational comparison would be beneficial for different components in the system (the text encoder, LDM(s), and image decoder) instead of just an overall process.
I think the Baseline LDM (trained for 25,000 GPU-hours (same as Stage C)) needs to be trained for GPU hours of Stage B + Stage C, given that both stages contribute to the final latent representation of the proposed method. More importantly, a baseline with the same architecture of the upper part in Stage B, Figure 3 (i.e., a conventional LDM obtained by just removing Stage C and the below part of Stage B, Figure 3) seems necessary to show the benefit of the proposed approach.
The parameter values in Table 2 might confuse readers due to inconsistencies in their presentation. For some models, like LDM, the table seems to consider all the parameters, including the text encoder. Yet, for other models such as the proposed method and SD, only the diffusion parameters are listed. I strongly suggest presenting the ""total"" parameters (because several components work together for a single text-to-image system) or, preferably, detailing both the ""total"" and diffusion parameters separately.
The popular MS-COCO benchmark has been conducted at the resolution of 256x256. Why did the authors change the resolution for IS in Table 2? In my experience, the resolution affects the metric scores. Furthermore, for some models (LDM, DALL-E, CogView), the IS results at 256x256 were reported. I also highly recommend including CLIP score.
I think the description “By conditioning Stage B on low-dimensional latent representations, we can effectively decode images from a 16x24x24 latent space to a resolution of 3x1024x1024, resulting in a total spatial compression of 42:1” in page 5 looks incorrect or overclaimed, because Stage B also takes a high-resolution latent map, 4x256x256, as input.
The behavior of the proposed model seems less explored. The representative analysis with different classifier-free guidance scales to show the tradeoff between FID-CLIP score [SD, GLIDE, Imagen] is missing. Furthermore, it would be interesting to analyze the tradeoff between the number of sampling steps and generation quality.
Minors: The paper is fairly easy to follow, but I think a careful proofreading is necessary: many typos exist.
x -> × (in many parts)
In stage B, we utilize a -> Stage B
Inception Score (IC) -> IS","n/a","8: accept, good paper"
"Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks","Keywords: Drug Design, Molecule Generation, Deep Learning, Computational Biology","I'm not so convinced about the translational equivariance of theorem 3.1. The concept ""Zero of Mass"" is not defined in the cited [1]. I suppose this is the space where
x
has a zero center of mass. How does this affect
θ
and
y
? [2] gives a detailed analysis about how to handle translation invariance in diffusion, but it's not so clear to me how this applies immediately to a BFN. The proof of theorem 3.1 in the present manuscript says nothing about translations.
The proposed method has limited novelty, as it combines a sampling method with an equivariant neural network to create an invariant sampler, as has been done many times previously, without other significant methodological innovation.
If the authors clear up the translational equivariance, I'll increase my score.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks","Keywords: Drug Design, Molecule Generation, Deep Learning, Computational Biology","There appears to be some significant issues with the formulation of the model. First, key equations are not derived or justified in the text or appendix. For example, how is the variational bound of the probabilistic model (Eq. 8) derived? Furthermore, how does it lead to Eq. 19? What is
L∞
? Is this the supremum norm? Why does minimizing this value lead to the correct parameters for the proposed model? It is difficult to verify the mathematical consistency of the model without these derivations. Second, the proof of Theorem 3.1 and Proposition 3.2 appear to be incomplete. For example, the proof of Theorem 3.1 ends mid-sentence. Moreover, I do not see anywhere a proof of translation invariance, only rotation invariance via the matrix
R
. Additionally, how does Lemma C.1 establish Eq. 23? There appears to be major steps that are skipped in this proof.
It is not entirely clear why Bayesian Flow Networks improve the performance of modelling 3D tasks (or perhaps specifically molecular generation tasks). The authors attempt to provide some intuition but I am not entirely convinced (see Questions).
Overall, I believe the work is very interesting but the manuscript requires some significant polish before it can be accepted.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks","Keywords: Drug Design, Molecule Generation, Deep Learning, Computational Biology","I found the text inside the section ""Overcome Noise Sensitivity In Molecule Geometry"" unclear (see Questions below).","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks","Keywords: Drug Design, Molecule Generation, Deep Learning, Computational Biology","The noise-sensitivity section (3.3) is not very clear, the authors should describe in more detail the issue and why a variance-increasing versus variance-decreasing sampling procedure is an important design decision. The claim of ""smoother information changes"" especially seems intuitive yet subjective.
The authors should explain how the objective is changing in equation 21, as it is not clear to me how this is improving the issue with sparser sampling of the center buckets.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Small-scale proxies for large-scale Transformer training instabilities","Keywords: Small Transformers, Training, Stability","I did not find significant flaws in the paper, I thought that two possible weakness are the following:
Absence of concrete rules of thumb: One weaker point in the paper is that it does not provide concrete rules of thumb for setting the relevant hyperparameters of transformer models and their training loops. Specifically, I think that the paper goes a long way reproducing instabilities and performing detailed ablations, but does not provide concrete advice (i.e. general recipes) for hyperparameter settings. Given the thoroughness of the ablations, this is a relatively minor point. However, I think that a short discussion of how a practitioner could use the insights in this paper to fix training instabilities and extract better model performance (by utilising smaller scale runs), would be useful.
Limitation to C4 data: To my understanding, all experiments in this work involve the C4 dataset, which is textual. While it is most likely that the authors' findings generalise to other datasets, it is not fully clear that the scalings shown in this paper would be encountered in other data modalities. However, I appreciate that performing experiments on additional data modalities would be a large overhead in effort, and the current findings to be convincing enough.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Small-scale proxies for large-scale Transformer training instabilities","Keywords: Small Transformers, Training, Stability","While I am not extremely familiar with the large-transformer-models community, I am under the impression that the pool of persons effectively concerned by this work is very small. As the authors note, training such large models is very computationally expensive, and currently only very few groups have the means to train such models.
As a result, I wonder if this subject might be in practice rather niche, in terms of how much of the community could actually use it.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Small-scale proxies for large-scale Transformer training instabilities","Keywords: Small Transformers, Training, Stability","The structure of the paper is a little weird (the conclusion is very short and contains no useful information, the discussion of existing results is just put at the end without much being done from it, the main points seem to be made in the figures. ). The way the logits in the attention mechanism pose problem is not made super clear or intuitive (obviously, it's a little hard to prove something, but at least some intuition would be appreciated). For instance, we learn that high enough learning rate will pose problem at some point, but that's the kind of things that is not surprising. Does this validate the whole hypothesis? Note: the concerns have been addressed.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Small-scale proxies for large-scale Transformer training instabilities","Keywords: Small Transformers, Training, Stability","A significant part of the paper is dedicated to replicating observations made in large transformers to small transformers. The utility of this is a little unclear. While it demonstrates that a small model with high LR could serve as a proxy for a larger model, it doesn’t demonstrate any new insights regarding large models. It would be more impactful if the authors would make previously unknown observations at a small scale, and then show that they hold at a larger scale.
Section 3.3 reads a little anecdotal to me. A more systematic study would be better.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models","Keywords: diffusion models; temporal coherency; Gaussian noise field; continuous white noise; noise transport","The major weakness from the practical point of view is the implicit assumption that temporally correlated noise maps can induce temporally consistent video editing results, which is often not true. This limitation, however, has been acknowledged and explained by the authors in the paper.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models","Keywords: diffusion models; temporal coherency; Gaussian noise field; continuous white noise; noise transport","The proposed method is computationally inefficient as compared to prior arts. Quantitative comparisons on this aspect would have been more helpful for future research works.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models","Keywords: diffusion models; temporal coherency; Gaussian noise field; continuous white noise; noise transport","From the theoretical point of view, the presented approach relies on the warping field being a diffeomorphism, while in practice to the best of my knowledge optical flows estimated with off-the-shelf methods are rarely invertible mappings.
As the authors themselves admit (Appendix E.3), ""the impact of the noise scheme is negatively correlated with the amount of constraints given to the model"", and, in particular, the method has a limited impact on latent diffusion models. However, it is obviously still useful for cascaded models.
As mentioned in the paper (Sec. 6) the method is computationally less efficient than other techniques.
According to Tab. 1, while the proposed method typically increases temporal coherence, at the same time it worsens frame-wise image plausibility metrics such as LPIPS or FID.
None of the video samples in the supplementary except for fluid dynamics provides the results of noise handling with the method proposed by Control-A-Video model. Please note that this model more close to the presented method in spirit since it also takes input video into account while PYoCo does not.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models","Keywords: diffusion models; temporal coherency; Gaussian noise field; continuous white noise; noise transport","I guess most experiments in this paper are conducted in zero-shot way which applies the image processing model and method to video processing problems. Looking forward to seeing whether this helps when training a video model, like the PYoCo model Considering video restoration (Zeroscope Text-to-Video) and pose-to-human (dreampose) already have good performance, I wonder the gap between image model+ integrate noise and these video models. As stated in Appendix E, integrat noise does not work well in latent diffusion model. I wonder if this is applicable to other pixel-level diffusion models like the open-sourced deepfloyd from stabilityAI, whose capacity is comparable or better than stable diffusion.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Vision Transformers Need Registers","Keywords: representation, vision, transformer, register, SSL, CLIP, attention, attention map, interpretability, DINO, DINOv2","The norm shows significant reduction for OpenCLIP in Figure 7, yet in Table 3, it doesn’t show significant improvement for object localization which is the main benefit of using register. Further explaination / exploration the reason behind it should be helpful for wide adoptation.
Minor: it should be OpenCLIP instead of CLIP in Figure7.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Vision Transformers Need Registers","Keywords: representation, vision, transformer, register, SSL, CLIP, attention, attention map, interpretability, DINO, DINOv2","The removal of these artifacts does come at the cost of new tokens, hence additional compute. The paper reports a 2-6% increase when adding 4-16 new register tokens.
One very interesting observation was how the different register tokens end up focussing on the different areas of interest on the object. If there are spatially discrete areas of focus for the registers, does this undermine the argument that we need them for storing global information which was earlier being done using redundant patches?
Not a weakness, but would be nice to see some norm-related metrics and/or visualizations for the outlier tokens across different heads. Do all the heads from these tokens end up getting these tokens repurposed? What does that variance across heads look like?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Vision Transformers Need Registers","Keywords: representation, vision, transformer, register, SSL, CLIP, attention, attention map, interpretability, DINO, DINOv2","While adding additional token (registers) seems like a simple and efficacious approach, I'm wondering if it's the only possible solution for reducing patch level redundancy. Did the authors observe similar effects across other self-supervised models, like MAE, where nominally the patch-level reconstruction should also alleviate representational redundancy?
In demonstrating that the artifacts hold global information, the authors ""choose a single token at random, either high-norm or normal,"" and then ""train a logistic regression classifier to predict the image class from this representation, and measure the accuracy."" Why choose this token at random? Why not use all the high-norm and normal tokens, or some projected and pooled version over all of them in order to regress to the class? In experiments we have conducted, this almost always outperforms using single tokens (cls or otherwise), and it may be the case that the conclusion that the high-norm tokens outperform the ""normal"" tokens is not so clear when this is done.
There seems to be a conflict between the fact that ""high-norm tokens appear on patches that are very similar to their neighbors,"" ""often appear[ing] in uniform, background areas,"" and the fact that performance on ImageNet classification improves almost monotonically with more registers, but not dense tasks like segmentation or depth estimation. In particular, I would expect that if reappropriating the ""redundant"" local patches helps on object-centric classification, it should help much more substantially on tasks that are even more reliant on good (non-redundant?) local information (i.e. segmentation or depth estimation). Can the authors comment on this?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Vision Transformers Need Registers","Keywords: representation, vision, transformer, register, SSL, CLIP, attention, attention map, interpretability, DINO, DINOv2","While the paper did a great job at analyzing the behavior of outlier tokens in previous models in Sec 2.1, the paper does not have experiments showing that such behavior is eliminated by adding the register tokens. It would have been interesting to see if the behaviors ascribed to normal/outlier tokens in Fig 5 and table 1 are now transferred to image/register tokens in the proposed model.
The discussion around the performance of models on unsupervised object discovery is fairly limited and does not match the resuls.
The paper is strongly motivated by the difference in attention maps compared to DINO and the limited performance of DINOv2 on LOST. While the gains of DINOv2+reg are impressive, it is still very surprising that it doesn't match DINO. It would be great if there was more discussions or some qualitative examples of that to explain why.
The paper states that ""for all models on all datasets, adding registers for training improves the unsupervised object discovery performance."" However, the results indicate that registers harm the performance on OpenCLIP.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment","Code Of Ethics: I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.","My biggest gripe with the paper is that their claim that motivates the approach is not empirically validated and there is no mention of such validation elsewhere. The authors claim both in the abstract as well as in the appendix that prior art use feature maps that may embed the inductive bias of the training data. While I can comprehend the underlying reasoning, such a claim needs to be empirically shown. For example, an experiment on out-of-distribution test sets demonstrating the superiority of the closed-form solution would back the authors claims and in turn strengthen the paper.
On the same topic of bias, I argue that the authors should explicitly state that their method still exhibits bias, but that the source of this is the underlying feature representation (result of this can be seen in Tbl. 1, Aachen Night dataset). Otherwise it may read that the authors claim their method is not biased. This is stated at the end of Section 3, but I think it should be stated clearly in either Abstract, Introduction and Conclusion section. This is a minor point however and only serves to improve clarity.
A little contradictory to my point in the Strengths section, I believe the math heavy section 4 and 5 could be made a little more clearer when derivations skip multiple steps. Otherwise the sections read as if one equation immediately follows from the other, which is not always the case. (e.g Eq 6. -> Eq. 7). This would enhance the readability of the paper.
On the Aachen-Night dataset, the proposed method clearly suffers. The authors claim that this is due to the underlying feature representation used, which was not trained day-night correspondences. While I find the reasoning sound, it would help the authors claim to have used a feature representation that have used such correspondences during training. This in turn would again strengthen the papers contribution and indicate that it can work in different settings.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment","Code Of Ethics: I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.","The paper is required to give more comparisons with state-of-the-art in terms of accuracy of SE3
Can the authors provide more training details of the proposed method, for example, the feature embedding network E, the learning rate, the batch size.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment","Code Of Ethics: I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.","No major weakness.
It would be interesting to see more discussions on the insight to the end-to-end learning framework's limitation, and a solution to that.
It would be interesting to see this approach handles outliers inherently.
It would be interesting to see this approach is applied to other areas.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Learning Energy Decompositions for Partial Inference in GFlowNets","Keywords: Generative flow networks, reinforcement learning, generative models","Learning the decomposition of the terminal potentials is interesting, but there are no theoretical guarantees that the learned decompositon provides meaningful local credits in all settings.
In terms of the empirical results, while the method performs quite well on a variety of tasks - there is an important caveat to note which is the size of the problems. The trajectory length in the problems considered is quite small. There are no experiments on problems with long trajectories which is where the local credit assginment would be critical and thus demonstrate the efficacy of the approach.
Another motivation for the approach even in the presence of ideal intermediate signals is that the true intermediate energy function can be expensive to compute. However, all the experiments consider tasks where this is not the case. So it is unclear whether there is a significant computational advantage.
Another important caveat of the empirical analysis is that it focuses on discrete problems and does not consider the continous case.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Learning Energy Decompositions for Partial Inference in GFlowNets","Keywords: Generative flow networks, reinforcement learning, generative models","See questions.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Learning Energy Decompositions for Partial Inference in GFlowNets","Keywords: Generative flow networks, reinforcement learning, generative models","I take issue with the use of ""partial inference of GFlowNets"" in the title and ""partial inference"" elsewhere and would strongly suggest for this to be revised.
""Inference of X"" means, given some information related to X, producing an instance of X or a distribution over X. So ""partial inference of GFlowNets"" should mean learning part of a GFlowNet, or learning it from incomplete information. This is not what is done in this paper: the whole GFlowNet is learned, but some terms in the objective can be computed using partial trajectories.
The third paragraph of the introduction and the second paragraph of 2.2 attributes ""partial inference"" to [Pan et al., 2023a], but in fact that paper does not introduce this term and does not ever use it.
The minimal fix would be to make the title ""partial inference of in/for GFlowNets"", which would more accurately describe what is being done.
Small errors in exposition on GFlowNets:
Error on the top of p.3:
exp⁡(−E(x))
is the reward, not the energy.
End of 2.1: SubTB as written does not ""interpolate between DB and TB"". It only interpolates if one uses the
λ
parameter from [Madan et al., 2023], in which case it indeed interpolates between DB (
λ→0+
) and TB (
λ→+∞
).
2.2: As written, (2) simply does not make sense:
E
is defined to be a function with domain
X
, but then it is applied to nonterminal states
s
! This can be fixed by writing that FL assumes an extension of
E
to nonterminal states, and that the freedom we have in the choice of this extension is a starting point for this paper (+ briefly discuss possible sources of the partial energies).
Limitations/costs/failure modes of the proposed algorithm are not discussed.
Missing details on the form of the model that predicts
ϕ
(I could not find them in the appendix). Does it share some parameters with the flow and policy models? It is an interesting question how simple or complex the energy decomposition model needs to be, relative to the policy model, in order to be useful.
Some theoretical characterization of the optimal energy decomposition would be helpful (even in the case of a tree-shaped state space).
In all plots with curves, please use markers or line styles, and not just colour, to distinguish the curves.
I am very willing to raise the score to 6 or even 8 if the above weaknesses and below questions are addressed.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Learning Energy Decompositions for Partial Inference in GFlowNets","Keywords: Generative flow networks, reinforcement learning, generative models","Please see the following questions.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization","Keywords: game theory, stochastic optimization, nash equilbrium, normal-form game, x-armed bandits","The empirical section (6.2) could use some additional explanation/discussion. The baselines that are compared against should be explicitly stated in the body text (and cited appropriately) instead of just stating that they are the baselines used in Gemp et al. 2022's simulations.
The flow of Section 6 generally could be improved (one suggestion is provided below).","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization","Keywords: game theory, stochastic optimization, nash equilbrium, normal-form game, x-armed bandits","The loss function only captures fully mixed equilibria. The authors address this by considering quantal-response equilibrium. As a result, a zero loss can only serve as an approximation to a Nash equilibrium.
There is limited empirical evaluation on real-world games. Most experiments involve small synthetic games from previous research. It's possible that more complex games may expose certain limitations.
SGD encounters issues with saddle points in certain games, which is a common challenge in non-convex optimization.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization","Keywords: game theory, stochastic optimization, nash equilbrium, normal-form game, x-armed bandits","I do not see major weaknesses in this work, though I am not an expert in this field.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Multi-Source Diffusion Models for Simultaneous Music Generation and Separation","Keywords: source separation, probabilistic diffusion models, music generation","The results of the paper would be made stronger with more discussion of the computational footprint and details for training and inference. How does the footprint compare to Demucs or other methods? How does does computation scale with the amount of data?
Further, some brief qualitative analysis of the results might be warranted. Do the authors have an explanation for the relative performance on certain stems relative to Demucs? What are the high-level takeaways from the qualitative results in Table 3 beyond those that the reader could intuit or speculate about?
Some feedback on the manuscript:
Section 2.1, in the last paragraph: should ""the minute"" read ""a minute"" denoting duration of the context length?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Multi-Source Diffusion Models for Simultaneous Music Generation and Separation","Keywords: source separation, probabilistic diffusion models, music generation","Adding details on the correction step could make the paper even more self-contained.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Multi-Source Diffusion Models for Simultaneous Music Generation and Separation","Keywords: source separation, probabilistic diffusion models, music generation","I think the paper would benefit from some additional discussion of the computational and data requirements of the proposed method. Presumably separation time is linear in the number of inference steps (plus correction); it would be nice to see this explicitly compared to Demucs with and without Gibbs sampling. Similarly, if the proposed method is more data-hungry than discriminative methods such as Demucs (e.g. if the proposed method is not competitive when trained/evaluated on MUSDB), this might be worth emphasizing further. Parameter counts for each method would also be nice to see.
Based on the listener study and provided listening examples, MSDM struggles to produce coherent and high-quality generations -- even when judged in the context of its synthetic training data. To my ears, it seems like tempo sometimes degrades within the model's 12-second context for unconditional generations, and for imputation generations when strongly metric signals (drums, bass) are not given as conditioning. Overall, the separation results seem much stronger than the generation results.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Multi-Source Diffusion Models for Simultaneous Music Generation and Separation","Keywords: source separation, probabilistic diffusion models, music generation","The paper is well-written. I have some minor comments. If it can be clarified, the significance of the work will be increased.
The idea of using a generative way to model audio and solve multiple audio tasks in one model is not a new idea. For example, we have a unified VAE approach to do source separation and transcription [1]. Of course the current work is novel but it would be better to include those studies and compare the approaches in related work.
What is the novelty compared to NCSN-BASIS? Any intuition for MSDM Dirac? Is it a marginal improvement from existing methods, or not?
The introduction of ISDM method is not clear. Is it a baseline method where the assumptions are obviously wrong? Is it another valid approach? Compared to MSDM, is there a trade-off in terms of generation quality and separation performance?
The introduction of correction step is okay. Since it is evaluated in the experiment section, could you explain more in the paper? What is the statement to be expected prior to the experiment regarding correction step?
[1] Liwei Lin, Gus Xia, Qiuqiang Kong, Junyan Jiang: A unified model for zero-shot music source separation, transcription and synthesis. ISMIR 2021: 381-388","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"LEGO-Prover: Neural Theorem Proving with Growing Libraries","Keywords: Theorem proving, Large language model, Autoformalization","1. Comparison to baseline is not very strong
In my understanding, the best-performing prior work Subgoal-Learning (Zhao et al., 2023) does not get the human written informal proof, so the natural comparison is between this baseline and LEGO-Prover (model proof). The improvement on miniF2F-valid is from 48% to 52.4%, which is a 4.4% improvement. This is decent, but not huge given the complexity of the method and amount of additional LLM queries required (which could have been used just running more iterations of the other approach, for example).
Additionally, there's no comparison on miniF2F-test for LEGO-Prover (model proof) which seems important to include if following the above interpretation as the main result.
I also find one of the main results in the abstract misleading: the 48% to 57% improvement is actually between the baseline (which gets 100 attempts) and LEGO-Prover-Star which is a combination of LEGO-Prover (model proof) and LEGO-Prover (human proof) which in my understanding each get 100 attempts. This doesn't seem like a fair comparison since there's a combined 200 attempts used in LEGO-Prover-Star. (I'm open to revising this if there's an explanation I'm missing or I'm misunderstanding the setup here of course).
2. Comparison to ablation is not very strong
The ablation of the skill library changes the 50-attempt solution rate of the method on the validation set from 47.1% to 50.4%. This 3.3% solution rate gain is not much for the complexity of the proposed method. I like the idea of the skill library and I do believe that by experimenting with variations on the approach the authors can achieve greater results, but as-is the library doesn't seem to add much.
The library version must also involve far more and far larger queries to the LLM, given all of the lemmas included in prompts and the fact that for every 3 problem solving attempts there are 8 evolving attempts. Simply using all those extra tokens for more attempts at solving the original problems would likely provide a lot of benefit and could conceivably close the 3.3% gap (this could of course be disproven through an experiment, and would be a valuable thing to include).
3. Could use more details at certain points, and overall readability
It took me a very long time to understand the method; in part this is just due to the many moving pieces, but I think the explanation itself could also be improved and I'll do my best to lay out some of my confusions/thoughts which I hope will help the authors.
I think that presenting the top level algorithm loop first would greatly improve this: that LEGO-Prover makes 100 passes through the miniF2F dataset and in each pass makes a single attempt at each problem in the dataset using the Solver (which is composed of two pieces: Decomposer and Formalizer). And that concurrently, for every 3 problems attempted it makes 8 attempts at solving any pending Lemmas that are proposed but unsolved (and also it calls the Directional Transformer to evolve them? Though I'm unclear on how much that is called relative to the Request Solver). A very high level schematic and brief description early on could be helpful for this – as is, I found myself trying to understand the 4 pieces (Decomposer, Formalizer, Request Solver, Directional Transformer) somewhat independently only to find later that there's this larger 100 pass cycle split into two concurrent processes, which came as a surprise around page 6 (until then I was just unsure when the lemmas got evolved/proved during this whole process), though perhaps I've missed some earlier discussion.
A bit more clarity could also be used in this top level loop, which I'll leave questions on in the Questions section.
Figure 2 was quite difficult to understand (though I appreciate how nice the visuals are). I left some notes in the ""minor"" section around tweaks that could help with that.
Figure 1b is meant to be an overview but I also struggled to understand it, and it doesnt include a depiction of the Request Solver (which seems important – when are the lemmas solved?). These figures all make sense to me now having read the paper, but they didn't help as much as I would hope for understanding the idea at a glance. This isn't a huge negative, but it would have been nice to get more of a feel for the overall setup from these splash figures.
minor suggestions:
In the related work on skill libraries it'd be worth mentioning DreamCoder (Ellis et al 2021)
At a glance it's difficult to see that Fig 2 is actually two subfigures – spacing them out more and/or making a thicker/different line between the two would help readability.
I'd suggest that Fig 2 should not reuse ""skill library"" in all 3 places, it should separately be lemma store, request store, and problem store. It was quite confusing that things labelled as ""retrieved skill"" and ""formal statement"" and ""request"" and ""similar skill"" (using labels in top right of each box) are all coming out of the skill library in different situations. Alternatively, something like color coding the different parts of the store and using color to show which is used in each place. This would just generally help for readers who glance at the figures before reading through the whole setup.
The main text having a table containing just the system messages from the prompt (can abbreviate away the ""expert mathematician"" bit) would be immensely helpful if space permits – looking to the appendix for those was key for my understanding. This would immediately clear up a lot of things, such as how the decomposer is producing two different outputs.
Section 3.3 has a ""Table ??"" where the reference must have broken; likewise there is a ""Figure ??"" and a ""Fig. ?? (a)"" near the end of 4.2
at the bottom of page 5, the phrase ""As depicted in Fig. 7"" should be moved a few sentences ahead – Fig 7 has the prompt, which is only relevant to the latter sentence ""Finally, the request solver prompts the LLM to generate the proof for the request.""
Missing period at end of first paragraph of section 2","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"LEGO-Prover: Neural Theorem Proving with Growing Libraries","Keywords: Theorem proving, Large language model, Autoformalization","I don't see any major weakness in this paper except for that the authors can perhaps write down the pseudo code of their algorithm to make the inter-components interactions more explicit.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LEGO-Prover: Neural Theorem Proving with Growing Libraries","Keywords: Theorem proving, Large language model, Autoformalization","The paper refers a lot to the figures, but these are not always explained in detail and they are quite complex to understand, with a lot of different components. Figures can be used as a support for the text, but not as a replacement.
The comparison with Thor+expert iteration and Draft, sketch, and Prove might not be completely fair, as these make use of GPT-3 instead of ChatGPT.
It would be helpful to have the workings of the LEGO-prover presented in some algorithmic way, in order to have an overview of the whole pipeline.
Minor: there is a missing cross-ref on p. 8.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LEGO-Prover: Neural Theorem Proving with Growing Libraries","Keywords: Theorem proving, Large language model, Autoformalization","I am unsure why the paper splits the miniF2F dataset into valid and test datasets, although the proposed method does not need training.
The proposed method outperforms the previous approaches significantly on miniF2F-valid, but the difference on miniF2F-test is smaller. The paper does not discuss this point.
The paper says, ""Consistent with the (Jiang et al. 2022b; Zhao et al., 2023), each problem undergoes 100 attempts of proving,"" but I cannot find such a setting in the paper of Zhao et al. (2023).
Table 1 includes cells that have no number (represented by ""-""), but there is no explanation nor justification for it.
(Minor) The presentation can be improved. The figures in the paper include code fragments, but it is difficult to read and understand them due to the small font size and the lack of explanation. Regarding the latter, for instance, I cannot find, in Figure 1(b), where the retrieved and new skills go to and come from, respectively.
(Minor) The text can be improved. The paper seems to have several missing citations and incorrect references (e.g., I think ""Figure 3(b)"" on page 9 should correctly be ""Figure 4""). Another issue is that the paper cites the author names of the prior work even where it cites the paper, and vice versa (e.g., ""Subgoal-Learning Zhao et al. (2023)"" on page 7 should correctly be ""Subgoal-Learning (Zhao et al. 2023)"").","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ASID: Active Exploration for System Identification in Robotic Manipulation","Keywords: sim2real, system identification, exploration","Not per se a weakness of the method but the expectation set by the beginning of the paper. There two aspects that make RL challenging to deploy on real system is safety and sample efficiency. The writing gives the impression that the paper tackles both aspects, when it really tackles the sample efficiency aspect. There is no guarantee that the exploration is safe only that it should be more informative. The proposed approach is interesting as it is and I don't think not dealing with safety aspects is an issue.
Another aspect that does not really fit with the paper is the geometric learning aspect. It does not integrate well with the rest of the paper. The proposed approach is also highly specific and not generally usable. For example, the shape reconstruction is not going to work for complicated objects and will not result in accurate physical simulation outcomes. It is interesting that something like this can be done, but way it is presented and the amount of space available to that aspect makes it hard to fully understand and makes the results sound rather underwhelming.
One aspect that it unclear from the paper is how specific the resulting exploration and task policies are. How generalizable of a policy does the system learn at the end of the day? For example, does the ball pushing policy work only for the specific environment with that breakdown of friction patches and coefficients or is the policy more general and can be used to push balls in a variety of environments? Put differently, do I need to learn a new task policy and calibrate the simulator for every minor varioation of the task description?
The work mentions that it assumes the optimal policy can be found. That is a rather big assumption for RL as finding the optimum is not guaranteed and the other aspect is that often the reward function does not truly represent what we want to optimize for. Does the proposed approach actually need to find the optimum or is a ""good enough"" policy also acceptable?
Overall the experimental results are nicely presented and show good performance. Two things that could be improved are the discussion of the outcomes. There is little information about failure modes and their explanation, for example. The other part is that Section 5.3. makes sense under the hypothesis that good exploration coverage leads to good RL task performance. Is it possible to show this more directly in that section?
As side comment, maybe using \Pi_{task} for the learned task policy, to mimic \Pi_{exp}, could be a nice way to make it even clearer that there are multiple policies and what their goals are.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ASID: Active Exploration for System Identification in Robotic Manipulation","Keywords: sim2real, system identification, exploration","The main weakness for this paper is that this pipeline is very similar to other exploration methods model-based RL. For example: Shyam P, Jaśkowski W, Gomez F. Model-based active exploration. In International conference on machine learning 2019 May 24 (pp. 5779-5788).
Pathak D, Gandhi D, Gupta A. Self-supervised exploration via disagreement. In International conference on machine learning 2019 May 24 (pp. 5062-5071).
In fact, the pipeline is quite similar to Shyam et al. albeit the metrics and models used are different. However, due to the similarities in the process, those papers should be discussed and, ideally, included in the comparison.
While the experimental section is one of the strengths due to the evaluation in a realistic robotic scenario, the methods should also be evaluated on standard benchmarks for comparison, such as HalfCheetah. The baseline used [Kumar2019] seems very weak (in Fig 4 it does not explore at all). Furthermore, the work of Kumar2019 does not seem to be related to exploration with mutual information as stated in this work.","5: marginally below the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"ASID: Active Exploration for System Identification in Robotic Manipulation","Keywords: sim2real, system identification, exploration","More detail on why the Fisher Information is used vs other methods (observability Grammian, Kalman Filter covariance).
The numbers in the heatmaps in Figure 4 are hard to read, maybe block font for the numbers?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"ASID: Active Exploration for System Identification in Robotic Manipulation","Keywords: sim2real, system identification, exploration","Presentation/clarity can be improved: specifically, the abstract and introduction mostly describe the field of active exploration for system identification and adaptive control, as opposed to the specific method proposed, which appears to overstate the paper’s novelty. Furthermore, the approach warrants a better intuitive explanation. As I understand it, the Fisher Information objective attempts to quantify the sensitivity of model parameters to trajectories expected given some policy. Therefore, maximizing this objective yields a policy that, when executed, yields the maximum additional information about the model parameters.
Lack of baselining/adequate discussion of other methods that use the Fisher information objective. The statement “As compared to these works, a primary novelty of our approach is the use of a simulator to learn effective exploration policies” seems too strong and overstated given that there are entire fields dedicated to this, and “the application of our method to modern, real-world robotics tasks” is an inadequate claim to novelty.
Literature review can be improved with a discussion of the following:
Bayesian RL/Bayes-adaptive MDPs: M. Duff. Optimal Learning: Computational Procedure for Bayes-Adaptive Markov Decision Processes. PhD thesis, University of Massachusetts, Amherst, USA, 2002.
PILCO:
Deisenroth, Marc, and Carl E. Rasmussen. ""PILCO: A model-based and data-efficient approach to policy search."" Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011.
Adaptive MPC:
S. M. Richards, N. Azizan, J.-J. Slotine, and M. Pavone. Adaptive-control-oriented meta-learning for nonlinear systems. In Robotics: Science and Systems, 2021. URL https://arxiv.org/abs/2204.06716.
Sinha, Rohan, et al. ""Adaptive robust model predictive control with matched and unmatched uncertainty."" 2022 American Control Conference (ACC). IEEE, 2022.
System identification in partially observable environments:
Menda, Kunal, et al. ""Scalable identification of partially observed systems with certainty-equivalent EM."" International Conference on Machine Learning. PMLR, 2020
Schön, Thomas B., Adrian Wills, and Brett Ninness. ""System identification of nonlinear state-space models."" Automatica 47.1 (2011): 39-49.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Towards a statistical theory of data selection under weak supervision","Keywords: Data Selection, Empirical Risk Minimization, Influence Functions, High dimensional asymptotics","My main concern is the applicability in general setting and the assumptions in the paper:
There is a concern in that (to my understanding) only the behavior exactly at the the optimum was considered (or at least in a small neighbourhood of the optimum), for example, refering to the equation B.3 (definition of the error based only on optimal values of the parameters); and the assumption B.1.A1. (lack of multiple optimal values). In most non-trivial non-linear models an iterative optimization procedure must be considered, which results in parameters passing through a range of values in addition to the final minima (global or local). In this case, even having a low error at the optimal paramter values will not help the optimization procedure.
There appears to be a dependency of some calculated values on the value of optimal parameters that are to be estimated (\theta^*) starting from the equation 4.2. It was unclear for me whether we can use estimates of such parameters and how correct would be the final results when the assumptions are violated or some values are replaced with estimates (in case if closed form solutions are unavailable).
Since the paper is aimed at establishing a new branch of the data selection theory, would be nice to state applicability limits (to my understanding, only linear models were considered in the examples, including linear models with simple single non-linearity, such as generalized linear models)","10: strong accept, should be highlighted at the conference","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Towards a statistical theory of data selection under weak supervision","Keywords: Data Selection, Empirical Risk Minimization, Influence Functions, High dimensional asymptotics","I think that some parts of the paper are hard to follow and could be more clearly written (for instance, Sections 4-5). I understand that due to space constraints, presentation could be more challenging.
I do not find some other significant weakness.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Towards a statistical theory of data selection under weak supervision","Keywords: Data Selection, Empirical Risk Minimization, Influence Functions, High dimensional asymptotics","The presentation is quite technical. Readers who are not experts in this area may find this paper hard to follow.","5: marginally below the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Towards a statistical theory of data selection under weak supervision","Keywords: Data Selection, Empirical Risk Minimization, Influence Functions, High dimensional asymptotics","The primary limitation of this paper, to the best of my understanding, is that all mathematical analyses beyond Section 4 assume that the surrogate model is equivalent to the optimal Bayes conditional distribution. In other words, the sample selection process somewhat presumes knowledge of the true label distributions. Consequently, the authors have not been able to provide a sound theoretical justification for the ""magic"" effects claimed in Figure 1. This drawback significantly affects the significance of the work, in my opinion.
Theorem 1 asserts that
ρunb/ρnr
can grow arbitrarily large by selecting the feature vectors' distribution in an adversarial manner. However, can the same be said for
ρnr/ρunb
? What happens when the feature vectors' distribution is more generic, such as Gaussian? Without additional guarantees in these respects, the theorem may lack substantial significance.
All the mathematical analyses in this work are based on asymptotic conditions (
n,N→∞
with
n/N→γ
), which remain intriguing but could be expanded to encompass a broader scope. For instance, non-asymptotic guarantees and cases where
n/N→0
could be explored.
The section related to high-dimensional analysis exclusively considers a linear model with Gaussian feature vectors. Additionally, it assumes that
N/p
converges to a known constant. These assumptions offer room for extension and relaxation.
This paper is densely packed with intricate mathematical statements, often presented in a dense manner. Many results, sometimes unrelated, may require more context and explanation than a ""9-page limit"" can accommodate. In this regard, the authors might consider submitting their work to a journal to allow for a more comprehensive presentation.
Paper has no conclusions section.
Minor comments:
In Theorem 2: ""an non-empty"" -> ""a non-empty"".","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Mastering Memory Tasks with World Models","Keywords: model-based reinforcement learning, state space models, memory in reinforcement learning","My biggest concern is the lack of an explicit literature review/ related work section, which I would suggest to include in the appendix. Specifically, I believe that it is of special relevance to include a more in-depth comparison between R2I and S4WM -currently briefly mentioned in the conclusions- since both combine DreamerV3 with SSMs.
Also, I noticed there are no mentions about making the code available. Thus, it would be specially benefitting for reproducibility if authors include a summary of the alg in pseudocode at the appendix.
-- After Rebuttal --
Authors addressed very well all my concerns, the paper now presents clearly its differences with respect prior work and with a well documented code reproducibility should be easy to reproduce. I believe this will be a very relevant work for the RL community","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Mastering Memory Tasks with World Models","Keywords: model-based reinforcement learning, state space models, memory in reinforcement learning","Despite the conducted ablation in Appendix O, the question on why the different input variations work differently across environments still remains open. And the raised hypothesis on “feature instability” sounds vague and not properly backed up by a solid argument. It would be great to provide a better understanding of this challenge to give more clarity on how the method works, but I understand this is a difficult open problem that demands a careful investigation.
The work adopts SSMs to address the challenge of handling long-term dependencies in RL (memory and credit assignment). Nevertheless, it does not motivate the employment of Dreamer (or, more generally, Model-Based RL). I think it is important to describe and motivate why Dreamer was used instead of Model-Free RL, as it is not clear why MBRL would be better than MFRL for these memory tasks (unless there is another motivation besides asymptotic performance, such as sample efficiency).
In the same line, Figure 4 brings some “memory-augmented” Model-Free baselines, but it lacks “PPO + SSMs”. This baseline would definitely clarify my concern. If there is no constraint in the sample budget, it is possible (perhaps expected) that the MFRL agent would perform better.
In Section 4.3, the claim of “not sacrificing generality” is questionable. There is a small drop in performance. For instance, in Appendix J (DMC-proprio), DreamerV3 is (at least) slightly better in 6 tasks. In Appendix K (DMC-Vision), 8 environments. In Appendix L (Atari), 10 environments. I suggest rephrasing the claim to account what is observed in the Appendices.
The work from Deng et.al [1], proposing S4WM, looks very similar to the proposed one. Indeed, both works propose replacing the RSSM with SSMs with the same motivation: improving memory capabilities. The work on S4WM was publicly released approximately 2.5 months before this submission, which can be seen as concurrent work. Nevertheless, I believe the work is almost overlooked by the proposed paper, which has a small citation in Section 5. Given the similarity, it would be crucial to provide a more detailed comparison contrasting both works, in terms of methodology and evaluation, perhaps in the Introduction or in a separate Appendix.
Minor Concerns
In Appendix H, task Autoencode: the episode length for the Hard task is 156. Is that right? I believe it is supposed to be 256.
References
[1] Deng et. al. Facing off World Model Backbones: RNNs, Transformers, and S4. NeurIPS, 2023.
Summary of the Review
The work brings an effective improvement on World Models due to a well-motivated employment of State Space Models. This validates this architecture and extends its effectiveness in dealing with sequences in RL. The work does a great job in empirical analysis, anticipating many questions and answering them with extensive experiments and ablations. On the other hand, I believe the paper could be improved if the aforementioned concerns were addressed. Nevertheless, these concerns are not critical enough to prevent acceptance.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Mastering Memory Tasks with World Models","Keywords: model-based reinforcement learning, state space models, memory in reinforcement learning","Limited contribution. It is notable that there already exists a S4-based world model, namely S4WM [1]. Despite minor design choices, the major difference of this paper is that it conducts MBRL experiments while S4WM only conducts world model learning (e.g. imagination and reward prediction). However, in my humble opinion, it is not surprising that improvements in long-term memory can lead to improved MBRL performance in memory-demanding domains.
Three kinds of actor and critic inputs are introduced, namely, output state, hidden state and full state, which results in a critical design choice to be tuned for each domain. Although the authors provide some takeaways to select between them, it is not always true. For instance, output state policy is utilized in memory-demanding environments, Bsuite, while hidden state policy is used in non-memory environments, DMC.
The authors claim that R2I does not sacrifice generality for improved memory capabilities. However, there is a clear trend in Figure 6, that R2I performs worse than Dreamer in standard RL tasks.
Some inaccurate statements. For example, the authors say R2I's 'objective differs from ELBO in three ways', but to my knowledge, these three points are all borrowed from DreamerV3 but without explicitly being mentioned in the text.
[1] Deng et al. Facing off world model backbones: Rnns, transformers, and s4.","6: marginally above the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.","Keywords: Monte Carlo, Denoising Diffusion model, score-based generative models, Sequential Monte Carlo, Bayesian Inverse Problems, Generative Models.","It would have been intriguing to explore the performance of the MCGDiff algorithm on non-image data. While the research focuses on image-related tasks, extending the investigation to other data types would provide a broader perspective on the algorithm's applicability and effectiveness across various domains.","10: strong accept, should be highlighted at the conference","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.","Keywords: Monte Carlo, Denoising Diffusion model, score-based generative models, Sequential Monte Carlo, Bayesian Inverse Problems, Generative Models.","The paper is detailed and the appendices can be hard to read. The authors don't really solve inverse problems in the traditional sense. They generate realistic samples learned from a distribution that are consistent with the observations. While this sounds exactly like solving inverse problems, the resulting images, although better than existing methods and very sharp and detailed, only resemble the ground truth. I mention this because these types of methods cannot yet be used in sensitive contexts like medical imaging or science in general. There is a lack of control and interpretability on the generated images, as with all the current diffusion methods. The code issues have not been addressed. From looking at the source, the diffusion code seems to be based on DDPM, which is not acknowledged in the main text or appendices. Speed issues have not been mentioned. The bibliography is excellent except for the first paragraph of the introduction. Linear inverse problems as described have been studied mathematically for a very long time (Fredholm, etc) and in computer vision since the late 1980s at least. Perhaps the bibliography should mention this.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.","Keywords: Monte Carlo, Denoising Diffusion model, score-based generative models, Sequential Monte Carlo, Bayesian Inverse Problems, Generative Models.","The authors comment that standard image metrics, e.g. FID, are not suitable for evaluating Bayesian reconstruction methods for solving inverse problems. Results from a handful of examples of inverse imaging problems are presented, which all look very compelling. Nevertheless, it would be useful to summarise performance over a larger set of test images, if possible.","10: strong accept, should be highlighted at the conference","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.","Keywords: Monte Carlo, Denoising Diffusion model, score-based generative models, Sequential Monte Carlo, Bayesian Inverse Problems, Generative Models.","It seems the contribution point 3 is mainly a support for the first two points, hardly it can be classified as an independent contribution.
A pseudo-code or diagram describing the idea of this method would make it much easier to be interpreted
This method should be pretty slow as both diffusion model and particle filter are computationally heavy ones. Would be good to clearly state the limitation and also report the runtime etc.","na","6: marginally above the acceptance threshold"
"Self-Alignment with Instruction Backtranslation","Keywords: large language models, self-supervised learning, data augmentation","While instruction tuning backtranslation is a useful method, it is not clear how it compares with self-instruct. If the same seed dataset had also been used to generate instruction tuning data from the same base LLM, that would provide a good comparison. The distilled models considered in the paper have been trained on different seed datasets and use more powerful LLMs for distillation. Although I don’t see this as a serious limitation of the paper, this study would have helped shed light on how the two approaches compare.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Self-Alignment with Instruction Backtranslation","Keywords: large language models, self-supervised learning, data augmentation","No obvious weakness but it would be better to clarify the choices of unlabeled data for augmentation.","n.a.","8: accept, good paper"
"Self-Alignment with Instruction Backtranslation","Keywords: large language models, self-supervised learning, data augmentation","The paper assumes that the seed model M0 can somehow provide meaningful evaluation for the generated instructions by just following instructions. This might need further investigation. For example, M0 could be just selecting instructions that are similar to the seeds while discarding other instructions which are still useful but may vary in style or format, etc. Also, the work could consider other filtering methods such as using the language modeling probabilities as the scores or using external models such as those trained with NLI.
The paper assumes that a proportion of the unlabeled data should have the corresponding instructions which is not quite intuitive. One limitation is that this might greatly limit the types of instructions that the backtranslation model can generate. I would suggest a further study to understand the types of segments that do have meaningful instructions and the types of instructions that we could collect from the web corpus.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Self-Alignment with Instruction Backtranslation","Keywords: large language models, self-supervised learning, data augmentation","no significant negative issues.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Learning Interactive Real-World Simulators","Keywords: Generative simulator, simulating real-world interactions, planning, reinforcement learning, vision language models, video generation","While this work shows great promise in a range of downstream applications. I believe it might need more experimental evidence to support the claim that it can simulate low-level actions well. Specifically, section 4.2 only shows results for a relatively simple object (mostly blocks) re-arrangement (without grasping, e.g.) on a table. What about grasping objects, pulling objects (e.g., opening a drawer), etc? It will give us insights as to how fine-grained the controls are supported by the proposed simulator, even if it cannot simulate low-level actions perfectly.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Learning Interactive Real-World Simulators","Keywords: Generative simulator, simulating real-world interactions, planning, reinforcement learning, vision language models, video generation","I expect that this paper will comfortably clear the bar for acceptance. However, there are two main issues I believe should first be addressed. I've set my score relatively low because of these, but anticipate increasing it following a revised version.
Whilst it's difficult to accuse the paper of overclaiming in any specific place, the writing and framing risk feeling a little showy. The title is very general, and applies to any paper on model-based RL for the real-world rather than something specific to this paper, and naming the method a ""universal simulator"" feels grandiose. (Happy to collect other revewiers' opinions on this.) The connection between POMDP's and action-conditioned video generation is more-or-less assumed by any world model paper (e.g. [1]), and shouldn't be highlighted as a main contribution of the paper.
One of the recurring claims throughout the paper is that the major novelty is UniSim's ""orchestration of diverse datasets, each providing a different aspect of the overall experience"" into a single model. Yet no hard evidence is given for this combination being important -- aside from two vague figures in Appendix E. At a minimum, it would be important to train a version of UniSim on say, datasets from the Language Table environment only, and report numbers for when synthetic data was generated from this, in Table 2 and 3. This would help support the claim that dataset diversity is valuable.
Other issues (in decreasing priority)
I think it'd be useful to investigate how entwined the effect of actions is with the dataset distribution. For example, could camera commands (zoom in etc) successfully be applied to kitchen scenes as in Figure 3? The fact that the name of the dataset had to be included as part of the action during training, makes me suspect actions may not be able to generalise well to new kinds of video. This would not be a dealbreaker for the paper's acceptance, but is important to show readers how general this data mixing is.
A lack of strong baselines might be expected for this kind of scale-up work. But in their absence, ablations become more important, to verify that the various components of the model were all necessary. The paper only presents a brief study of which frames to condition on.
The model section is poorly written. The use of
T
is (I think) slightly misleading -- usually the transition fn of a POMDP is defined as operating on the states,
T(st,at)→st+1
, and there is a separate emission function producing the observations,
p(ot|st)
. Eq. 1 implicitly combines these -- I might recommend renaming it
f
or
g
or whatever. I didn't follow why
ol
notation needed to be introduced, since it's immediately unrolled into
[ot,ot+1]
and never referred to again. I also didn't understand why the model conditions on the noised, rather than clean, previous observations. It's said the last four frames are concatenated from
ot−1
, which confused me -- does
ot−1
represent four frames, or should it read
ot−1:t−4
or similar?
It's a shame to give the model details only in the Appendix C, as I believe many readers would be interested in them. I hope some of these can be shifted to the main body, particularly key details around the diffusion architecture (such as the core and super-resolution modules) and the amount of compute required.
Any algorithmic or model novelty is light (more or less straightforward video diffusion).
The two main experiments were conducted on environments that were within the training distribution of UniSim. It would have been more impressive to investigate the performance on new environments.
The wordy description of all datasets in 2.1, I felt was much better summarized by Table 5 in the Appendix (perhaps with the addition of a column explaining how an action space is defined and handled), and might be swapped. (Optional!)
Minor issues/questions
Appendix says 1M steps on 512 TPUs with batchsize 256 -- this seemed a low ratio of training updates to available compute. Did performance saturate beyond this?
What was the wall clock time of the model training?
How many parameters were in the model?
Will the model weights be open-sourced?
[1] Transformers are Sample-Efficient World Models","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Learning Interactive Real-World Simulators","Keywords: Generative simulator, simulating real-world interactions, planning, reinforcement learning, vision language models, video generation","I think the paper presents a very important step towards learning a universal video predictive world model. One of my questions is, the shown demo looks like generally still in distribution, in terms of generalization across different embodiment: the generated video contaiing robot are very similar to robotic dataset, and in more complex scenes training using human videos the model seems only handling human hands. How does it work in those complex scenes when the model is commanded to predict outcomes given a robot action input? Also, when it comes to low level control input, the paper seems only handling delta motion in the cartesion space. Does it handle more general end-effector action in SE3 space? (joint space seems out of reach for this family of method since it's not observable) Is it true that for predicting outcomes conditioned on robot action, the robot arm needs to be visible in the first place?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Learning Interactive Real-World Simulators","Keywords: Generative simulator, simulating real-world interactions, planning, reinforcement learning, vision language models, video generation","It would be nice if the paper delved more into the limitations of the models. The paper has shown that exciting results can be obtained, but it's useful for the community to know the limits of the generalization capabilities, especially if people want to use this in the future for various applications.
For reproducibility, it would be helpful if the authors could release the code and some example pre-trained checkpoints.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning","Keywords: partial label learning, label disambiguation, candidate label set pruning","More empirical analysis in the experiment should be presented, such as which PLL algorithms are more sensitive to the pruning method.
More explanations on bad cases are needed to show the limitation of the proposed method.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning","Keywords: partial label learning, label disambiguation, candidate label set pruning","The numerical simulation experiment about the calculating of values and conclusions is not shown clearly enough.
The PASCAL VOC dataset used in the experiment is not introduced well, as the dataset is not originally for partial label learning.
Detail of trained feature extractors (ResNet-SSL, ResNet-S) is shown unclearly.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning","Keywords: partial label learning, label disambiguation, candidate label set pruning","Weaknesses:
My major concern is that the proposed method will transform a PLL problem into an UPLL problem, which is more challenging due to the existence of the correct label may not be guaranteed in the candidate label set. Although it provides an upper bound of the per-example pruning error rate, the negative impact of eliminating the correct label from the candidate label set is still unknown.
The proposed method is dependent on the KNN algorithm, which should be given more details in the main body of the paper. For example, it could be found in the appendix that the KNN algorithm are implemented on the output of a feature extractor. However, what the feature extractor comes from is unknown.
[1] also attempts to filter out the incorrect candidate labels, which is suggested to be considered in related works, and even experiments.
[1] Xu, Ning, et al. ""Progressive purification for instance-dependent partial label learning."" International Conference on Machine Learning. PMLR, 2023.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning","Keywords: partial label learning, label disambiguation, candidate label set pruning","No big problem, only some minor issues, such as, typo, vague expression, and missing reference.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Robust agents learn causal world models","Keywords: causality, generalisation, causal discovery, domain adaptation, out-of-distribution generalization","As the authors acknowledge, the results are mainly theoretical. Even a minimal empirical validation of the key insights would strengthen the paper. For example it would be great even if you turn the informal overview (appendix C) into a simple simulation example rather than remain a thought experiment.
The scope is currently limited to unmediated decision tasks. Extending the results to broader RL settings would increase applicability (although I acknowledge that seems significantly more challenging task and out of scope of this work - it’s just a personal curiosity at this point and would be excited to see the next paper already).
The proof is still quite challenging to understand and I believe that there a more informal / simplified sketch that can be introduced to help the reader before dive into the more formal proof.
On a similar note, the implications of the assumptions are not discussed. (e.g. I’d like to see things like, “assumption 2 implies that there exist distribution shifts for which the optimal policies are different”.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Robust agents learn causal world models","Keywords: causality, generalisation, causal discovery, domain adaptation, out-of-distribution generalization","The only weakness, in my opinion, is that the statement of the result in the introduction felt pretty slippery. (See detailed comments below.) All of this was satisfyingly resolved, but I do think the paper would benefit from an effort to sharpen that first section.
Details comments:
Please define these: ""distributional shifts"" ""distributionally shifted environments"" ""target domains"" ""causal modelling and transfer learning""
"" used to derive out results"" typo
""Our analysis focuses on distributional shifts that involve changes to the causal data generating process, and hence can be modelled as interventions (Schölkopf et al., 2021)"" This would have been nice in the intro.
""This does not assume that all shifts an agent will encounter can be modelled as interventions, but requires that the agent is at least capable of adapting to these shifts."" I don't know that I understand this sentence.
""By cCreftheorem: main,theorem: main approx agents"" typo?","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Robust agents learn causal world models","Keywords: causality, generalisation, causal discovery, domain adaptation, out-of-distribution generalization","They do not conduct an experiment for justifying their results.
Their results can only be applied to a small range of scenarios, where we need to reach small regret for all mixture of local interventions. However, most applicable tasks, such as transfer learning, only consider interventions on a subset of variables.
There are some spelling mistakes in their text, and some usage of notations are unclear in their text and proof.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Robust agents learn causal world models","Keywords: causality, generalisation, causal discovery, domain adaptation, out-of-distribution generalization","Only necessary condition is proved but not the sufficient condition. It will be stronger to prove something like, if the agent has learned some ""approximate"" causal relationship, it can efficiently learn the optimal decision under distribution shift.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs","Keywords: LLM, Benchmark, Evaluation, Psychometrics","The conclusions drawn relative to any ""average human population"" performance is suspect. The human benchmarks in most cases are rather weak because of their locale/cultural biases and small sample sizes, e.g. ""six high schools in China"" for BFI, ""undergraduate psychology students from the United States"" for DTDD, or ""Hong Kong students"" in ICB. All of these are taken from seminal works (Table 6) are they aren't the only the studies that use each of the scales, so I think scales themselves are okay especially when considered as an array; however, the interpretation of experimental results then becomes much weaker because of these biases and small-N in the human benchmarks. I think the authors did make an honest attempt about being transparent about the demographic distributions in the Appendix, but in the main paper discussion I think the claims are still overreach and/or require additional caveats.
It would've been good to have some brief discussion on the prompt design impact, e.g. why was ""helpful assistant"" necessary? Do things break otherwise? Such a persona prompt may already implies certain caveats on psychological portrayal conclusions, e.g. only when an LLM is ""acting"" like a ""helpful persona"" is a ""empathic"" as defined/measured by the EIS, WLEIS, and ES.","I think it's important that this paper include a statement that achieving certain levels of performance on the proposed benchmark does not imply fitness for related use cases. I think it's important to distinguish the (good) framing of the paper of psychometrics for LLMs—which focuses on a scientific inquiry of understanding LLMs—from the applicability of an LLM for say automated counseling or companionship use cases, simply because it clears a high score on the Emotional Abilities tests (Section 3.2.4. / Table 4). A high performance on the benchmark benchmark should not be seen as a certification for use.","8: accept, good paper"
"On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs","Keywords: LLM, Benchmark, Evaluation, Psychometrics","The main weakness of the paper rests with its significance considering the amount of previous research in the field, of which the authors are aware as per Section 5 of the paper. This is of particular importance when comparing to work such as Safdari et al. [2023] (in the paper's references) whose methodology might appear more sophisticated than the direct application of questionnaires in this paper.
There is no real discussion of the work limitations, either in terms of actual results and findings, or in terms of the overall framework. In particular considering the latter, it seems questionable that all psychometric aspects of LLM could be considered as equally relevant or justifiable. For instance, emotional competence of LLM (see e.g., Elyoseph et al. [2023]) can be attributed technically to their sentiment analysis ability and, in terms of training data, could be attributed to various sources (including fiction). In the specific case of empathy, it might be appropriate to distinguish between emotional competence and Theory of Mind. For the latter, it is mentioned in Bubeck et al. [2023] (in the paper's references) that GPT-4 has some ToM abilities in particular that of passing a modified version of the Sally Anne test (modified to ensure non inclusion in the training dataset). There was no real discussion on this aspect, not least in relation to the training base in case it includes fiction, following the hypothesized impact of fiction on empathic abilities [Kidd and Castano, 2013]. So, clearly a more in-depth discussion in 3.2.4 would have been welcome. As far as personality is concerned, since this paper comes after previous work and claims to be providing a more consistent framework, one would have expected a more in-depth discussion on the relationship between personality and personas at the technical level, i.e. the assistant roles that might be activated under certain circumstances, in particular as the ""Likert Prompt"" of page 4 makes an explicit reference to the LLM being/acting as a ""helpful assistant"". Such embedded personas can be reflected in the high scores of Agreeableness throughout the LLM, which even jailbreaking fails to decrease below Crowd average.
Kidd, D.C. and Castano, E., 2013. Reading literary fiction improves theory of mind. Science, 342(6156), pp.377-380. Elyoseph Z, Hadar-Shoval D, Asraf K and Lvovsky M (2023) ChatGPT outperforms humans in emotional awareness evaluations. Front. Psychol. 14:1199058.","N/A","6: marginally above the acceptance threshold"
"On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs","Keywords: LLM, Benchmark, Evaluation, Psychometrics","Instructing LLMs to respond with Likert scale numbers oversimplifies their responses and may not capture the richness and nuance of their capabilities. Some psychological aspects are complex and may not be adequately represented by a single number.
The prompt design appears overly simplistic. It raises questions about how the results might vary with the use of different prompts. Additionally, how will the result change based on the utilization of a more complex ""chain-of-thought"" prompt?","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Diffusion Model for Dense Matching","Keywords: Diffusion Models, Visual Correspondence","I do not have major concerns on the paper less lacking some details. One notable improvement will be adding more discussions to diffusion based dense prediction networks, especially methods like DDP [1]. It is questionable to me why DDP is not directly applicable to the task of dense matching. Another possible improvement is to add diffusion-based dense prediction models as baselines to the method (\eg a DDP model trained on dense flow supervision).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Diffusion Model for Dense Matching","Keywords: Diffusion Models, Visual Correspondence","""These approaches assume that the matching prior can be learned within the model architecture by leveraging the high capacity of deep networks""
For the argument in the paper to be more compelling, the above statement needs to be clarified. Exactly how is the prior ""learned within the model architecture""? Can we say something more precise about how the prior is captured, and how much of it, in these earlier methods?
How many samples were used to compute the MAP estimates used for statistics in the tables, as per Section 4.6? And were these samples chosen i.i.d. from the standard normal distribution?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Diffusion Model for Dense Matching","Keywords: Diffusion Models, Visual Correspondence","a) Possible generalization concerns and limited experimental evaluation: modeling a prior on what a good matching field looks like using a diffusion model exposes the proposed solution to generalization problems since the prior will only model the type of matching flows seen during training. For example in the extreme case where the method is trained only with match fields coming from homographies it will probably not generalize well to other types of non-rigid transformations between frames. The competitors have this type of limitation in a less pronounced way since they focus on improving feature extraction and matching rather than modeling a global prior on what a “good matching field” should look like. Whether this problem arises in practice is hard to estimate from the current paper since the experimental validation is rather limited compared to the main competitors.T he proposed method is evaluated only on two datasets for dense correspondence matching and on two corrupted versions of the same datasets. Competitors like GOCor, PDCNet and PDCNet+ are evaluated on other datasets (e.g., MegaDepth and RobotCar) and additional correspondence tasks (e.g., Optical Flow on KITTI, Pose Estimation on YFCC100M and ScanNet).
b) Inference time concerns: Tab. 5 of the paper compares the inference time of PDCNet(+) vs the proposed method with 5 sampling steps and shows that the two proposals are comparable. However in Sec. 4.6 the authors mention that in practice they sample multiple times and average the diffused fields to get the final performance. Depending on how many samples are drawn it will have an impact on the runtime making it grow significantly. From the current paper it is unclear if this multiple sampling strategy is used in the experimental validation ro only in Appendix C.2 and whether the inference time of Tab.5 are taking this into account or not. If not (as it seems like from the text) the inference cost will be significantly higher than competitors.
c) More ablation studies and unclear dependency on the initialization: the core of the work is the use of a diffusion model to refine an initial estimation of a matching field (
Finit
). From the paper it is unclear how much the prior is able to recover in case of a bad initialization or not and whatever, if possible, the model will need more diffusion steps to recover from a bad conditioning. I would have liked these aspects to be discussed as part of the ablation study. Another interesting ablation that would have nicely complemented the work would have been using the dense cost volume as conditioning to the diffusion process. If the concern is around hardware limitations a test should still be possible at lower resolutions.","No concern","8: accept, good paper"
"Diffusion Model for Dense Matching","Keywords: Diffusion Models, Visual Correspondence","Novelty : The novelty is somewhat limited to the specific design of the conditioning to the diffusion model. Computation of cost volume using pretrained network have been used in many flow computation networks (as in Glu-Net). In particular, the main novelty is the smart choice of inputs and outputs for the diffusion model. Elaborating a bit more on the challenges of the design will help highlight the novelty of this approach.
Generalization: The framework shows impressive performance on dense matching for the given datasets, but providing a sense of how generalizable this is to in-the-wild captures, is potentially helpful.
Performance limits: The qualitative example demonstrated show dense correspondence matching for relative simple transformations between source and target. Providing some insights about how the framework performs for wide baselines or for settings with large viewpoint changes would be helpful.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video","Keywords: self-supervised image-pretraining, egocentric video, Walking Tour dataset, multi-object tracking","I'm a bit confused about Table 4: Video Object Segmentation (DAVIS-2017). In the DINO paper they report ViT-S/16 with INet getting 61.8, 60.2, 63.4 respectively (their Table 5), however your Table 4 reports DINO as getting 59.4, 57.4, 61.4 what accounts for this difference?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video","Keywords: self-supervised image-pretraining, egocentric video, Walking Tour dataset, multi-object tracking","Scalability concern. Although the proposed method does outperform DINO on all reported experiments in controlled experiments (i.e., with the proposed WT dataset), the results with even WT_{all} is still not clearly better than DINO with ImageNet-1k. This leaves it unknown whether the WT dataset will eventually outperform ImageNet-1k (or the even larger ones like ImageNet-22k and LVD-142M) with the dataset at a reasonable scale. Also the experiments are mostly on ViT-S, which is relatively small compared to the well-known works in the field (which usually report at least ViT-B), so it is also hard to tell whether the proposed method scale well with the model size.
Significantly worse results on image classification. I have noticed that the image classification results of WT-pretrained models are lower than ImageNet-1k-pretrained by a fairly large margin (45LP / 36KNN on WT vs. 72LP / 70KNN on ImageNet). Although one can argue that this is because of the domain gap between WT and IN, I would consider the accuracy difference large enough to require some formal justification (e.g., run WT and IN pretrained models on a 3rd classification dataset like iNaturalist or Places) to conclude that the WT-pretrained models are not significantly weaker on image classification tasks.
The potential privacy and safety issues of the dataset. Also see Details Of Ethics Concerns. As the paper claims the dataset as a main contribution, I would expect more efforts in assessing the privacy and safety issues in the dataset (e.g., How many clear faces are detected and what are their resolutions? How many harmful scenes are detected to the best effort of the authors?) and clarifying the legal issues and usage restrictions of the dataset (e.g., Is it possible that some videos are taken down upon the request from people appearing in them? Is their usage in some jurisdictions not allowed / limited to non-commercial only? What are some possible negative effects if the models remember the private information in it? What are the possible effects of some common mitigations, like blurring the faces in Google street view?)","The paper proposes a new dataset consisting of 23 hours of UHD (4k) videos filmed on the public streets which may contain personal information like high resolution faces of strangers and audio recordings of the nearby people talking (very likely) without their consent. Although the videos are not filmed by the authors themselves and are in CC-BY licenses on YouTube according to the paper, I'm concerned that it needs a careful discussion regarding the compliance issues or restrictions of using them for machine learning purposes (or even posting them on YouTube in the first place) in different jurisdictions.
There is also no assessment or mitigation about the potentially harmful scenes (e.g., violent, harassing, criminal) in the proposed dataset.","6: marginally above the acceptance threshold"
"Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video","Keywords: self-supervised image-pretraining, egocentric video, Walking Tour dataset, multi-object tracking","The paper mainly talks about how we can learn discriminative representations from egocentric videos, whereas what kind of egocentric videos are suitable for DoRA is not deeply discussed. It would contribute more to the community if we knew what properties a video should have to be worth learning.
A good SSL method should be scalable, not only on the dataset but also on the model structure. It would be better for authors to show more results on larger ViTs.
Some minor writing problems. (1) in Sec. 4 “Discovering objects with multi-head attention”,
Q~
,
Kt~
are only defined in Fig.3 and are not defined in text. (2) In Fig.3 (Left), the input should be
Xtoi","None.","8: accept, good paper"
"Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video","Keywords: self-supervised image-pretraining, egocentric video, Walking Tour dataset, multi-object tracking","One minor issue I have about the presentation is the introduction of the tracking module. The tracker is not learned, and it is only used to provide object locations. I would like further discussion on the potential use of the corresponding information. Also, a comparison on the effect of using different types of unsupervised trackers would also help strengthen the work as the major idea seems to be not dependent on a certain type of tracker.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video","Keywords: self-supervised image-pretraining, egocentric video, Walking Tour dataset, multi-object tracking","Performance on ImageNet linear probing seems low. While I understand that video-pretrained models have a disadvantage over image-pretrained model as they can’t be pretrain ‘in-distribution’ with respect to imagenet. However, ImageNet is a standard vision task. It is important to understand why there is such a gap between image and video models on this evaluation.
The DINO baseline is trained for 100 epochs only which is not the default setting. Additionally, DINO paper reports a performance of 61.8 with a VIT.S/16 on Davis while the paper reports of 54.6 for the same method. I would encourage the authors to report what are the performances of the DINO released models as those models are available.
DORA shares some similarity with the VITTO. Both approaches learn from video and use an 'unsupervised' pooling mechanism. However, DORA seems to underperform VITTO on the ADE20K and MS-COCO tasks.
Missing comparison with more recent baselines. It would be nice to add comparison with DINOv2 and a weakly-supervised baseline OpenCLIP, which are both state-of-art methods.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Neural Fine-Tuning Search for Few-Shot Learning","Keywords: stochastic, neural, architecture, search, few, shot, learning, adapters","Empirical results reported lack confidence intervals. Although I suspect this is due to space limitations, they should be included to verify the statistical significance of the results report and for better comparison with baselines. If some results do not meet statistical significance, they must be modified when presented in results tables to reflect so accordingly and the claims made need to be adjusted.
Ablation study on search paths shows that N=3 not only provides better computational efficiency but additionally prevent overfitting on the support set. How does it compare with N=2 or N=4? I believe that further insights here would be useful as to how this hyperparameter is set. Furthermore, how does performance vary depending on N across ViT and ResNet?
Meta-dataset baselines that are compared to omit some recent methods that can be included for completeness of comparison [1, 2, 3].
[1] Improved Few-Shot Visual Classification [2] CrossTransformers: spatially-aware few-shot transfer [3] Enhancing Few-Shot Image Classification with Unlabelled Examples [4] Beyond Simple Meta-Learning: Multi-Purpose Models for Multi-Domain, Active and Continual Few-Shot Learning","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Neural Fine-Tuning Search for Few-Shot Learning","Keywords: stochastic, neural, architecture, search, few, shot, learning, adapters","The results lack significance compared to the additional training required to obtain NFTs. The method requires training a supernet, performing an evaluation to find the best subnet. As NFTs achieve only a less than 1% accuracy gain on the Meta-Dataset in a multi-domain setting, the method is excessively computationally expensive and inefficient when compared to the actual performance gain.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Neural Fine-Tuning Search for Few-Shot Learning","Keywords: stochastic, neural, architecture, search, few, shot, learning, adapters","(-) The authors stated the superior performances in various experimental settings. However, the author didn’t specify the structure and the number of parameters.
(-) There is no ablation study on the two-stage search for optimal path (sec. 2.4): the best-performing path during training time, the searching path at test time, and the proposed hybrid one.","None.","6: marginally above the acceptance threshold"
"Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time","Keywords: Distribution Shift, Temporal Distribution Shift","Learning neural SDEs is traditionally successfully presented in the framework of variational Bayesian inference (e.g. Li et al. 2020), where stochastic gradient descent methods are applied to minimize the evidence lower bound (ELBO). I wonder why the authors do not clearly address the reference to variational Inference in the manuscript, especially since the indications (e.g., the graphical model in Figure 1, derivation of the likelihood loss of IFGET in Lemma B.1) are given.
The Sine experiment (Figure 3) is arguably a rather simple problem from a dynamic point of view and yet already indicates the limited extrapolation quality of the approach. Of course, this reduces my confidence in the generalization ability of the approach. I suspect possible causes in (i) an unfavorable modeling of drift and diffusion coefficients and (ii) that the linear interpolation approach in the IFGET module is too coarse. Can you comment on this?
The IGET module reminds me on a approach by Kidger et al. 2020 (Neural Controlled Differential Equations for Irregular Time Series) in which the authors also try to improve the learning of latent trajectories by including interpolated sample trajectories, in their terms a ""controlled path”. This is done in the ODE setting, but can be integrated into the SDE setting if the approach is applied to learning the drift coefficient. Can you explain in more detail how your approach differs?","--","8: accept, good paper"
"Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time","Keywords: Distribution Shift, Temporal Distribution Shift","In one iteration, for two consecutive domains, only one interpolated sample is generated. Can more than one sample be generated and used? For example, we can first generate one interpolated sample via Eq.5 and then set this sample as
z~m+1
to generate the second sample. If so, how does this influence the performance?
Table 2 shows that smaller temporal gaps improve the generalization ability. How is the improvement of SDE-EDG over the baseline when using different time intervals?","8: accept, good paper","1: You are unable to assess this paper and have alerted the ACs to seek an opinion from different reviewers."
"Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time","Keywords: Distribution Shift, Temporal Distribution Shift","The illustration of continuous-interpolated samples is not very clear. I am a little bit confused about why the samples generated with linear interpolation method are called ""continuous"".","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time","Keywords: Distribution Shift, Temporal Distribution Shift","1 I doubt the existence of evolving dynamics. It's worth considering scenarios where time-related tasks might lack evolving patterns and instead exhibit random shifts.
2 Linear interpolations may not reflect the true evolving trajectories, since the real evolving trajectories might be nonlinear and complex.
3 Considering that IFGET is an approximation, and the existence of ground truth sample-to-sample correspondence is uncertain, how do we guarantee that IFGET accurately represents the real evolving trajectories?
4 The authors conducted an ablation on weighting on IFGET; however, I am curious about the performance of IFGET without continuous interpolations, which will show whether continuous interpolations improve generalization to sparse timestamps.
5 I understand neural SDEs that neural SDEs do not rely on the assumption of the model being uni-modal, in contrast to prevelant uni-modal Gaussian distributions. However, most deep learning methods assume the classification tasks to exhibit uni-modal characteristics through using ERM classification loss. Therefore, I am wondering whether uni-modal or multi-modal classification loss contributes to the accuracy improvement of SDE-EDG in EDG.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Less is More: Fewer Interpretable Region via Submodular Subset Selection","Keywords: Interpretable AI, Submodular subset selection, Explainable AI, Image Attribution","The idea of decomposing an input image
I
into regions has been studied for several vision tasks like self-supervision (Noroozi et al., 2016 etc.), object detection (Redmon and Farhadi, 2018) etc. These should be cited and the differences should be called out.
The use of saliency maps
A
in sub-region division is unclear. The paper should highlight how saliency maps are used to evaluate patch importance.
Most of the scoring functions like
seff.
,
scons.
etc. rely on cosine similarity or distance metrics which have been studied extensively in literature (Deng et al., 2018, Wang et al., 2018 etc.) but have not been cited in the paper.
The paper lacks the explanation regarding how individual scores contribute to achieving their respective objectives. For example,
scolla.
employs a cosine distance metric between the semantic feature vector of the target class
fs
and features extracted from the residual regions of the original image when the selected subset of regions
S
is removed. To the best of my knowledge, maximizing this metric ensures that the collective impact of the selected region is sufficient to generate explainable representations.
The proposed greedy search algorithm (section 4.3) has been studied for subset selection tasks (Wei et al., 2015) and is therefore prior art.
The paper misses a critical reference in submodular optimization (Fujishige, 2005) and should include it in the related work.
The experiments should include ablations on
k
which is the number of sub-regions selected from
V
.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Less is More: Fewer Interpretable Region via Submodular Subset Selection","Keywords: Interpretable AI, Submodular subset selection, Explainable AI, Image Attribution","Some suggestions for minor improvements:
The phrase ""... at the level of theoretical aspects.""at the introduction sounds a bit too wordy. It can be expressed more concisely.
This sentence in the introduction ""Image attribution algorithm is a typical interpretable method, which produces saliency maps that explain how important image regions are to model decisions."" can be better phrased, in my opinion, as ""... that explain which image regions are more important to model decisions.""
I don't think fine-grainedness (page 2) is an actual word. Fine-graininess may be an alternative but I am not sure.
On page 2, the word ""...datasets."" at the end of the first sentence of the second paragraph needs to be omitted.
Contrary to what has been said on the introductory sentence of the White-Box Attribution method paragraph, I don't think there is a THE image attribution algorithm. I advise the authors to state either the name of the specific algorithm they are mentioning or use the plural.","6: marginally above the acceptance threshold","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Less is More: Fewer Interpretable Region via Submodular Subset Selection","Keywords: Interpretable AI, Submodular subset selection, Explainable AI, Image Attribution","In Algorithm 1, I didn't see the use of variable k. Should n of line 3 be k?
In Table 1, why are some results of LIME and Kernel Shap not reported? Is it because these attribution algorithms have limitations on the CUB data set? Hope the author can explain it.
It would be better if the authors could discuss the limitations of this method.
Can the author further state whether the proposed method is white-box based or black-box based (assuming that the calculation of a priori saliency map is not considered)?","No ethics concern.","8: accept, good paper"
"Less is More: Fewer Interpretable Region via Submodular Subset Selection","Keywords: Interpretable AI, Submodular subset selection, Explainable AI, Image Attribution","In Section 5.3, for the discover the causes of incorrect predictions, the author only verified it on ResNet and achieved good quantitative results. It would be more convincing if the author could try to add some backbone, such as VGGNet.
Why are the results of LIME and Kernel Shap under CUB data not reported in Table 1?
In Table 2, the saliency map without a priori seems to be better than the method of adding a priori saliency map in terms of average highest confidence evaluation metric. Can the author add an ablation experiment to observe the impact of different partition sizes on the results without adding a priori saliency map, such as 8x8, 12x12, etc.
In the introduction, “and a fine-grained dataset CUB-200-2011 (Welinder et al., 2010) datasets” -> “and a fine-grained dataset CUB-200-2011 (Welinder et al., 2010)”
In Algorithm 1, the input k is not used, please check carefully.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Cameras as Rays: Pose Estimation via Ray Diffusion","Keywords: 3D Computer Vision, Pose Estimation, Diffusion","One dataset is too small to see the applicability of a method. Since I see this method as superior to ""PoseDiffusion"", it would be great to see some results on the ""scene-centric"" dataset and compare it against PoseDiffusion.
It would be nice to see a ""memory"" requirement to run these models. Processing N image features together, I am assuming requires a good amount of GPU memory.
It would also be nice to see accuracy at different thresholds i.e. @5, @10, @15.
It would also be nice to see an ablation study where we do not scale the poses. Most of the applications require properly ""scaled"" poses.
The language is clear but I think the paper presentation is poor. Here are a few suggestions to improve the readability of the paper.
For e.g., Fig 2. is really confusing where the authors are trying to show the camera to ray-bundle and ray-bundle to camera process.
Fig 5. A qualitative comparison is hard to see and to make a good sense, as opposed to Fig 4 of PoseDiffusion paper for example.
Also good to say in eq (3) that ""d"" is obtained by unprojecting rays from camera pixel coordinates, and ""m"" is obtained by considering point ""p"" as the camera-center since all rays intersect at the camera center.
In section 4.3 evaluation Table numbers are wrong. Tab 10 -> Tab 1, Tab 4 -> Tab 2
Fig 6 is very confusing. I think this needs to be redone.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Cameras as Rays: Pose Estimation via Ray Diffusion","Keywords: 3D Computer Vision, Pose Estimation, Diffusion","The main weakness of this paper is the somewhat contrived and limited dataset and metrics used in the experimental results. The CO3D dataset consists of many turntable-like videos with a camera orbiting in a circle around a single object of interest at an approximately fixed distance. The variability of camera poses is quite limited compared to images in the wild. Furthermore the image is tightly cropped around the object of interest. This tight cropping ensures that most rays sampled pass through this common object in all views, which could provide added benefit to the propose approach. The cropping also provides a disadvantage to feature matching approaches such as used by COLMAP. COLMAP benefits from having a larger context of the scene with more features to match. However, the authors are just duplicating the experimental setup from prior work (RelPose), so they are not entirely at fault for these decisions.
The proposed algorithm also, presumably, does not estimate precise camera parameters and would need a further bundle adjustment step to achieve sub-pixel accurate camera models with comparable accuracy to COLMAP (under the conditions where COLMAP succeeds). The metrics only measure if the camera rotation is within 15 degrees of correct angle and within 10% of the scene scale in position.
In terms of clarity of the work, one concern I have is that the authors often say ""sparse-view"" when it would be more accurate to say ""wide-baseline"". For example, the abstract states that 3D reconstruction remains challenging for sparse views (<10). It's not the reduced number of views that are the challenge, it's the wide baseline between those images. More traditional methods like COLMAP would do just fine on 10 images from more similar viewpoints.
Also, I found the camera visualization in Figure 5-9 to be confusing. Without the context of the 3D object or the coordinate system and with only a few cameras, it's hard to interpret what I'm looking at. In many cases it's not even clear which cameras belong to which algorithm's results.
Minor issues:
Typo on middle of page 4: ""the camera camera extrinsics""
References to Tab 10 and Tab 4 at the start of Section 4.3 seem to point to incorrect tables.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Cameras as Rays: Pose Estimation via Ray Diffusion","Keywords: 3D Computer Vision, Pose Estimation, Diffusion","The authors announce that the traditional representation of pose maybe suboptimal in neural learning in the part of introduction. However, no further discussion is given. More specific explanation is necessary, and the comparison with the proposed novel representation of pose is also required.
The punctuation is necessary at the end of each equation, please check it carefully.
The authors fail to state more details of the proposed network architecture. Moreover the training detail is also required.
To demonstrate the performance of the proposed novel representation, can authors undertake more experiments on more datasets?
Please check the format of REFERENCES.","5: marginally below the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Cameras as Rays: Pose Estimation via Ray Diffusion","Keywords: 3D Computer Vision, Pose Estimation, Diffusion","As reported in Table 1, it seems that the presented over parameterization method plays a crucial role in the framework. The performance of Ray Regression (Ours) surpasses that of R+T Regression by a considerable margin. The diffusion model only results in a 3.8% improvement in the case of two images. To my understanding, the superior performance is primarily attributed to the least-squares optimization which accounts for a robust estimation. However, it is still quite confusing why the pose estimation benefits from the ray representation.
Basically, the idea is to regress a ray represented as a 6D vector for each patch in the RGB image. It is arguably more challenging than predicting R and T. The difficulty lies in two aspects. First, it is a dense prediction problem. Second, it regresses 3D information from RGB images. One could also predict the corresponding 2D coordinates in the right image for each patch in the left image as an alternative. Intuitively, it is easier to predict 2D coordinates than 6D ray vectors. The authors argue that such a method could struggle in sparse view settings due to insufficient image overlap to find correspondences. It is unclear why the presented method is able to achieve better robustness.
Moreover, it is confusing why the presented method can recover the translation. According to Eq.3, m is coupled with the translation t. Predicting m then demands a requirement of capturing information about the camera translation. However, the actual input of the network is a cropped image. The information regarding t loses after the cropping.
The authors only conducted experiments on the Co3D dataset, which makes the evaluation not convincing enough. There are several datasets that have been widely used in the literature such as Megadepth, ScanNet, and HPatches. It would be beneficial if the authors could show the effectiveness of the over parameterization on such datasets.
According to Eq.7, the patches of all available images are jointly processed, which is computationally expensive. As reported by the authors, training the diffusion model takes four days on 8 A6000 GPUs, which is much slower than RelPose and RelPose++.","5: marginally below the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks","Keywords: Distributed Learning, Self-Repellent Random Walk, Token Algorithm, Central Limit Theorem, Asymptotic Analysis","see questions below:","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks","Keywords: Distributed Learning, Self-Repellent Random Walk, Token Algorithm, Central Limit Theorem, Asymptotic Analysis","All results are asymptotic. It is not clear (theoretically) whether there are gains for finite time, before eg. the token can visit most elements of
N
. The analysis requires some a priori assumptions about the ODE invoked for stochastic approximation. The analysis is heavily indebted to Doshi et al.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks","Keywords: Distributed Learning, Self-Repellent Random Walk, Token Algorithm, Central Limit Theorem, Asymptotic Analysis","The paper is mostly motivated by the recent progress of Dochi et al., and it is not clear what is the ""main"" novelty of this paper compared to the previous work (fundamentally). It seems to me that most results are refinements of Dochi et al. (while I agree that the setting is slightly different.) The authors may add a paragraph to highlight the main ""technical"" novelty of this paper.
Also the parameter
α
measures the ""heaviness"" of the self-repelling random walk, which is basically a hyper-parameter. It seems to be a bit strange to quantify the errors using
Poly(1/α)
(provided that one sends
α→∞
and I do have concerns on the real application in this regime). Also the idea of using self-repelling random walk to accelerate optimization is not new, see https://arxiv.org/abs/2005.04507 (in which it was shown to outperform many existing algorithms.) The authors may think of citing the work and some references therein.","Not available.","6: marginally above the acceptance threshold"
"Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks","Keywords: Distributed Learning, Self-Repellent Random Walk, Token Algorithm, Central Limit Theorem, Asymptotic Analysis","A concern in my mind is that the paper assumes
X
takes values in a finite state space. The decentralized optimization where only a single agent is active each time is a particular example. Are there any other examples where
X
takes finite value?
In my opinion, for a general SA method, the randomness or the noise could be various. Note that the Poisson method used in the proof is not limited to discrete randomness. Is it possible to extend the analysis to a more general setting where
X
could be a continuous random variable? If not, where is the main difficulty?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Detecting, Explaining, and Mitigating Memorization in Diffusion Models","Keywords: Diffusion Model, Memorization","This work can be written more clearly, especially the section of the introduction was not very well written. I found that section 3.2 motivation was particularly helpful in setting the pace for this work.
In terms of the experimental setting, I do believe that performing experiments to see how the memorization ratio changes with repetitions in the data set might be a great way to further solidify if the method works. In particular, this could follow directly from the setup of Somepalli et al.
I would love to see more images of memorized inputs and further discussion beyond the two images shown in the paper right now to get a better sense of the performance of this method.
Most pertinently, I see that the mitigation strategies lead to a significant drop in CLIP score. In particular, if you were to look at the region on the plot between the model initialization before fine-tuning and the final fine-tuned model, it is evident that, especially when you contrast with Figure B where all the points are between 0.29 and 0.3, the inference time mitigation leads to a significant drop in CLIP score. It is unclear if this method is actually useful in that regard. It suggests that we are unable to reach the same performance as that of a model that was never fine-tuned. I am curious what the authors feel about this particular observation. In particular, a model that was not fine-tuned had a higher CLIP score on the prompts, but the method using mitigation achieved a much lower CLIP score. I am not able to position these results with the overall setup.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Detecting, Explaining, and Mitigating Memorization in Diffusion Models","Keywords: Diffusion Model, Memorization","Clarifying the Concept of Memorization: Could you provide a clear definition of what constitutes memorization in this context? Does it require an exact match between the generated and training images? For instance, if there's a slight variation, such as a difference of 10 pixels from the original image in the training dataset, would that still be considered memorization?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Detecting, Explaining, and Mitigating Memorization in Diffusion Models","Keywords: Diffusion Model, Memorization","See above","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Detecting, Explaining, and Mitigating Memorization in Diffusion Models","Keywords: Diffusion Model, Memorization","While the mitigation strategies aim to reduce memorization, it's unclear what impact they might have on the overall performance of the model. Often, there's a trade-off between reducing a particular behavior and maintaining high performance. If these mitigation strategies significantly impair the model's utility, it might deter their adoption.
As stated in the paper, a weakness of the proposed method is the lack of interpretability in the detection strategy of memorized prompts. The current approach requires the model owners to select an empirical threshold based on a predetermined false positive rate, but the outcomes generated lack clear interpretability. This lack of clarity can make it difficult for model owners to fully understand and trust the detection process. The authors acknowledge that developing a method that produces interpretable p-values could significantly assist model owners by providing a confidence score quantifying the likelihood of memorization.
Advising users on modifying or omitting trigger tokens might be effective in theory, but in practice, it could be cumbersome. Users might need to understand what these tokens are, why they need to modify them, and how they affect the output. This could make the user experience less intuitive, especially for those unfamiliar with the inner workings of AI models.
The paper assumes that all prompts can be modified or that users will be willing to modify them. In real-world scenarios, some prompts might be non-negotiable, and changing them might not be an option.
While the paper suggests that the method is computationally efficient, implementing the strategies during the training and inference phases might still introduce computational or operational overheads for model owners.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How","Keywords: Finetuning, pretrained model hubs, transfer learning, hyperparameter optimization, meta-learning","In the ablation study, for the Micro and Mini cases, QT: -M, +C, +G (DyHPO with cost-awareness) performs as well as QT: +M, +C, +G (DyHPO with cost-awareness and meta-learning) which shows most of the benefit coming from the cost-aware aspect of QuickTune and not the meta-learning.
Novelty is limited since the core of Quick-Tune is DyHPO, a prior HPO method. Cost-aware acquisition functions have been used in the past and the approach of using meta-features and meta-learning good initializations for the estimators also lack originality.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How","Keywords: Finetuning, pretrained model hubs, transfer learning, hyperparameter optimization, meta-learning","Paper is strong and has thorough results. The one thing I was curious about was how the method performs on other standard benchmarks such as Imagenet, and whether any of these results can be validation on different domains (eg text datasets, where finetuning is also very common).","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How","Keywords: Finetuning, pretrained model hubs, transfer learning, hyperparameter optimization, meta-learning","I do not follow how the normalised regret is calculated. In particular how is y_max and y_min calculated? Is it provided by Meta-Album datasets? Is it the min/max of all runs ever done on this study? How significant is a 10% regret and is there any more expensive way to close that gap when using this approach?
The curves on plots like figure 3, shows a different behaviour between the methods. It is hard to predict if quick-tune always beats them or if that story changes as the wallclock time gets extended. It would be interesting to see if the search approaches regret 0 or stays ~10% above it.
One issue with model selection in particular with small datasets is overfitting, including to the validation set. I expected some discussion around this and also an explicit reference to which splits are used during which phase.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How","Keywords: Finetuning, pretrained model hubs, transfer learning, hyperparameter optimization, meta-learning","The paper only considers computer vision classification, while related works such as LogMe (You et al., ICML’21) consider various downstream tasks (classification and regression), and modalities (vision and language). It can be impractically expensive though to evaluate the approach on also these other settings.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models","Keywords: Efficient fine-tuning, Long context, Large language model","The authors only evaluate perplexity and retrieval setting","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models","Keywords: Efficient fine-tuning, Long context, Large language model","The efficiency aspect of the could could be more prominently discussed in the main body of the paper
The presentation of the work could be improved. See below for suggestions","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models","Keywords: Efficient fine-tuning, Long context, Large language model","No major weaknesses.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models","Keywords: Efficient fine-tuning, Long context, Large language model","the paper only evaluated on retrieval and perplexity. It would be good to evaluate on other generative tasks that require longer context.
the improvement on perplexity doesn't seem super consistent in Table. 4","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Amortizing intractable inference in large language models","Keywords: large language models, LLMs, Bayesian inference, chain-of-thought reasoning, latent variable models, generative flow networks, GFlowNets","Overall the paper is hard to follow: the authors provide little background on reinforcement learning and GFlowNet training. In particular, the authors use many terminologies without/before defining them clearly, examples include “policy”, “reward”, “matching” a target distribution, “rewarding all valid integers equally leads to an expected gradient of zero for policy gradient methods.”
In section 2, by looking at the problem of using LLMs to generate random numbers between 0 - 100, the authors try to motivate the use of GFlowNet instead of PPO training. PPO training does not resolve the distribution skew because the reward function only considers whether the number lies between 0 - 100. One correct way to do it could be asking the LLM to generate a sequence of numbers sampled from 0 - 100 uniformly and assign a positive reward only if the frequency of the numbers are close to uniform. A major part of the introduction focuses on intractable posterior inference/conditional probabilities and the fact that Section 2 mentions nothing about them makes it hard to follow.
In section 3 the authors introduced some related problems in NLP that could potentially be solved by GFlowNet and in section 3.3 on page 5 that the authors finally describes GFlowNet and their training objective. What is the original subtrajectory balance objective? How do you modify it? What is the semantics of your objective function? Answer to these questions can help distinguish GFlowNet from other approaches from the methodology perspective.
Besides, some important related works of the field are missing from Section 3: -for temperature scaling: [1] leverages importance sampling to fine-tune LM p(x) such that it approximates the desired distribution p(x)^{1/T}. Their approach suffer from various problems such that the variance of loss is high due to the exponent 1/T. Given that the authors study this empirically, does the GFlowNet objective also suffer from this issue? If so, how is it resolved?
-for text infilling: [2] and [3] both studies the problem of text infilling where [2] adopted a fine-tuning based approach. [6] and [7] tackles this problem by training insertion-based language models.
-for constrained generation:
Current approaches to the problem use tokenwise approximations (Liu et al., 2021) or various problem-specific beam search and local search techniques
Other than search-based approaches, frameworks like FUDGE [4] and NADO [5] trains auxiliary models (classifiers) and combine it with LMs to approximate the desired conditional distribution.
To summarize, GFlowNet seems to be a very very general framework that allows you to fine-tune an LM to approximate any distribution that is proportional to an arbitrary reward function r(x). Despite the experiment results showing advantages against vanilla baselines, the authors did not make a strong argument showing why GFlowNet would work better on these downstream tasks against existing approaches, including the ones mentioned above.
The main argument may be stronger/clearer if the authors focus more on the chain-of-thought reasoning part other than trying to provide a generic solution to all intractable inference for LMs.
[1] Shih, Andy, Dorsa Sadigh, and Stefano Ermon. ""Long Horizon Temperature Scaling."" arXiv preprint arXiv:2302.03686 (2023).
[2] Donahue, Chris, Mina Lee, and Percy Liang. ""Enabling Language Models to Fill in the Blanks."" Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 2020.
[3] Zhu, Wanrong, Zhiting Hu, and Eric Xing. ""Text infilling."" arXiv preprint arXiv:1901.00158 (2019).
[4] Yang, Kevin, and Dan Klein. ""FUDGE: Controlled Text Generation With Future Discriminators."" Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021.
[5] Meng, Tao, et al. ""Controllable text generation with neurally-decomposed oracle."" Advances in Neural Information Processing Systems 35 (2022): 28125-28139.
[6] Lu, Sidi, Tao Meng, and Nanyun Peng. ""Insnet: An efficient, flexible, and performant insertion-based text generation model."" Advances in Neural Information Processing Systems 35 (2022): 7011-7023.
[7] Susanto, R. H., Chollampatt, S., and Tan, L. Lexically constrained neural machine translation with levenshtein transformer. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics (ACL), 2020.","5: marginally below the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Amortizing intractable inference in large language models","Keywords: large language models, LLMs, Bayesian inference, chain-of-thought reasoning, latent variable models, generative flow networks, GFlowNets","Overall, I really like the paper, but I do think there are a few places it could be improved:
Limited discussion of the training objective and its relationship to possible alternatives. The training objective is introduced very briefly and without much intuition. I realize that there is an extensive literature on training GFlowNets and there is not space to go into full detail here. But are there reasons that this objective (among many other GFlowNet objectives) was particularly well-suited to the language modeling case? Why GFlowNets at all instead of e.g. reweighted wake sleep (a common method for amortizing intractable posterior inference)? How sensitive is performance to the distribution you use to generate training trajectories? How important is the replay buffer, and how is it populated? In fairness, I am not sure how many of these questions need to be addressed in a short conference paper.
Limited discussion of the limitations of the proposed technique. Ultimately, the training method given here is a mostly-on-policy reinforcement learning method. A key challenge for such methods is exploration -- finding high-reward samples to reinforce. I would have appreciated more discussion of the sorts of posterior inference tasks that are and aren't likely solvable with the proposed techniques (at least without further innovations), possibly along with potential mitigations for these weaknesses.
Metrics for infilling. I had reservations about some of the metrics used to evaluate the proposed approach, in particular for the story infilling task. It is unclear that measuring similarity to a single reference sentence is very meaningful--especially since a purported strength of the method is sampling the full posterior. It would be nice if (randomly selected) qualitative examples were presented for all baselines. It may also be worth considering an automated evaluation of the coherence of the resulting story (e.g., by asking GPT-4 to rate coherence). Despite the many (valid) critiques of such LLM-powered evaluations, I do think they are at least a better fit for creative coherent generation tasks like this one than metrics like BLEU.","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Amortizing intractable inference in large language models","Keywords: large language models, LLMs, Bayesian inference, chain-of-thought reasoning, latent variable models, generative flow networks, GFlowNets","Please see the following questions.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Amortizing intractable inference in large language models","Keywords: large language models, LLMs, Bayesian inference, chain-of-thought reasoning, latent variable models, generative flow networks, GFlowNets","The datasets are small, and the inference only involved fine-tuning vs. training from scratch, which may unlock entirely different and interesting new global solutions. This is an understandable limitation, but a more full exploration (which can be tackled as future work) might extend the power and reach of their method.
One of the central pieces, the learning objective, has already been derived in a different soft-RL Q learning context, as pointed out by the authors. There doesn’t appear to have been further explorations of downstream applications as performed in the current work however.
Their method requires fine-tuning for different queries/inference problems. It would be interesting to see if instead it would be possible to have a single network (as they suggest in future work) that can answer many different types of queries.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models","Keywords: carbon footprint modeling, large lanaguage models","the procedure of how LLMCarborn figures out the optimal parallelism is not quite clear.
It is not clear how to use LLMCarborn to guide the design of future generations of LLM architectures and figure AI accelerators.
The relationships and connections between the proposed hardware efficiency and metrics like arithmetic intensity and MFU are not clear.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models","Keywords: carbon footprint modeling, large lanaguage models","Some parameter is crucial to the final predicted results, the process of setting parameters should be clarified. For example, in equation 3, \alpha, \beta are the fitting parameters. However, the fitting dataset and fitting method are missing.
Apart form the parameters discussed in the paper, more factors also affect the footprint. e.g., the paramter precision (fp16, int8, int4) and the implementation of kernel operation.
There are not any text description about figure 3 and figure 4.
The proposed llmcarbon is somewhat like a system design with many prior experience from sota, the algorithm contribution are not notable.","5: marginally below the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models","Keywords: carbon footprint modeling, large lanaguage models","It is not clear how the ""ground truth"" carbon footprint numbers were established by prior works. Did they perform actual measurements? This is a concern because if the numbers are estimated, and there is an overlap in estimation methods, then it's not surprising that the error rate is low.
It is difficult to separate the contributions of the paper from the prior works. Much of the equations and parameters of the equations are based on prior work. Is the contribution of the paper to sum up carbon numbers from prior work equations?
There is no measure of utility of an LLM. For example, one can reduce the emissions by increasing test loss, but a high test loss can lead to poor performance which cannot be used in the real-world. It'll be interesting to measure the utility across classical ML models such as those used for classification, regression, translation, etc.
It would be good to discuss the utility of the measurement tool. Is the expectation that model designers pick an appropriate data center, architecture, or training dataset to use based on carbon footprint? Much of the time such decisions are constrained by other requirements. For example, model designers have little control over the embodied footprint of the ML model.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models","Keywords: carbon footprint modeling, large lanaguage models","Not clear whether the authors' definition of embodied carbon is accurate. Not clear where the carbon coefficient factors in in the model formulation.","5: marginally below the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models","Keywords: carbon footprint modeling, large lanaguage models","the mixture of expert models seems to use regular scaling laws equations for performance prediction. More appropriate would be to use the equations from the routed scaling laws paper.
some factors are not very well discussed. For example, experimentation can have a large variance of CO2eq used. For deployment, more experimentation is usually undertaken to improve model efficiency through speculative decoding and distillation. A short discussion on the most CO2eq intensive factors and how they might differ between companies/institutions would be appropriate (no need to model this)","10: strong accept, should be highlighted at the conference","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis","Keywords: Web Navigation, Web Automation, Large Language Models, Language Model Agents, Tool Use, Program Synthesis","Especially for this kind of work, the broader impacts section should be in the main text and should be fully fleshed out. This is a significant weakness in this work.
It would be good to have a baseline comparison comparing what performance looks like with model scale. Flan-U-PaLM is a 540B parameter model which puts it at a scale inaccessible to many researchers.. it would be good to benchmark how this approach scales from small accessible open source models, to the large ones used in this work.","This work builds automated bots to interact on the web. This is important work but it should have a fully fleshed out broader impacts section.
Update: Authors have updated the document to include an Impact assesment.","8: accept, good paper"
"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis","Keywords: Web Navigation, Web Automation, Large Language Models, Language Model Agents, Tool Use, Program Synthesis","Because the model relies on Flan-U-PaLM with 540B parameters, it's difficult to judge how reliant the method is on the ability of this particular model to generate executable code.
The organization of the paper could be improved, including more details about how feedback was acquired and finetuning was done to enable planning and summarization (i.e. Fig 6 in appendix)","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis","Keywords: Web Navigation, Web Automation, Large Language Models, Language Model Agents, Tool Use, Program Synthesis","Overall, this is a strong paper, however, one weakness of this work is the lack of baselines to compare results against in real-world tasks. Table 1 provides good ablation study insights into the proposed WebAgent but there are no other Agents to compare to. Similarly in Table 3, HTML-T5 is only compared against MindAct on Mind2Web. Are there any other agents that could be used on this benchmark?
Another weakness of this work is its clarity and ease of comprehension. Some aspects of the paper were not entirely clear, in particular how was HTML-T5 trained to predict sub-instruction plans and HTML summaries? What data supervision was used for that?
Similarly, it is not entirely clear what HTML-T5 produces: Figure-3 indicates ""HTML-snippets"", but the paper mentions multiple times that it ""summarizes"" HTML pages (so it should produce a summary?), and in Section 3.2 the paper states that it predicts ``the corresponding data-ref attributes''. If the model outputs only data reference IDs (like suggested also with Figure 6) then this is not summarization but more like information retrieval and the paper should reflect this. In addition, if object references are what is really being predicted, then it is not clear how Flan-U-PaLM make use of that information without having access to the raw HTML containing these objects.
Another confusion is the window size of HTML-T5: in Section 3.1 it is mentioned that the input sequence length of HTML-T5 is 4096, but in section 4.2 it uses 16k tokens for the context window. Which one is it? 16k tokens seems more likely overall since the model is supposed to take as input instruction, previous sub-instructions, and raw HTML. Just the raw HTML would overflow the 4096 context size as mentioned in the paper and illustrated by Figure 2. After reading 4096 in Sections 3.1, it was hard to understand how all inputs of HTML-T5 would fit in such a small window (especially after seeing Figure 2).
Eventually, one important thing that the paper should discuss is the difference between train and test settings. It seems like WebAgent was trained on all domains individually. What precautions were made to ensure that the testing tasks do not overlap with the ones used during training?
Minor: some syntactic mistakes make the paper hard to read sometimes.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis","Keywords: Web Navigation, Web Automation, Large Language Models, Language Model Agents, Tool Use, Program Synthesis","The presentation can be improved. Please consider revise the writing to avoid the questions below.","5: marginally below the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Lipschitz Singularities in Diffusion Models","Keywords: Image Generation, Generative models, Diffusion models","One minor suggestion is to avoid saying
t
being small (rather, it is about
σt
being small). Since
t
is in fact
0,1,2,3,..100.
May add more discussions to the alternative approaches (see Questions below).
It may be worth showing that directly learning
∇log⁡qx(t)
with the least square is prohibitve.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Lipschitz Singularities in Diffusion Models","Keywords: Image Generation, Generative models, Diffusion models","This paper as it is impeccable in terms of presentation and contribution, both theoretically and practically. The only drawback is that no open-source code is available to experiment with their approach.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Lipschitz Singularities in Diffusion Models","Keywords: Image Generation, Generative models, Diffusion models","The only weakness I would like to highlight is the discussion of the alternative methods presented.
I believe 1 of the methods from the appendix is not mentioned in the main text - namely the Remp method (D.3.3).
It would be nice to see an expanded discussion of these with some small experiment to show the quantitative difference between the proposed method and these other methods. I appreciate the space limitation, but I think this is really an interesting point.","None","8: accept, good paper"
"Lipschitz Singularities in Diffusion Models","Keywords: Image Generation, Generative models, Diffusion models","The observation concerning the presence of infinite-Lipschitz constants in the diffusion process is not original (Song et al., 2021a; Vahdat et al., 2021). Concerning it has been observed before, the authors should like to tone down their claims of having observed it first.
Some of the English is stilted (""vexing propensity of diffusion models"" in the abstract, ""Recently, there have been massive variants that significantly promote the development of diffusion models"" on page 3).","None.","6: marginally above the acceptance threshold"
"Interpreting CLIP's Image Representation via Text-Based Decomposition","Keywords: CLIP, interpretability, explainability","I could not think much about any significant weaknesses in this work. I have some questions as follows:
How the zero-shot results compare against from methods like MaskCLIP [1]?
It has been shown that the zero-shot accuracy of the embeddings from only late attention layers is very competitive to the original performance. Will this also hold true where the representations are used for downstream tasks which require adaption? For example, it will be good to see the linear probe performance of the filtered embeddings on imagenet or other datasets like CIFAR100, Caltech101.
[1] Extract Free Dense Labels from CLIP, ECCV 2022, Oral","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Interpreting CLIP's Image Representation via Text-Based Decomposition","Keywords: CLIP, interpretability, explainability","Weakness: No ablation studies on the impact of the pool size (M) and the basis size (m) on the performance of the decomposition.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Interpreting CLIP's Image Representation via Text-Based Decomposition","Keywords: CLIP, interpretability, explainability","Cons / Questions:
While the authors perform the direct effect in the paper, can the authors comment on how indirect effects can be leveraged to understand the internal representations? I think this is an important distinction to understand if understanding the internal representations in more detail can unlock further downstream capabilities. If affirmative, what downstream capabilities will be feasible?
I am not sure if the current way to create the initial set of descriptions is diverse enough to capture “general” image properties or attributes. I believe the corpus of 3.4k sentences is too small for this analysis. While this set is a good starting point, can the authors comment on how this set can be extended to make it more diverse?
Did the authors analyse the OpenAI CLIP variants using this framework? The OpenCLIP and OpenAI variants are trained on different pre-training corpus, so a good ablation is to understand if these properties are somehow dependent on the pre-training data distribution.
Can the authors comment on how the images set in Sec. 4.1 is chosen? This is not very clear from the text. Is this set a generic image set that you use to obtain m text-descriptions per head from a bigger set of text-descriptions?","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Interpreting CLIP's Image Representation via Text-Based Decomposition","Keywords: CLIP, interpretability, explainability","Seems like human users are still required to provide some sort of heuristic to decide the role of a head. I would like to know how hard it is from the user point of view.
Seems like most of the experiments have been done on general image datasets. I am curious about the results on some fine grained tasks or datasets for example human face recognition.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Multisize Dataset Condensation","Keywords: Dataset Condensation, Dataset Distillation, Image Classification","The synthetic samples within the subset seem to be fixed, which may not reflect “Multisize Dataset Condensation” correctly.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Multisize Dataset Condensation","Keywords: Dataset Condensation, Dataset Distillation, Image Classification","When the IPC (Inter-Process Communication) is small, there still exists a large accuracy gap between the proposed model and Baseline-A as shown in Figure 2 and Table 1.
The impact of the calculation interval (∆t) on the performance of the MDC method needs to be further analyzed to determine the optimal interval size.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Multisize Dataset Condensation","Keywords: Dataset Condensation, Dataset Distillation, Image Classification","The paper explains three baselines for comparison. Compared to baseline A, the accuracy is not higher. Please explain the reason. Is it possible to reach Baseline A's accuracies? Equation 7 is not that clear. How to calculate the distance between the full dataset and subset?","NA","8: accept, good paper"
"Multisize Dataset Condensation","Keywords: Dataset Condensation, Dataset Distillation, Image Classification","It's not clear what's the purpose of baseline B. It looks like the results are only compared to baseline A and C.
It's not clear why the freezing is used in MLS selection. If adaptive is good, why not just use adaptive method to choose the subset?
Will the additional loss bring extra computational cost?","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation","Keywords: Text-to-3D, Image-to-3D, 3D Generation, Efficiency","While the work has overall a good contribution, one of my main concern is its writing. First, there are numerous minor language issues such as grammar mistakes and sometimes unnecessarily complicated sentence structure. This can easily be solved by a few rounds of careful proofreading. Second, the work reads more like a paper written for a computer vision conference without providing sufficient background to a broader audience at the ICLR community. While this style is not unprecedented in ML, it makes this work much harder accessible and misses an opportunity. Moreover, for people outside the specific subarea of 3d content creation some of the important implementation details may be missing.
These concerns range from minor points such as assuming the reader to be familiar with all mentioned vision / graphics concepts such as UV space etc without providing a proper background section. It also involves more complicated points such as the decision to provide some background (e.g. on SDS loss) but only to an extent that is only meaningful for people already familiar with dreamfusion. While in vision, many of these things can be assumed known, it would be useful to the learning community to provide some information here.
Also, I would rephrase the contribution bullet points to focus stronger on the technical aspects rather than first mentioning the overall framework, then dedicating one point to the actual technical meat and then talking about experimental evaluation.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation","Keywords: Text-to-3D, Image-to-3D, 3D Generation, Efficiency","1. Missing bits of context information - How much does it cost?
While indicative timings and implementation details (covering experimental setup, are provided, information regarding the resource usage, model size and complexity are currently underdescribed.
A comparative disclosure of such information covering the main experimental baselines that are considered would help the reader better assess its relative positioning throughout the typical criteria.
Mentioning where the computation bottlenecks lie in terms of pipeline components would also be valuable in order to fully assess the practical usefullness of the proposed sequential pipeline, beyond rough timings.
2. Challenging the ad hoc meshing post processing.
As it currently stands, the mesh extraction technique relies on many subsequent post-processing steps, including mesh decimation and remeshing (end of page 5 in the main paper). I believe the explainations around eq. (4) (before and after) could be further improved and detailed. My current intuition is that the mesh complexity at least could be controled jointly during the density query step. Also, given the lack of statistics given regarding each step (Weakness 1 above), the relative need and ROI to fuse these steps is also hard to assess.
The current procedure also produces non-manifold and non-watertight meshes with arbitrary complexity.
3. Evaluation.
The user study (ie, subjective quality analysis) that is presented in the main paper and further detailed in the appendix is a good idea and often overlooked in the field.
Nevertheless, its size and statistical informative validity are rather limited as they are based on a ""cohort"" of 40 users and 15 input samples to assess from.","10: strong accept, should be highlighted at the conference","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation","Keywords: Text-to-3D, Image-to-3D, 3D Generation, Efficiency","It seems the focus of the paper is image-conditioned generation. The results of text-to-3d are very limited and the comparison is weak.
I am curious about the setup of the stage 3. If we already have a mesh with coarse texture, we can optimize it with differentiable mesh rendering and SDS loss, as Fantasia3d did in the appearance modeling stage. What is the advantage of the proposed refinement compared to this?
Another concurrent ICLR submission ( https://openreview.net/forum?id=pnwh3JspxT ) optimizes SDS much longer (1 hour and 40 minutes) than this paper. However, this paper claims that longer training does not give better results. Can the authors clarify the differences?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation","Keywords: Text-to-3D, Image-to-3D, 3D Generation, Efficiency","Regarding the note “Similar to Dreamtime (Huang et al., 2023), we decrease the timestep t linearly”: Did the decrease of t help with the training time as well? Did it bring instability in training to the model? My previous exploration in this direction (for text to 3D in NeRF) showed improvement in the speed of generation for some objects but brought instability in the training. Since some objects needed more training steps than others, having a fixed annealing strategy damaged the performance, specifically for objects (e.g., motorcycles or dogs). It would be great if the authors could explore, in text to 3D, what the effect of the speed of annealing would be for different sets of prompts, (e.g., a corgi vs. a tree). Does the speed of annealing need to be tuned for each prompt?
The authors provided the experiment for time annealing in Fig 7 for image to 3D, but the paper is missing the same figure for text to 3D. Also, the effect of the speed of annealing needs to be explored.
Regarding the loss function, eq. 6, for UV-Space texture refinement: what happens if the object boundary in the Img2Img stage changes? How do the authors prevent the color of the background from leaking into the mesh color?
It would be great if the authors could compare the proposed texture refinement to other SOTA methods like TexFusion [1] or Text2Tex [2] or any other method of their choice. The reason for this ask is because texture refinement has been applied on top of the mesh. So, if the authors want to consider texture refinement as one of their contributions, they should either compare it with other baselines or reframe the paper and consider this as a side contribution.
I also tried experimenting with the code (great codebase!) and observed that, for text to 3D, the texture in most cases was very saturated. It would be great if the authors could comment on this phenomenon in the paper as a shortcoming and provide some insight into which parameter tuning might help.
Regarding the Janus problem, the authors provided a list of papers that address the Janus problem mostly using 3D data. However, it would be great if the authors could also reference methods like Perp-Neg [3] or Prompt-Debiasing [4] that address the Janus problem without the need for 3D assets. This has significant importance because they don't introduce bias from 3D data into the pipeline. For instance, they allow for the generation of a dog without the strict square position for standing that comes from the 3D asset. It would be great if the authors could also comment on the guidance of the SDS loss and the effect of increasing those values.
There are many typos in the paper, and it would be great if the authors could fix them. Examples are: on page 2, ""Gaussian splitting"" appears to be a typo; it should likely be ""Gaussian splatting"". “severl methods” on page 3 and “Dissusion” on page 5 is it supposed to be discussion?
It would also be great if the authors could comment on how to get the model to consider both the input image and the text prompt simultaneously in both the initial stage and the later mesh/texture optimization stage. At the moment, it seems to ignore the optional text prompt. Was this intentional?
The paper contrary to DreamFusion does not learn an MLP for the background, it would be great if authors could comment on why they made that choice and what are their findings.
[1] https://openaccess.thecvf.com//content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf
[2]https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Text2Tex_Text-driven_Texture_Synthesis_via_Diffusion_Models_ICCV_2023_paper.pdf
[3] https://arxiv.org/abs/2304.04968
[4] https://arxiv.org/abs/2303.15413","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LRM: Large Reconstruction Model for Single Image to 3D","Keywords: 3D Reconstruction, Large-Scale Training, Transformers","The method requires significant computational resources.
A minor issue, but the paper shows no quantitative comparison with any prior work.
Since the method is discriminative, it is not able to sample different realizations of an input. Additionally, the averaging of modes, even though has been weakened a lot compared with prior works such as PixelNeRF, still exists as the author mentioned.
The task of novel view synthesis is inherently probabilistic, as the author mentioned. Even though the method shows amazing scaling-up ability, it is questionable whether solving a generative task in a discriminative way is reasonable.
The contribution of this paper comes mainly from its presentation of the ability of large transformers and large-scale 3D data on novel view synthesis. Technically, the efforts mainly come from the engineering efforts combining different techniques and processing with the data.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"LRM: Large Reconstruction Model for Single Image to 3D","Keywords: 3D Reconstruction, Large-Scale Training, Transformers","Although the results look promising, the paper has two main weaknesses:
Insufficient quantitative comparisons: the paper does not conduct any quantitative evaluation against other methods. I believe the novel view synthesis and 3D reconstruction can be evaluated on the held-out sets for those 3D object datasets, and user study should also be possible. Even if the quantitative results may not reflect the generation quality entirely, the paper should include discussions on why these scores are not reliable/not feasible.
The quality on the occluded side is still limited. For objects that have overall smooth/uniform textures, LRM seems to do a good job filling in the occluded side information. But for more complex, asymmetric patterns (e.g., Figure 2. Giraffe, supp. website shoe example), LRM struggles to synthesize plausible appearances.
In summary, the absence of quantitative comparisons raises significant concerns.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"LRM: Large Reconstruction Model for Single Image to 3D","Keywords: 3D Reconstruction, Large-Scale Training, Transformers","I don't think there exists any apparent weakness in the paper. Please refer to the following questions part for my other questions regarding the details of paper.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"LRM: Large Reconstruction Model for Single Image to 3D","Keywords: 3D Reconstruction, Large-Scale Training, Transformers","As mentioned in the limitation, the back side of the model (e.g., figure 3 penguin) is blurry and besides that, the color tone/ saturation seems a bit inconsistent with the frontal view.
The model relies on the correct camera parameters and normalization of camera, which still based on the fact that the objects in the training dataset (objectaverse?) have a certain distribution of orientation. The more general way to formulate the scene is to assume the world coordinate is the camera coordinate (extrinsic = np.eye(4)), which make the object always face forward to the camera. Although, from the geometric learning works in shapenet, this approach is more challenging than appropriating the object orientation.
The approach relies on multiview data which limits the model incorporating more diversity in data source of single view images.","10: strong accept, should be highlighted at the conference","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?","Keywords: Transfer Learning, Medical Image Analysis, Organ Segmentation","I do not remark any major issue as the drawback of this paper.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?","Keywords: Transfer Learning, Medical Image Analysis, Organ Segmentation","The title may be a little misleading. If I understood it correctly, the word ""transfer"" in the title is not referring to transfer learning in this case, but simply asking whether supervision is also good for 3D data as it has been for 2D data. When first reading the title, I thought you were exploring transferring 2D supervised models to 3D tasks. Others may also make that incorrect assumption.
The use of the word ""ImageNet"" in the dataset name may want to be reconsidered. Besides being a large dataset with a variety of anatomy, the link to ImageNet is a bit weak and may also suggest properties that the dataset does not have (e.g., per-image classification labels).
CTs are very specific types of 3D data -- it's difficult to make a claim for all 3D data from these experiments alone. I think the paper could be improved by focusing the message more narrowly, perhaps on medical imaging segmentation.
To me, the results are not surprising -- if you have a such a large dataset with rich segmentation labels, then it should do better than self-supervision. This is in contrast to classification, where this may not be true. I think the main point of the paper should be that this is a new dataset that will be valuable to the community, not that rich supervision is useful in segmentation.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?","Keywords: Transfer Learning, Medical Image Analysis, Organ Segmentation","The paper explores the transferability of supervised learning by combining multiple 3D CT segmentation datasets. Similar work has been done in various fields, such as training various tasks and data in computer vision, which has shown improved results across tasks. This paper incorporates 3D CT data and tasks, with the only difference being the collection of more publicly available and private data, without bringing new insights or technological innovations to the community.
The conclusion that supervised pre-training has an advantage over other pre-training methods in 3D medical imaging is generalized to general 3D vision tasks in an inconsistent manner. The introduction discusses pre-training strategies for 3D vision tasks, but the experiments are all conducted on medical images. It is well known that there are significant differences between medical images and natural images, and whether the experimental conclusions on 3D CT data can be extended to other 3D vision tasks is not explored in the paper.
The fused dataset of over 9000 CT cases collected by the authors includes segmentation of 32 organs and tumors, but the evaluation in the experimental section focuses more on organs, lacking an evaluation of tumor segmentation performance. Comparatively, organ segmentation is less challenging in terms of generalization, while tumor segmentation is more complex. In the external dataset, more focus should be given to tumor segmentation, as it is more susceptible to a series of generalization issues caused by differences in populations, devices, and diseases in practical application scenarios.
Unfair comparison in the experimental section is a fatal flaw. Although the authors claim that collecting 9000 data is their contribution, the same 9000 data were not used for pre-training when comparing with other self-supervised/supervised pre-training methods. Therefore, it is not rigorous to conclude that SPT is superior to other supervised/self-supervised methods.
The results of fine-tuning SPT on 63 novel classes are not impressive. Although there is no comparison with totalsegmentator, the performance of totalsegmentator trained on 1000 data seems to surpass what is reported in Table 4. For example, totalsegmentator can achieve over 95% Dice on iliopsoas, while it is less than 90% in the paper.","This paper uses internal medical data for training, so it may need ethical approval for use.","6: marginally above the acceptance threshold"
"How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?","Keywords: Transfer Learning, Medical Image Analysis, Organ Segmentation","UniverSeg [1] is another paper that trains networks on a very large dataset, 22K scans, which is even larger than this paper. Although Arxiv version of UniverSeg is available since April 2023, I see this work and UniverSeg as concurrent works since UniverSeg is recently presented in ICCV. However, I still think that mentioning UniverSeg and discussing the similarities/differences in the final version would be useful.
[1] https://universeg.csail.mit.edu/
How do the models trained on the collected large CT dataset generalize to novel modalities such as MRI?","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?","Keywords: Transfer Learning, Medical Image Analysis, Organ Segmentation","The weakness could relate to the details of the pretraining strategy. Typically, image-wise [1, 2] or pixel-wise [3] pre-training relies on the InfoNCE loss for clustering embedding samples in the latent space, rather than directly applying penalties based on labels via cross-entropy loss. It would be more interesting to observe results achieved through category-guided InfoNCE loss [4, 5] pre-training using this dataset.
Additionally, there exist many promising domain transfer methods, yet the paper appears to lack exploration in this area. The current approach appears to be straightforward fine-tuning on other datasets, such as TotalSegmentator and JHH.
[1] Self-training with Noisy Student improves ImageNet classification
[2] Unsupervised Learning of Visual Features by Contrasting Cluster Assignments
[3] Dense Contrastive Learning for Self-Supervised Visual Pre-Training
[4] Supervised Contrastive Learning
[5] Exploring Cross-Image Pixel Contrast for Semantic Segmentation","I missed the data privacy of the patients throughout the processes of data collection, storage, and sharing in the paper. I have observed a 'pending' status in Table 5 of your Appendix A and I believe it is essential for the authors to address this issue appropriately.","6: marginally above the acceptance threshold"
"Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View","Keywords: Gene regulatory network, Single-cell RNA-sequencing, Dropout, Zero-inflated data, Causal model, Causal discovery, Nonparametric","For network inference, they can use some evaluation metrics such as ROC curve or PR curve to assess how well their predicted network recovers the true network. They should conduct more experiments to show the performance gained by using their causal dropout model. Several gene network inference methods have been designed to handle missing values in scRNA-seq data. Therefore, as a practical analytical framework, the authors should prioritize the comparison of their model with the most advanced existing network inference methods.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View","Keywords: Gene regulatory network, Single-cell RNA-sequencing, Dropout, Zero-inflated data, Causal model, Causal discovery, Nonparametric","I do not have major comments on possible weaknesses.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View","Keywords: Gene regulatory network, Single-cell RNA-sequencing, Dropout, Zero-inflated data, Causal model, Causal discovery, Nonparametric","My only (minor) gripes are that most of the theoretical analysis is deferred to the appendix, which can sometimes lead to questions due to insufficient detail (see below), and that the references are a bit sloppy.
Miscellaneous comments:
page 4, Example 4: I think the Bernoulli distributions should be reversed, since there should be a minus sign in the denominator exponential when computing the logistic function.
page 10, reference typo: * after ""Tabula Sapiens Consortium""
page 11, formatting error: ""ALBERTS"" should not be capitalized
page 11, there seems to be no reference to Gao et al. (2022) in the paper.
page 12, duplicate author: ""Paul R. Rosenbaum""","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Statistically Optimal
K
-means Clustering via Nonnegative Low-rank Semidefinite Programming","Keywords: clustering, Burer-Monteiro, semidefinite programming","Weaknesses
The time complexity of solving the primal-dual algorithm is
O(K6nr)
and this becomes prohibitively large when
K
is large. The experiments show small
K
values(eg:
4
). Even for
K=10
, the time for convergence can grow very quickly. In some applications such as document deduplication, and entity resolution, the value of
K
can be significantly larger than what is used in the experiments.
Typos
On page 3, in the paragraph after equation
2
, ""one-shot encoding""
→
""one-hot encoding"".","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Statistically Optimal
K
-means Clustering via Nonnegative Low-rank Semidefinite Programming","Keywords: clustering, Burer-Monteiro, semidefinite programming","Insufficient discussion of practical limitations
: The paper might not thoroughly address the practical limitations or challenges that users might face when applying the proposed algorithm in real-world scenarios. Understanding the algorithm's limitations in terms of computational resources, scalability, or specific data types is crucial for potential users and researchers.
Initialization condition
: The authors base their proof of Theorem 1 on the assumption that the initialization meets a specific condition. While this assumption is discussed in the paper, it would significantly enhance the rigor and credibility of their work if the authors were to provide a rigorous proof for this initialization criterion.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Statistically Optimal
K
-means Clustering via Nonnegative Low-rank Semidefinite Programming","Keywords: clustering, Burer-Monteiro, semidefinite programming","It is unclear how Theorem 1 allows to verify the claims about computational and statistical superiority of Algorithm 1 compared to existing clustering methods. In particular, how does Theorem 1 and the numerical experiments imply the claims ""..simple and scalable as state-of-the- art NMF algorithms, while also enjoying the same strong statistical optimality.."" in the abstract?
there should be more discussion or comparison of computational complexity and clustering error incurred by Algorithm 1 compared to existing clustering methods for the Gaussian mixture model Eq. (14).
the connection between theoretical analysis in Section 4 and the num. exp. in Section 5 could be made more explicit. For example, there are not many references to the theoretical results in the current Section 5. How do the numerical results confirm Theorem 1? How did the theoretical analysis guide the design choices (datasets, hyperparams of Algorithm 1) of the numerical experiments.
the use of Algorithm 1 needs more discussion: How to choose beta, alpha and r in practice? How does Algorithm 1 deliver a cluster assignment that approximately solves k-means?
use of language can be improved, e.g., -- ""..is the sharp threshold defined.."" what is a ""sharp"" threshold ?; -- ""..can be converted to the an equality-constrained.."" -- what is a ""manifold-like"" subset ? -- what is a ""is a nonconvex approach"" ? -- ""...by simultaneously leverage the implicit psd structure"" -- "".. that achieves the statistical optimality "" -- ""..which reparameterizes the assignment matrix .. as the psd membership matrix.."" -- what is a "".. one-shot encoding ""?","3: reject, not good enough","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Statistically Optimal
K
-means Clustering via Nonnegative Low-rank Semidefinite Programming","Keywords: clustering, Burer-Monteiro, semidefinite programming","No evident weakness except the separation assumption, but I acknowledge that overcoming this assumption is difficult mathematically, and even with this assumption the derivations and ideas are not trivial.","8: accept, good paper","2: You are willing to defend your assessment, but it is quite likely that you did not understand the central parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Unprocessing Seven Years of Algorithmic Fairness","Keywords: fairness, algorithmic fairness, social computing, tabular data, meta study","The weakness of the paper comes from the lack of a certain level of theoretical derivation to justify the empirical findings. The proposed term ""unprocessing"", as noted by authors, ""roughly corresponds to the inverse of postprocessing"", is more of less confusing (for reasons detailed in Section Questions). While one can observe from extensive empirical evaluations that Pareto-optimal tradeoffs can be achieved (setting aside numerical indeterminacy), there is a worry that the results can only provide limited insight regarding the not-clearly-motivated unprocessing procedure.","6: marginally above the acceptance threshold","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Unprocessing Seven Years of Algorithmic Fairness","Keywords: fairness, algorithmic fairness, social computing, tabular data, meta study","None","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Unprocessing Seven Years of Algorithmic Fairness","Keywords: fairness, algorithmic fairness, social computing, tabular data, meta study","I would like to see a comparison between the real unconstrained model and the unprocessed version of the constrained model. This comparison is necessary and could enhance the claim that unprocessing can be applied to find the optimal unconstrained model.
Section 4 is just a standard LP problem in solving Equal Odds with post-processing. It is not novel and there is no need to write down it in the main paper.
The author has admitted that their evaluation is only applied to tabular data, with a focus on 5 different partitions of the FolkTables dataset. It would be interesting to see how the conclusions can still be generalized to tasks with rich representations.","6: marginally above the acceptance threshold","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Unprocessing Seven Years of Algorithmic Fairness","Keywords: fairness, algorithmic fairness, social computing, tabular data, meta study","I found the technical description of how to achieve relaxed parity jarring from the rest of the paper. I would have liked this section to be longer and for more explanations there. I did find the figures quite helpful in understanding it.
A big selling point of the paper is the extent of their experiments. I think the reason they were able to do this is because they had access to a ton of compute. All the data sets and models (I believe) are easily accessible. If this is the case, I'm not sure that ""having lots of compute"" is really something we should reward as a contribution.
I found their approach intuitively obvious: Of course given a classifier, you can vary how much it violates a reward constraint in an optimal way. So I think the contribution here would be because (it seems like) no one has done this before rather than because it is so interesting.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning","Keywords: Dynamic Data Pruning; Training acceleration","The paper conducts a complete study on dynamic data pruning, and the following weakness is relatively minor.
Missing recent works: 1) static data pruning [a,b,c], 2) dynamic data pruning [d]
[a] Active learning is a strong baseline for data subset selection. NeurIPS workshop, 2022
[b] Moderate: Moderate coreset: A universal method of data selection for real-world data-efficient deep learning. ICLR, 2023
[c] CCS: Coverage-centric Coreset Selection for High Pruning Rates. ICLR, 2023
[d] Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt. ICML, 2022","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning","Keywords: Dynamic Data Pruning; Training acceleration","InfoBatch improves over UCB via throwing away the dataset sorting operation. However, in Table 2, the practical overhead cost saving seems negligible compared to the wall clock time and the total node hour. Also, how was the overall saved cost calculated in Tables 6 and 7?
To my understanding, annealing utilizes the whole dataset without pruning for the last 0.125% of total training epochs. This raises several concerns: (i) As the wall clock time of UCB and InfoBatch in Table 2 are both 10.5h, is this value taking the annealing process into account? (ii) Regarding Table 1, all the baselines and InfoBatch are compared under the same dataset pruning ratio. I wonder whether this is a fair comparison when annealing is involved in InfoBatch. (iii) Why did the authors utilize annealing only as a means of stabilizing the optimization, rather than leveraging the full dataset at the very beginning of optimization when we know that the early epochs of training can heavily influence the convergence of the loss landscape [1]?
The authors may need to provide further clarification regarding how annealing contributes to the stabilization of the rescaling process, especially if it does not seem to significantly impact the variance of the results in Table 4.
The authors claim that the use of loss values in pruning conditions serves two purposes: (i) it reflects the learning status of samples, and (ii) it theoretically ensures unbiased gradient expectations. However, in Table 5, it is observed that even a random pruning criterion achieves nearly the same performance as the original pruning condition. This result raises questions about the necessity and effectiveness of using loss values as a pruning criterion and may require further discussion or clarification in the paper.","6: marginally above the acceptance threshold","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning","Keywords: Dynamic Data Pruning; Training acceleration","The comparison with the baselines does not seem entirely apples-to-apples to me due to the ""annealing"" period on the whole dataset. I suspect (intuitively and based on the ablations in Table 4 plus the pruning rule seemingly being irrelevant in Table 5) that ensuring the total length of the optimization trajectory remains comparable to that on the full dataset (by rescaling the gradients) in conjunction with the fine-tuning on all data towards the end of training is the ""secret sauce"" to making a dynamic pruning method perform without a degradation in test accuracy. I'm not familiar with the (Raju et al., 2021) paper, but would expect that at least the annealing period could be incorporated into this method without further issue. At the moment the paper presents its selection rule leading to performance matching that of full-data training as a core contribution, however if this can be achieved relatively easily with other selection techniques as well, I think it becomes more about the re-scaling/tuning as general purpose techniques and the cost comparison between different selection approaches being featured more prominently. I don't think this would worsen the paper at all, although it would change the key takeaways a fair bit and I think it is important that the latter accurately reflect the empirical results.
On a related note, I am a little bit concerned that the hyperparameters on e.g. ResNets for CIFAR10 are not tuned for achieving the final test performance as quickly as possible. I think it would be worth adding a baseline that trains on all data with a reduced number of epochs/learning rate decay milestones but increased learning rate corresponding to the computation saved by pruning (so hypothetically for 20% saved computation, train for 80 instead of 100 epochs but with learning rate 1.25 instead of 1 and halve it after 40 instead of 80 epochs). This is to ensure that pruning approaches meaningfully speed up training rather than benefitting from slack in the canonical hyperparameter choices for benchmark problems.
I don't entirely follow what the theoretical analysis is trying to achieve in 2.3. Isn't this just showing that the soft-pruned and rescaled gradient is unbiased? Isn't this completely obvious from having independent Bernoullis multiplied onto the terms of a sum (the total gradient over the dataset) and the expectation of a Bernoulli being its probability (so that if we divide by the probability, we get an expectation of 1 and the sum remains unchanged)?
I found the paper to be fairly different to what the title made me expect. ""Info"" and ""lossless"" imply a connection with information theory and lossless compression to me, which is of course not present in the method. I appreciate that this is entirely subjective, but would suggest reconsidering the title of the paper. In particular, I would argue that the ""lossless"" part is a bit misleading since this is not theoretically guaranteed by the method, but merely and empirical observation in the experiments. Of course matching performance to the full dataset can always be achieved by letting
r→0,δ→1
, but this would remove any cost savings.
Similarly, I think the paper overstates its relationship with coreset/data selection methods a little bit. These are generally not for speeding up an initial training run, but subsequent ones e.g. for continual learning or hyperparameter tuning and typically incur an upfront cost. On the contrary, the proposed method speeds up a given training run without producing any artefacts (a coreset) that are useful downstream. So to me this seems more like a curriculum learning paper (although I am not particularly familiar with this branch of the literature, so this is a somewhat speculative statement).","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning","Keywords: Dynamic Data Pruning; Training acceleration","originality: The idea is somehow similar to other dynamic pruning approaches. It does not provide a different point of view in the matter.
quality: In the ablation study, I would like to see if different threshold selections (apart from the mean value) can affect the algorithm. I find it a little bit odd that there is no discussion regarding to this point.
clarity: The text is too dense. The figures are too small to be read in a paper. I suggest the authors to increase the figures, while removing the text surrounding them. Some sections, like 2.3, can be summarized to make room for the adjustment.
significance: the authors claim their threshold value can be established in constant time, whereas the state-of-the-art methods require a sorting part (the complexity should be
O(Nlog⁡N)
. However, I think this improvement is no significant, as the speedup produced is residual compared to the time needed to train the network.","I think the authors should address the issue that can cause a bias in the final training, as removing certain samples that can cause this issue.","6: marginally above the acceptance threshold"
"Multi-granularity Correspondence Learning from Long-term Noisy Videos","Keywords: Video-language pre-training, Noisy correspondence","The paper could benefit from providing more context and justification for the chosen methodologies and design decisions. For instance, the rationale behind the specific components of the Norton method, such as the alignable prompt bucket and the soft-maximum operator, could be elaborated upon to give readers a deeper understanding of their significance and contribution to the overall approach.
The paper could be improved by including a more thorough discussion of the limitations of the proposed method. Acknowledging and addressing potential shortcomings or challenges in the approach would provide a more balanced view and help to set realistic expectations for the method’s applicability and performance.
Providing more detailed implementation details, including hyperparameter settings, training procedures, and computational resources, would enhance the reproducibility of the results and allow other researchers to more easily build upon the work.","8: accept, good paper","3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked."
"Multi-granularity Correspondence Learning from Long-term Noisy Videos","Keywords: Video-language pre-training, Noisy correspondence","1.This paper does not provide specific numerical results on how well the proposed method handles noisy correspondence. It would be beneficial if the authors could provide more detailed numerical results or analysis on this aspect in their rebuttal or future work. For example, they could conduct experiments on synthetic noisy datasets to show the performance of their method. They could also compare their method with other methods that are designed to handle noisy correspondence and show how their method performs in comparison. This would provide more concrete evidence on the effectiveness of their method in handling noisy correspondence. 2.In certain scenarios, such as video-paragraph retrieval on YouCookII (as shown in Table 1) and in the context of ablation experiments (as indicated in Table 7), we observe encouraging indications of potential improvements. While in other experiments (as depicted in Table 2), there are mixed results across various metrics. Can you shed light on the reasons behind this disparity? 3.How does the proposed method compare with other OT-based methods like action sequence matching? What are the benefits or drawbacks of using OT for video-text learning? Please provide some comparisons and discussions.","8: accept, good paper","4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work."
"Multi-granularity Correspondence Learning from Long-term Noisy Videos","Keywords: Video-language pre-training, Noisy correspondence","While the authors effectively illustrate the motivation in Fig. 1, the advantages of the proposed OT method over DTW require more elaboration. It is advisable to include further discussions to expound upon and clarify the claims made regarding the superiority of OT over DTW.
The use of the stop-gradient operation in transport assignment Q is highlighted by the authors as a means to enhance the efficiency of their video-paragraph contrastive loss. However, the rationale behind this operation's efficacy is not entirely clear. To remedy this, additional discussions should be included to provide a more comprehensive explanation of why this operation is meaningful and how it improves efficiency.
To enhance clarity, it is suggested that the authors highlight the second-best results alongside the primary results in each table. This practice can provide a useful point of reference for readers and facilitate a more comprehensive understanding of the findings.
The results of DTW should be included as a baseline for comparison. This can help demonstrate the advancements made in the proposed methodology and provide a clearer context for the contributions of this work.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."
"Multi-granularity Correspondence Learning from Long-term Noisy Videos","Keywords: Video-language pre-training, Noisy correspondence","(1) The explanation of why using optimal transport effectively learns video-paragraph similarity in the paper could be more explicit. Specifically, when the similarity calculated by the S matrix might not be accurate in the early stages of model training, it is important to understand how the training objective, which aims to maximize the similarity of ⟨Q,S⟩, prevents misleading the model. Additional clarification on this point would be beneficial. (2) The paper does not compare the proposed method with other methods that use optimal transport for sequence alignment, such as Su & Hua (2017) [2]. It would be interesting to see how the proposed method differs from these methods in terms of performance and efficiency.","8: accept, good paper","5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully."